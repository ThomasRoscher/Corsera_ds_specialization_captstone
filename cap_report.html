<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Thomas Roscher" />

<meta name="date" content="2017-05-24" />

<title>Coursera - Predicting Possible Next Words</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,%40font%2Dface%7Bfont%2Dfamily%3A%27Open%20Sans%27%3Bfont%2Dstyle%3Anormal%3Bfont%2Dweight%3A400%3Bsrc%3Alocal%28%27Open%20Sans%27%29%2Clocal%28OpenSans%29%2Curl%28data%3Aapplication%2Fx%2Dfont%2Dwoff%3Bbase64%2Cd09GRgABAAAAAE8YABIAAAAAhWwAAQABAAAAAAAAAAAAAAAAAAAAAAAAAABHREVGAAABlAAAABYAAAAWABAA3UdQT1MAAAGsAAAADAAAAAwAFQAKR1NVQgAAAbgAAABZAAAAdN3O3ptPUy8yAAACFAAAAF8AAABgoT6eyWNtYXAAAAJ0AAAAmAAAAMyvDbOdY3Z0IAAAAwwAAABZAAAAog9NGKRmcGdtAAADaAAABJsAAAe0fmG2EWdhc3AAAAgEAAAAEAAAABAAFQAjZ2x5ZgAACBQAADWFAABReBn1yj5oZWFkAAA9nAAAADYAAAA293bipmhoZWEAAD3UAAAAHwAAACQNzAapaG10eAAAPfQAAAIIAAADbLTLWYhrZXJuAAA%2F%2FAAAChcAAB6Qo%2Buk42xvY2EAAEoUAAABuQAAAbz3ewp%2FbWF4cAAAS9AAAAAgAAAAIAJ2AgpuYW1lAABL8AAAAKwAAAEyFNwvSnBvc3QAAEycAAABhgAAAiiYDmoRcHJlcAAATiQAAADyAAABCUO3lqQAAQAAAAwAAAAAAAAAAgABAAAA3AABAAAAAQAAAAoACgAKAAB4AR3HNcJBAQDA8d%2BrLzDatEXOrqDd4S2ayUX1beTyDwEyyrqCbXrY%2BxPD8ylAsF0tUn%2F4nlj89Z9A7%2BtETl5RXdNNZGDm%2BvXYXWjgLDRzEhoLBAYv0%2F0NHAAAAHgBY2Bm2cY4gYGVgYN1FqsxAwOjPIRmvsiQxviRg4mJm42NmZWFiYnlAQPTewcGhWgGBgYNBiAwdAx2ZgAK%2FP%2FLJv9PhKGFo5cpQoGBcT5IjsWDdRuQUmBgBgD40BA5AHgBY2BgYGRgBmIGBh4GFoYDQFqHQYGBBcjzYPBkqGM4zXCe4T%2BjIWMw0zGmW0x3FEQUpBTkFJQU1BSsFFwUShTWKAn9%2Fw%2FUpQBU7cWwgOEMwwWg6iCoamEFCQUZsGpLhOr%2Fjxn6%2Fz%2F6f5CB9%2F%2Fe%2Fz3%2Fc%2F7%2B%2Bvv877MHGx6sfbDmwcoHyx5MedD9IOGByr39QHeRAABARzfieAFjE2EQZ%2FBj3QYkS1m3sZ5lQAEsHgwiDBMZGP6%2FAfEQ5D8REAnUJfxnyv%2B3%2F1r%2Fv%2Fq3Eigi8W8PA1mAA0J1MzQy3GWYwdDP0Mcwk6GDoZGRn6ELAE09H%2F8AAAB4AXVUR3fbxhPfhRqr%2F6Cr3h8pi4wpN9K9V4QEYCrq7b2F0gC1R%2BXkS3rjKWXlfJeBfaF88jH1M6TfoqNzdWaXxZ0NM7%2FftJ2ZpXfzzeVILi0uzM%2FNzkxPTU68Md64GQZ%2Bvfa6d%2BP6tatXLl%2B6eOH8uVMnTxyvVg4fGisfhNfcV0f3luz%2F7Srmc9nMyPDQ4IDFWUUgjwMcKItSmEAASaNaEcFo069WAghjFIlAegyOQaNhIEhQxALHEqIeg2P0yHLjKUuvY%2Bn1LbktrrKrOgUI%2FMUH0ebLc5Lk73yIBO4YeUrL5GGUIimuSx6mKl2tCDD8oKmCmGrkaT5Xh%2Fp6rlphaS5PYp4kPAy3Un74OjeCdTi4nFosU6Qg%2BqRBsoazczLwHdeNqpVx3AW%2BoVjdhMThOo6YkGJTl862RFq5r263bbYSHyuswVrylsSBhHzVQKDU11g6hkfAxyOf%2FDVKJ1%2FHCvgBHtNRJ%2Bb7eSYepeQ4VLZBqAeMjgM7%2FzyJJF1kuGw%2FYFpEq458Xrr65YTUa6VCEKGKVdJ%2B2FoBYYNKCwV1K6B2s1mJnPB7Ww6GtyO04ya%2FHHWPHs5P4J65NyVa5VA0E0LocwPci45b6tvMvohm1BYc1h12Xd2GrbbHVkjB1pzs6IKtOHeYd%2BJYhFasmfs9Zt%2BSZlo9pu8eg0utWZAKB8vjaxBQx7cSbK3Qdr2nBwM27vrXcUHtLolLJyJjK3CAbDcFDo3hsPZ63IH2RrsoWyskdB47jiKitFtcAgqj4wQQxN3PB81RCiCo0Y1jnUVYlOj5JHhJd2JBevIEeSQxDWzTN8PEE3AL90KtP11dVrC5II1L1w331pHFq10vPBGYeyUCFRvB7PAEzMltdubhb%2BlZ4dw9w86yyNfG%2B%2Bu0ZWOBkmsb%2BGrsrKGIN4R0XPQimnAEcj3CI6ZDR35zzHJEZlcW5cQCTMwty4umkB5B4ajHwVNhQDqdMLSAmClnhLScgYgMbQJESALUrtIvjpQz9LVxuIPSiYgQkjusZ01l4BERrPtdO9KfDErKQLne6EUbJlXHqTccNzL163tuES26ickjo5va6FIkCyIyaFEYA%2BlejuqlFxLWIYKmQG9W0tlMe0yXu80wPe%2FOavEJrd8srSFziSal30wMj5H2mH7T6H218RQ93qOFysDEgtLBoRuQUeXjyPQKexdLjoa4vtAQJiBsEXYutEo9T1%2Fm5mUdBMbXFCzIq8Z6Yl5%2B7nyic%2B1mE3xisVatpBarpcC%2FmUs9%2Fs3Csty2GRPfLMo7FrfqcS1KDxIntwVjnkEtjRJoFKEVHWmelIyxd7Y9xlqGHTSA0VfbnBks08M4W21bHczuJBrTiYixiBnsMF7PepCwTAdrGcy8UqZb5uWGvIyX9QpW0XJSrqE7hNzjjGU5u1vgRe6k5DVv4DZvpVnP6Vi0yMKLOhUvPUq9tCzvFhi5mV9KVNMvWpfRJg1bggjEml6Uz6KmiiN92dh%2BGg19OHK4TmOC61TIcAFzsF7DPNQ0fkPjNzr4sMZHaEX5fk7uLZr9LHK9AW9KF2wU%2F%2F%2FBUfaOnlREfyrK%2Frv6Hyn3ISkAAAEAAwAIAAoADQAH%2F%2F8AD3gBhXwHfFRV1vg5974yvZdMQspkSIYkQkgmhdAyIIQQWsSADCLSpajUiMgiAkuJNGmhKyJGDCyybCiyiGBHRGQtyLIuf2UX19UPy7oWyFz%2B972ZBxOE72N%2BL2%2BYd%2Bbe0%2B5p99wBAscBBIN4ACjI4D4oUJEIVAbIL8wPYX4oP1TQ3um3%2B0v5dZz2bj44nsyKLhYPXKkaL1wCAhuuXcQ69dsWyAu7qF5PBMFqQzQRkzQgYvIQCuXleXYHlCXl2x1YZg%2BF7HxMDNAQLQoVetwuKZCZjRUTQqc%2Ff7RjebisqAeuEQJXmpZUdA%2F3KgcgsJA2kL1xDNPDZqCyQAWdXiIy5YOHThUq4%2FKB1XFpgPr5heVtJuSQvJzxOeKB6HfEplzKWCEA4Sc%2BVgqkw8bwIF16K7fg0ttNJr3DajEKBqfT5UlNkwXJKyD4hCRRlFySwU%2BTvTTJkJTh1wkms6l%2FpBWa08Fmt%2FWP%2BNz2AWYcYEez3WwXvU5qECE%2FVB5ylJXl5993Hyc3zw6hkHaPoerldxVjh7eMX%2FF3hYWxu0KF382pcKpXsV%2B9QlS93Mj%2FSz%2FujinsVE1dDTszcEk1u4LpPdjXmDdw6UAsqFlUg7rmf2J%2Bd3aGLmC757GBuEe55mHNXGxifZVrLtuNNUBhwbU6wSQ5IAOyoS2MCxcH7VmpXkHIdZlFP4BPtOvFdvlZZsncL0Kl1pZcS99Iam5eK1erfhFvrkviL9HDKc5X6OV%2FChUq7aGEvw5U6QuFVCbEhOSSZHegODM7WOzxhOzZ2cVFJaXFIbfHK2cH7WlELuK3EnR5vHZJEkzvHZw35S933n0ucur5ky%2FMO7SraN2mrVuqGiNPnIt%2BNnTy6HF4fMkfvf%2B6EEjfkpWPh7rtXrJgp%2BNAk9hzQScj6194%2F%2ByxlZE72Ow0KvcdloMLbPcBiDD%2B2jdSW%2FEk6MENfk55AfQMtwabaPC0aZWZ2a6Nob1NKgxRc3qemb%2FaF0jtk3xZPtkpc4Xjr3KVXE7WDfpi%2BsfVJ1RotwUyJVFVbE4ZV3JUPi0pLsq%2B%2BXMM4A9Vd%2B%2FYcXcVvrtx7bLN61av2oINVTU11dU1NVV4cuPaFRvXrV7xDGPNH6%2BheQJpbMQaHLiz8R9fXb5w8dLl5vO7XnzhD7uef37Xxa8u%2F%2F3ipa9pxpUqrt5AYeq1b8QPxVNg5BQWw13h9k4PpEqB3Lx2eW0DlmxfqkdfUhoy9Y6EnNZgW0t7MZ%2F6smlubka%2BI0NfFckQoDwPkjih%2Bd4yrpTleTdRqoinJE6Ts7AULcTt8mRxQbYjMeLcXMpYwucgMgaCkrrMn668Z97YBwZHJm%2F%2B%2FhnWZ%2FKwOzazl5c2DerS%2Bo2Xth9eshXXd7jTu7NHHeb98%2BVHfqw%2F%2Bz%2FCmp5zhvSZe3e%2FkSOubt2EO3tExnWrrbsy%2F51x94%2BaWFa%2F84V1k%2Fbfx2Z1fWE0%2B2It%2B2zfxGEfAaBiMbBctRiug0CpIBLFUpyK2R%2BOumYgYrZB%2BcZAdoT4%2BTfM0CpsksEggGCxGoNUsV4J5sVpc5SGJE6pwxvIJgM3r97%2B1Kq1S7et2UQKUI%2Fv7znOCn%2F8jpW80ohvKaN24aOatFEFAx8XLFYDFYItR0UbkQMljuIiEgx5HMS0efW2pWtXPbVdGZb9yjruPIInv%2FsR3z%2F%2BEisAhMFkrmCRXGCB9uEUKgoomw16o95qEwxoJiaT2cDtl84CUP5G4XWJOTBmWLK8olOmNOjMKhUpWZWHK5LZgl9279229we2OBUX50kuVjv5QDo7PBwnsvrhWJF%2BYDIuVagZDxeFHOF1MEKbsBMEQS%2BKJjOVdXJ1BKw61EH%2BfeqSTzTz3I7ZA3Zuv%2Bwhshy3sDFL2TjctJR6n2SDsfFJ3A0I5ewXfAgugw7s%2B0XQG0SAfFVWHOEsr6TyphSHW5NHFc9J6Wa%2B7B3Dfp42HguHAUINniPlZCpQ%2Fl0CogDIrW%2F8u85iv7sGv8ZzGzYAxjwV%2FMCxTwobJQCTWU8HRPQeruaaXpRqestVdUOXso7dupeF7px4Z8%2Bed3arKFc44AIg51W9ch4kIIiUEocmSk4sBpCcj15oUDRJXYYExl37RmirrkIv55rLASYJJF%2BS3t0nopeptU%2BE%2BmLrLK%2BlPgQyid3mCBU6UP1rVz8R2n770zc%2FXf7x8s%2FNn9fvaFi3rmFHPfmMLWRP4lycho%2FjNPY4W82Os88wiJ34K4tdAIQjAOQkx8YArcM2PaAOjSZBL8uolzAJFFvGDXd8ej67P2AvKpUkOYghcnK7zl300RBcsExwzJ%2Fhbrd7GuYBwhgAIYtbTx%2F3%2Bd4klJ3gtKCQnGIz9InYZEzqG8EkjSzNavCB%2FcXYlcQshhyMsZrI6PYLWc3lOG%2FvlA4rHr%2F3uTFD3r38%2Fr%2B3fMKOke9W4oJ9G566u7au84CpOz%2Fct5R99wF7W6dIYjjnawrHIAh3hlungFOWgXoyzVKbHOr1eD19Il6vISsrrU8kSzbY%2B0QMGpdjgYh60zDTHJKHoyP4404pw27zB4o1o62gq%2BBLL299am8j%2Bzv774zj995%2FdgTOZsOfWr3rnTWPj2h8qGbo1%2FM%2F%2FkYYvmxfms7TtPrM54E7ns4vwBw0rFy%2FaNJjRRVTet31OgCBPABhongUDOCAzuE0h6gnxChToCJ1ulB0iH0jeqvscFBZotflk%2BhMQ5oJDqhrC%2Fl%2F%2FFxmAUlGYeK5Z6Jl5MDec2yJQdc%2Bl5ViNduL1avoZ805eGll04jy6COKheT8S%2BU6kQwdw%2BlW6nPpXF4qtEoBziwAye3mMnRLkqlPRLqZdQlsKxTcLghkqhzjrLL5M%2BWgUwldSkjbL1HPLrCf51d8MHbv66zu%2FmcGl5Kz0YNZ0%2Bmcf759kbEB29qGGrZiYWop2b2R9fYqnKnlWOVzqXqgNfQIB5LtRr8fQLLT7CyT0ZLaL2K0WFzU5e0TcfmojkckcgvcyhJ4pNlr8Bd63VyEhIbiGhfIBFGTq8R9lqcWB2Dl1G79Rn%2F9i8n08OU3L%2F760UX2E369YuvqVUPrI9VryFR8CXc5V%2FrYefbW7svv%2FYNdxUHv%2FOnFVQ1V8yse2Dde0UcAIY%2FzU4L0sA1FEQg3jJT0jVAJFBlqbOOrALk1dCOmkuHNF%2BmpaKOYunHhldNAlZhEyFGpz4R20C%2Bc47Vmu%2B6gqXo9lewuq5TfXrLnZORk9Ink5JjAlNwvYvJBoF8E5N8qd9nN3jrmj7mOx8OPLDXqolpgwv0zZkpuzaeTynf%2BvWjNvnr22b%2BbsfDJR7%2Be%2BcL6dQ1bXlu3CDvOWfHIMytnrhJPHt7x4L7eg%2F48%2B8C5U0euLuu%2Ff8ozr1xteHTRssdGru8V3kwfeHTMsN937%2FzksLEzFdlO5NQpNsMLWdAtnJlizzQYAAQu26AljUvWZbEQlyuJi1Ymcr8Iaal2jjKNg5qJ9Ctqx02jMyDFKHJw8TpUIvjHKhXZQlZ0%2FIwe1eO%2B%2B6%2FRVHpg2mv%2FuPbBuguPMtfKLU%2BtuXfjkIFraEVzg2tlMuZg6O57%2FvXBP1C3kZ3H9od2PPV81RMVE%2FaNAy3HEcaokRS34Ta%2BLAA8XotzQMRiizkRDVfN87X0JXae6NzkVR6Znehb6J8XL%2BY3IKovXMjn0oEDMrkmmc2iXu9yGm0DIkab6hgTZklwj%2FT6FDccpXsmn6Rjlxv%2BknyrTFMR8%2BU%2FcF9%2BDiRwh%2FUCiChwdeXD58cDhSwsRjeikNNcTo83%2F0AtP2DDKLywji1nhxSezMTjgo9eVHOy3LBbJgIQ0OsEsToiIFRHrIjI4wHOlfxEz6a4ZOTXTLq9eTjdTofW1bEH6up%2Bg5GIBDhGEr2BkRNVlMZTa%2FP3HKVyrMMKrF3H%2FKPYUAWjlGsXaRnXrxTIhrJwqp%2FbMtnphFYWIdgGoLWtddqASGuPzdA7YhNaqFZLvVJSEa48LZwUd4YSN4mJ%2Baq%2FctSSXgtmD6gf2emV91%2F9KNj38bHd9l3PX0tq19dMnzFw3OSsgsWjj%2BzqPXn0w4On3e9nZ%2BNJLYFZ1yqkQ2ITFEM5zzwyA%2B1KLJ1kVwpAjsvSTgx3S%2BrQQeiisxv5Ky%2B9kGbnqUmllmSFEhOP6%2FG4ug6C2nJQUPdSt0td36R1IFMgbsUalrqlQAbw4KK1v1BwIH%2FudKqm8NCQbeMHP2LUtVk3rv7Fb4712N3Tt%2FDeaWvZt3%2B8wA7swe6Y%2F5cvjv3I1rHJn%2BAyhLM44ODVn14%2F7bBUDpq%2Fhpxb8c388XfdM%2BrU3veu%2BTws17Pv7O79aFvzMnvxc3aaHRq8sAZX4jgUsP7CfvYntoNhGYquJiAAAKJNPAIyWLjk0ojFqENR0SwqyILNaiG9I0bRYhFECoKD518xh6iplZYz%2B5W8H0OIlBsz%2FtURB6IHmnaT7itJORvb6A94cnbjGZYvHrnSg0zENwfPGTGddQIKJwCEo9xyW8ALGdA7nO0UUg1Wn89iEGQLjwd01iRrUlXEarWAxVcVsTjAWxUBevt4QnM9%2FgxBMbluwe4SAjxpj%2FmcgN0ef3cCt2IAhVVLsR%2F7%2BTIjjZjU9PTeY1ew4I9%2FOvhn8cCeI%2FNf9BnK2Pk3%2FkZ7TF00%2B6HoquhndauXPAGAMIdb09Oqr8gOu6jFpbdQb5IDekccglHi%2FHK2DL%2B4emRymUNIE3%2BRo3WokKfbtNP37Cs0%2F7rxjQ0X2Cvs2Rex%2FNNLuysbxBB7lX3FPmdvl64rwyU44QusOVSzuj8AUTgmDuEc04FdsYcWQQ8COJyiuSoiUsFSFREct4ppwc9rSBlA%2BZuAPZTBx2Az2Uo2CY%2FhIHysic%2F1z59PI%2FdU5CtWz%2BaJB9gi9gKmYebVKZgHgMq89Bc%2Br1GJWSSDAQXQoWAyS%2FreEUlCQsTeEUKRr3B03DZmUZBwxy%2F6S%2FMZmh%2BdTYZHt5OF4oH1LKc%2BeilhJj0UhpMlAKQ6pAbjTRPxSW45Q0CbAac3asPzwaNfrY9LTuyi2ilOhUvnI8SSohNapUJK7wiAaDLZe0dMgujtHRGdt4%2B8%2FHaphRyV9%2Brq5lT1xe9nfPc0a2IrDuKQL%2F%2F9bve3DrL%2Fso%2FQj0kbVrGXCYuWZWXjUhzzD7xn%2F%2BD6GvYau8Q%2BZe8H8LUY7WK6yuVQ2KdHBJ0giCCaTTraO6LTiQaJoshJV81RgnG%2FQbydi5f%2FDYnpjc2ssZGSRrI3Ws1z7dXkYQC8NoLNxfFqVpwaNht1OotVT4GzFDJj9GrpGI15%2BJJiPpxLMg0v6dVv9AONx9jclFWuR6fyFGvI0TNxvRC%2BUjHmnkjBViRGg4Ix0Yn6RGzLWkgJZRVRDKHw1TvRrzc2NpL1J6JN5M0l0dc5snnk4%2BjCBF0QIT1soQCCJCMFzgtw3EBXxTekkO0%2B0aio0pV%2FbIp9V%2BKIgpPrUZJOFCUev%2FJSmsuNBjuVjDK1gKQgp2DnLbuZlRjwuJUAn2MY4nce4COtZjadZSsCntbhh6zRomMm0bbpo%2Bbh4oGrVQLPOume7Uev%2FBCXo1IDsUG7sFsvcaytVpDB7jBS2aqjKCdypaUI4xPzabNJKZdj%2BWvNn%2BtsW4%2FRVB2xkGeEk582NR%2FnE3ZMwaxy2guAqFp99FZ5bu%2BIXqDW3hHqvLVNiOltBiTmueJRtpW9oZgjHIE9sBOOujo9%2Bv1%2Ffvn5h%2F9Eeb77LHuYa%2B94HIt1bArbxs6yU1iIuRjEAnYqZp%2BE8erqdUBRONnA%2Bc75DE6XQaiKGAySLDuqIjKVEtavhpXmSgW%2FmlplYChutYXx7Ay7tLsRZ5PWUePGL949euKoYPr7t1HOh2jK6mdXrVC5wHaoXLBCCp%2BZp8MeAIEa%2BOqmZtns6x0xC7KTL2yZM%2BMtlRs3J6I2pViG8q258sX7OOxndrH0tpz5ki3rzuqxivyf%2FDnN%2BWMCN1SGs8yIxKS3y0aDQdYTwePVm8EMVRGzmVDK5UepkSi6cntnp2Ku8ktw20SOf5bGNm4BcRXyGdhfcfkJ9jQ7%2FVXTzl2vfEZGRLeJB94%2Fzf4%2BLjqZjFi9cuWqJwDVHIFw29ha4V6a0wSQ5BSFrGxTGvV4uH30CFSfoEoJiY4mt0CGlozy8D%2Bo5jgx%2B6jmBbwy4BEI%2B9d3rHnZ0I%2FGN%2B7usnL1ey%2BxM389WLx%2F1%2BINHRbWXfoDLjz%2B6Z07su%2BYN73vyIFFvd959sV3qtf2nfFA35F3FQw8AoDgABCGcv7JvJ7iABSRUp1epgK3CYLmFeJ5qGYSi7k3IEsbWYFQyQrE9PWqJzjM14yPj2OHrLDdhgYZZafDrqOCmQ8UpzGUuFzsLkUnVHMYs4uij%2F2F%2FcJfFxrfee3ld8QDzf2vsC8wo5nuaa44%2BMabh%2BghQAAA4XW1%2FpMcNqJgMuooCJQqiPLlrxWvQhjgF8%2F%2FSgXTwej3O6M%2FNmF1x8zWHdVaFh%2F5uU3bnwXkmg1yXz6aT6km%2BQwpyW6LRdQn2Q0U9TGTotqUGOKqNclWAjJldKcyenwSZ0h8cyc75y5CT3v2xU42u%2BnL9p6UYpSa0Nne7yy%2B1EQ%2F7PaW6%2Fdbm0N88llHNx18ic5qnrv59RXv0YUK93QAQr1q9QNhhyCJ3ORLiskXFJMvtDT5KhocAz63Yu7rj%2FPIY0oTXmKdjuAkfHg%2F60QWROeQZnI4%2Bgq5M9oX4lybrUY5GWGrIBJRpnoDiChTUeOcJmE%2BqKL%2BGCJdcNEhlrSb%2BQ6T8%2BR887zoCZJPFyv1ZQBBscZ6pWKmQyqDLKBgMIoCNwcUdUrMcuuKmVot8AvlzU6qi9roq82%2F0LSFwoaNC69OAIQGdoRMVnSRY2mRUFAYoxcJlTDIOdBSfeJRD5nMSvEEu4B%2BdkS6svyKX6HWC0A%2Bi1c2Kd5c2XRy3h0mgYbo%2F4spg%2FKNEDuCzdrMFFACSacHOUgFevPMXj5rMb9CfMoLfOrSA%2BKF5b9KyigFJCgExOMgQVJYD1TWiQQEwrO%2BG5rpVFUTC3DfaPxsA1vG9pEg3dQ8jnwV9QJea2Zv0k3XKtUKsJLHIlEqwBgjmU%2FLQUfRp9mbCwCxTjhHHZIf9OA8AILRID2BkJ%2Bs1ZoxwDW1OMStBHU83G1fm5MZ0%2B4QzhUdK3f33F8MRKk50lPCUEXzoVc4K1NnTEvz%2BRw6yqMpYkzrFSFGI7jd1ooIt4LJFRHRA24o%2F98LVH4tX7NllapJZ7zS6LZn8QVeLKsVKjrQrxv43GPPvUychyc%2FVveH0F3HR77xCrNs%2FmPDWy89tOWB3js3Y1%2Bb1GPe7Jq5dxTuORZ11TZuHC3LD00fOhwI7OVWtVZygRPSeVUt0%2BD1Wq2mVGqiGX4zmNwOu8HOhccRljzgqoiArYV5DSXF1SDB1sddEk825YBijeRQiVcrvHAqyJ5Pv%2F3%2Bk0l%2F7GwKzGzQ6Wa811i%2FqXFjfb0wlJ1jP%2FDXxwMGLpdcbNHcsTuWvv7ll29fOPPJXwAQpnMOLxWGxbIaK6VuPU3ySmaOmQ0cHDPPzVmNGM9qlJ1DHgNzu6hmOGTcZXYV9f8d8HTbUOn8QrbvuW11Tz3swiw0oRPvyPQu96Sywe9%2B2mlNGRBlVqGU88fB%2BdM97E%2BVvGCx2CV7ht%2FhtgIgmqhez9mjt1FnRYR6bscerSYTkLTqvTcUDPLPA6osi%2BJOiG7ST%2F%2Fn2W%2B%2F%2B%2BTCTLMsNCxmTzdu3Ny4evOmNS9gNlr5647tA%2Frh0V%2B%2Fmfny%2B4Gv3r54%2Bi%2BfxLF0cN44IRk6hdOTDF4jpdzqtkrxGit4uRskyaUyyqIw6paZQyiRZQ632%2B%2BJsUuivNbh53Kb%2Bx%2F2JYp%2Fe%2F%2B7qFl8eecf%2FzBk65bfb7WQLstc2AZl1GMH9v3fJxx%2Fp2pttp%2F%2Bc%2FeGrS8oUksFoBYpHVxK3cVlMjkJ4UaSuj0GvhQMgKIsVkScspUqq0GtY98IAxWmOZS1p2QNgeJSXkPW3DX3mE%2BzrxreeANH3lObN6LH8KHopW83l9G3%2B3TugmsDC9PnPNkLgEKQuYQCzplcKIVu8HC4a56vQ5YpvYtY4ESnSHIzW6Vn%2BQzd72xlLbYWV0R0nXpFDJm6XKvOqvPk5pJekVxrm%2FJekTY2T7teEU9KnHUa%2Bzj%2F8pXd%2BrzbxD1uragaVBdAqDC%2BjaAUkrJv%2FOXKcGMXmJOnbhQXF%2FF3QsHJVnf87VhB3sSqoa%2Fte5X9jf3r7FdPzMgtC%2FccNOnTtwb3ZPb6ZWdOPLzh7amPD50%2F4z8%2F1T4uVE5ICkzt9ewxXYdBbfPqVx54ddvqMauTndXFnYfmBnY%2B2PS66ypEhs2ZFOn5IO08%2FZFvfn4cEPYCCD24nnuUzM5i0nFz7dF7vEkWvcMhVEQcNgOA3q0Y7xjlCatesVT2mALbtRUfM1P06cfm%2F%2BGZhgadoWD%2FjBMnyJuLfn%2Fkk%2BjrfHXnDOow4N5XP4gWAxDYDoDjxAtAwcr9tZ3PJCDa7Ga5MmImVlQ04%2F3EwqZSIqAJJVQc3NDQ1CG3TceObXI7CJWYU1Zc0qFDaSkAubaKudSxTZAEd4Q9TqPRrNP5kj22yognrLcC1z6ISzW5xSTOhATTljhb3v2det7Zv%2FeNGZnLt9g16B6h%2BaqNHZHv0yaP8TSV89QGJTzetxgMRqNOEkSdYHeYAGw2nY7KRje1xiKGfD5zeUyFyuJsRTUiQi0bdclYkzcER73JeuD5E2zOnB07dKSgy2icydpGlxLpQTZOcjW%2FXTo9NjcO5nNT4GQCoiASQHfca2tMVBjHYVRo6SRfJQGoCAfcdruDiz%2BgdwRo66xWHrfb4RPMPm5p0302p1UPDkUPuCLEt534Igi1bHVIVIgEzfAqepHh1bRDypryyOa1DVNmblnVsDhFl79rIuIAXcHhmYdfJicWLNj3cnSLcv%2Fzx9HjQmV99dDDg8e8%2BheuMZq2cnxdUBBOApeiri69x23S22xcWW02g%2FV2ytpSV72Jmrp7m4JG6NDUt95RNPXwJ%2Bq8d0XUSWM2dhSfU9EknsU6wSyDnOwzeLgds1GbYvxvmcVylSHFilGFxE4PYRT74fKaf%2FwOTZcvobX5lZ3PPffii88%2F10Cy2I%2FswyeR%2FAFNmMfeZ1f%2F8rfzH545p1j5vdyW1apU%2B6E8nOEzCrKsS3foHJkBwQhWq7siYrXprboUaHXDzMdZ0GLBqpaeO2hPAhMUr62Y%2BgRHrThpU8Niry7c%2BPBf%2F%2Bf7yzvryabGFc8%2B6xowcMRg1kUqqh9azT5h%2F1GcNr14%2BGTWl29fevfUeYVXHNNSlVexqMKW6qHJyT6bL8OfnOK1pqalecxOp8wtv80MFRHz%2F%2BY2VT5yJ1l63Ul6r3vQ0njtQyL9GzaIW15cvXnjnI8uf%2FfJ57P0SQsajObpM%2Fd9mHXp3YunT59birloRDO2a6z%2F9T38eEzFCzE9okGOpw1ywy6zXm8wEF4DsZrB4FYtg03rc2nRkaE5IY15ZEfvjt4eRQtfaahz6rrsFoaZNlk%2FfTbaJFSenDQjlrnS6XyW1twOtIplrqLzeuZaEfHYJKq%2Frj%2F5t8pdueG5kbsG25Hfpq50%2Bj%2Fe%2F%2BtjA%2FbXzF82%2BdmN88r%2FevSPL3Z6ftEjj7Yds%2BJ13jSzsaHnpjbt7h4Uvrdr2aAH%2ByzaXLm4R1W3O7p2KO71FCCkX%2FuG7BQrwKPWJlwu3jPioEKS1%2BC0OXtFLGGbVeaCkj1xU3kqIVjV5ONWqo52xVGXhtxKNuHyEMcdA5NSJuSy17ZurRiBXdlrw2vN8lyzHQeQZdU9%2F83mRWePngiAsIOvrjKhElx8fh86ZZPJ4DS4PSaz2aZzWdVV7TFqEbMS%2F4daVmW0rJcrhBY127EvX9TPNNQl6UP7Z7zztlAZLeMO6GMSvnpozV2Dj54hp7RcjgiVau%2BHAQ0ms6hHK6jhiJZl%2BNX0NFTicIYQt7ER%2B76ptuiMte%2FtYyP4oI%2F8o0cx9iPtrx6K5UpSgI%2FWinsblz4lNc3rsZipYBZ0yQ7ubnTuxCyYK7c2A1U2Z2Rlk8LhUHSq1BmbsoRPKeSfcBbp2qSdPsY%2B3jNxsk5nLHCcaHqjg0snBF7dzc6QBZ3OvHR%2FdK5QyUaz6j5l%2B4tJbXTp7trW9eRvHClACAIIOpXGzLBdFiVAUWlxQZ3RLaD1pnQ4ngmjmhUfYgteQT9m%2FJktwFVH2Cn27hFSQLxsGO6IfhU9jUdYD0AgfL1LfHw3z%2FsVMqnHK5jB7OBLO0UHfIJCVam1GRJo46KKOdrSUrLvuwFOnfnuS%2FtYTsWfl%2FStKu2xq3cXzuCVn9wf%2Bpn87mrGy5vtC03HtkAsZ6YPCZW3yJl7RUQr6npF0P2%2F5cz0oeZ%2FksHR0%2BTL6D5y31Q6eN685sPxrixetlPl5%2FYlJxu9AFbZRbmnpqlpTq09K3F7TdV%2FbpXcPJZTfEtxCddDvj7d3EK4ZLfHjedrpx794PFH58%2F49MClCxdM44aRZaRxE%2BaPjywnw0Zg4ebdS6Xj7NzZoCl4FhAvMxuZrfluorSo0RSABN%2BtlHzx8nKeJv3cDAiV7Ijaw5Oq4OwWDQ4H8UFqqsXiE2laujso0QScEzYFFXSDxYr7U7DPVNCV5Dj2pcRw4eKhDx%2BZ%2F9jjp45OnvHwVFIePIvB49LSPRvZ%2ByPvJcsjvOq5cRenZNg4zJn2qEvdpyXVQg6tAS%2FXAzu1JvkcpuoIdVglCaojEuTngS3pjfw38rSkOlOZT8nQVNOmbD9lKoU5HFg8t2TMUz2mRrqPyi95omTcisrHK%2FsMJSfuLFn%2FUKvsVinhsvqH%2FRkZSeoOPFuKdcJwrcuYCALV8343AGpSu4xtNPOWXcZcCQNO1%2FXt0PNKk%2FGszp3Ly0IVZPfVC2Lfxb3C5ZVhQDjK7fd5dVemazjNozNTahCARxo62irVJxKnwUz4SzDKgg%2B07k9ljt9sw2apra1KOJCldLR6NAOuqD89OWHNwpPHcdniPisKChY%2BtHv7My8sX%2FFdifTO%2Bxlov4LNXXfvoH7vstCH5z462QkQypUYSDzBpV4Zzk5y6s3mZI%2BdGD1OMS3dlORL6h%2FR%2B3xOcNr6RpxJIPa5uRWkRdPQzZ6Nm29lf5Lfinl2ypuduEqQxqONXTatnD0HG9jQblU05erVU2%2B99f%2FEEzUL%2B%2F1uGTs397MxS%2B7YtDz%2FxwtzsfO%2BU4psZqMkeIVtnHNByAibW0GmBSxtctLd7iwZeNSYn1gJchaVBku9il8r9co82Ja9clCxDnKwNLs0IXQ6VLV4%2BOLx8%2BeOq7t%2FUVXVgmF14%2BYuGrN42MKqeVtnzHh627QZW8mHj01aNmxh794Lhz059ZEFD%2FCHvfj7JZN%2BN2XbM1Onbd8BiscDEJT9Fw8MDrdzWGSj0WYS9URPTS6LW%2FYmGSwW2So5HBScbqsz3UmsTqvThG7JlATlWg%2B33RHrzL7lpjuGUOGj1uaovjBEKnH2HjYCJfY6dmGv72BvYGd%2BARu7j1wgZ5vZ3Ma57Ec08RslQBKsgaxUVYkkUR726QUqUDlmFjgmiYqtbgjFLYRiI5p%2FYebmnxVpXPuF1kupUABdeGdcdiE4pdy0Dj5fmkmCgNS13E07lbRqK%2Fn1%2FmCviN%2Btt%2FWK6OGGznh%2Fs4t9I39VVFmLztSUlwuwZdCiRC2l%2FKk33lG0dHD%2FqprTbw5%2FZmTxqMV9Z8yYvelw%2FcCqjf%2F%2B6K9P9H9t4KLl7R%2BcvmJR99W%2Ff6Ggbs3LPQbRnMF1WW0mD5q1NDW4IJjSKdy5prTH%2BklDl%2BfctXrZxm5rs9r27dWuY8e8oqHTRvWb0MVZPfnuKWXOMUCwWLTQ8eKH6u5TWpiTanKAI8lnpW495N90QCAhzctKeI%2FFxVnZpaXZWcU4pzgrq7Q0K6tYnFrUrl1RYUFBYfwOQGEM7xzvEdt5hxKeSwWDXmrNT0936a1esbSDZAKH1ZRuIuCwOYjJYXKk5AWcoRQByhNPBdhblgFRMxHuG90bnN2obu8KDjc3eYHM1py5DiFU2NqhNXTQOXMWz10weE77sRWvffDZq0880vHB5vXv4PB3les1tv2D02z76xP2YNvdezD3pT3s7N497JOXhMCeTTu3t%2F2dq9X3n575qfMjIXZI%2FQ7b%2Fu6brOGD0zj0rT%2BwD%2F%2BwB3P2xr8GQKCCushU8W1OdzqUhlt5pRQDokeJazP8rQwGh88D1EYJNTvSOakf3feGku9qVGpqG4xTV8ojfbXWGSt18iYUtdZJXEnDlt0%2FedPztWvHjM%2BbtnB%2BHauecmLUlAeov2bk6HHjJkhCcGFoRIcJs1jnI2OaCgRBqd8NhFraSI%2BCBGbICTupxI21YNTrBbMkWKwmUYegHGS5WbPRiyhjVuw2EAfPVEriM1kjLsUhtexzTK9lO0kQ1%2Fdk29mzvXB9yo23qh9EHfeDXhAhJWwiKKAki0J1RCSQr20nattixUJOXfM71Bv9Hhc%2BCdeuaV3LRAIbAAjXdUoX16r7wqGgF3iOLui5Zpn1JodXKu1gsnFoi9Pi0DmtjnQHAR63E4fT4bythikCCP22ZKVVoUS%2Bhp0Bqm51Fnr%2BL2UjHz5YPXLwfRNx36B%2Bl3eeXrwWxYbNVy%2F8n%2BpGrtwd7tNtSfXsNFaLo9jTdPZ89ub%2FpXB47YrkEiRpzW3r%2BoJ09UfBJLnmAoG5dBi5LJ5U83Z%2F2GIGp7L7nGwzHPNQhS3J7yWaAKe27LkytvA6c%2FfPn39g4Oqa%2Bfun195VPX3qwLunC2vmH9i%2FoGZlTdOCgdOm3l0zdZoiv%2FGASic8yQYLAMhwBiA6Q93NqCLLub9OUmpcstOLaHGCwAsItnQvZqjyadHEUVx6cz%2B0JMt%2Bsjy645vIQH91edGont0XbPj9msiaPXiIVI2%2FNHhk35IePbMLh0yeP6V6%2FZPPA4KflKlzBqAsnGkVRaCONIPUOstxn%2FMhJ%2BnrRKMzxUmcTl2yP92s88eVhKvIfTe2KDHRmKtlyd%2F2PpPpA3vsPbRzw4w1sz%2F8snbmA6Or7%2Bw%2BpUPP8mXDl2wVvqx%2BwJu%2F%2FYmVHWb32L5q0oAeXXrkBYa2LZl5056LnkfvwhP6xD0X5YAIN3pyAOvaT85494494cnCD133dnN3O1oEqNZDegiV4IHicLJoMOhs4HS6dC6%2BLeC2ulLMRKks6LWkMWHX6XqfaELKyMnTOhsGs13PNCxJNkz%2BZ%2F0Qg6GhAeewK698pKaNLwyr2caOScrsU1mzMEJygRWCYYcgIoBopDa7TidSq4jaQa%2F8RJkG7MortqVTEvILI6Z9PL1rzacn%2F%2Fov0pY1S3t%2FraYhx5WrKDBA2ED6Yh0dqvitsEECMJuofkCEQsyAJOqq2jzatUOseZR82L1nz%2B7xMwlZzIVNAOBQIge7xQhgUfrILXa7jtog%2F71CzQq3qDNoZYbSkOzBpo31obZtOw24a8BDQx4ubWIXRk7UT9S1Kckrtu%2BbHgSEvqQKP1d3kPleHwFKDSZuX2mGBGlK3sc5EGO7FpnEzw8MXLlQ8pQsvpNv4K4ld9471NP2%2FhFAoDt1kaPi26q3zgo7lONnEnBvHfMfbr3iP964r4XTTjgzJSYsWHJ0V%2F3qF3eu3%2FB8lN07fsKwYRMeGCZM3nHw8LPP7T%2Bw%2FTH%2Bb%2FYjjwCBau4hdsY9BF%2BZRr1AgMrEoJdu5R%2F4fBhELEUxdqM72c5aTGef1%2BIQVnvjPTGxCb3wfhzek01IufGW24c%2BAOIZzq8gnCYLACAbHrsGKMNHNDV6EPR%2FosTBA8ziYuCw7Tjs%2BThseQz2CwV2Ou3PYeV9xMZBVchkAMkvnuAQM34FFf4CxEZ9KD5qXmxUIBBiM2mNMBxSoY3Sba1zpQWwlbVVwCXk5EIqmmhqKj93lzEgkm2zG3tH7IEWecP9w%2B9rGZ4ohslCYnXDUm9MGF2J0ihbnJBfkf59Rs7q4vv9Y9X1ozq9%2BdbRTwPhSMnYbk2zOnXtXqqkXKHH1tZM7NOvw5ip2e0XjzjcWDEhMjB%2FyIz70jFvcU%2FeGRvmVKrdoPJ0bltbq9R1v%2FYaDgTdn4hNzIa84ltA1MLCGETS7SCOQSAGkdoSIv86xGsg3HKMrOsQE6CUQxiaKGmtgtyAkWIwIMNxKIN5QK4xAIk3MIIVnNA%2FfAdPM%2BwIOhPaRNEtuvROycm7kHm7iMHM7wabASUqOtByowkglmHm5an5G8bOiYau9y%2FSAF7vYVQ2zqR5UUeUXdxLDtMT0SMkNXqR9Lhag0cfURpetbZG%2FAvZr2jRHOZSOkc5ztkqzrMIAf55rM9N5VmbON8PqhxBs8aRmyFqoTwG4b4dxLFrV2MQyS0hsq5DTACHylWC%2FhhXgUA%2BgFip9id54Z5wod3t1glmAKcgCUk%2BrogS11erXC6%2FJJ%2BWL8jcIsuyoNfbqiJ6Kri17tNEXW55EDWhHZV7uVhLarxnM5QhVqpNqbM3bcJ9eBf%2Bbn%2F07S9xNlt4lIyKtaWSunqyntWxHSQcba5nhhhNYrmqS%2B3jurSmJdWx7jiVLwUx3sKsmLb5bgdRi4YYhP92EMegKQaR3RIiX4PgeGy65RhZ1yEmwMdxnW4b5z7CQrQJJmEDGMEX1st6ino0mXXgy0%2B0x2rMHLeOu0ewbTh8BHua7RiLw9m2MThS2DCa%2F3fbaLyfPTsaR%2BCIsWwrAOXzv877434CJ6RAQFkZnnRvmsAPExtcAA6rqFMCF0%2Ba32f2945YHTpRoDazQHnjnES1lrm3%2BFq4%2BYgL%2Fygm0lglwc7fxSoM1BZEj3qKzovZ1zsLv1479tEH9ykddGe2jnx04rGmh6Mjpu%2F9zy%2FNwbFk68SdWpPhmOUDNr2FDyl9dMMXV699l61D26bmvgOVZjp2ZRN9qTc7xVdOrI9LlUxpXLoVMfk7Nb7fDFELp2MQKbeDOAZzYhAZLSGyrkNMgA3xlRNMtEfCbHWUTvF5CmKjOFSQeO%2FfrHjvH9%2BpMOtFUbKDBB6vWeALiC8fs96sl2LdkZoVarkRrHVH8v9lCDcaJGexM%2BzzQ42NZ9GHnuYrO3mL5LvvUdvFy4zXWq%2FB6ei%2FV%2B5Y9yQAqv0oW6R0aK94ppxcMTUAXpMJUu25YkGhw5Hbrl12RaQd5LrV3S5tj%2Bvm0xpaZCBL2vZIQjWCo6Q2%2F2lnOTKUqE%2F1UYJv5ZAOKb36Lxv32p%2BOTCrfUnn27ofnjujZq094yVz2TcPf%2Fv7%2B58IPi6dX3OnPyC0L3b917LZdPTcF8w%2F0mVQxcHZN%2BcTisqHF1YMuXO0r7Nv3562c52pXkOTnPL8TACXovgLUVWlXOH6L57V56vN2t3t%2B7FP1eajFc%2FGz689fe%2BUW3xc%2FvP58whegruiOKsCNGRZehzj%2BcwyiTQwCqAIhKbtXOVDENWdkOJQLre3tedlIaF%2BWlJTe3ghi5y4pbYNtKyK%2BAqGgV6RD66BdECyZQU%2BxzqKriLgsNtBaO9R97viBxZsNL1corarUot3Jy%2F%2BqHSkOv7bLFExMz5TiAMaaVIb%2Fwg7NmPnUc0VVb4%2Ba%2F3xO8a6Hj%2F0reqcOO967tWbwurHswpy73lz03Mt7Jg1ZtfPpwzvoK7OWGon8BOY%2F%2ByddrEUqp%2Fie%2B4eMYP%2F9%2ByRWGwjyVpav5k5sXH9%2F5MVNo2XdQ6Sw4ektO5V1zXc4lW4kzreeMU%2BJFaqnVDtxVIn1ikl8vyqRVppEbn5e21993vp2z4%2F9rD7PafGcS1R7PsEQk1d7TaLX%2FgqAo9URXolZHHYXKGOgqI3xIgApTICovZYRgzDHIa79iUMMSoA4xl6IQTg0iG84RDrHQ4OYwA4CqBbHZ9d89VRlx1zyq6euqsJ5fsnUqhXwYN5jsTttkj7YRp9eETFSj91nsfLIR0%2B9LqSttY3QmLJw6%2F3b430QyITiIlAqxdlBMcj%2FlHpUk%2B6gRVqnV4kwil39%2Be%2FsK5T%2F9sUYXdkp9n3vr4YN77ll3OW%2Bpzc8v7NpC3vppe0vPUtC7Ev2FzR%2FcQmlWcInr25%2BcGHXgtrefZ6cNHMlm8b%2BtaaRbXjh4Aku21jXgbraqmOrzaLyJC1RNqNUrt0Vk%2F1HquySb%2Fe8drD6PPN2z4%2Bp45Ngi%2Bd8fu35a9%2Ff4vtcJtrzCSkx3Wh3fS2Ph2YhR9gJVO1CD4WTPAaDTSACKjsZTifKZjMqJ%2FQQ8tX1yhOfG8nPjUN6iccXE96Pp8ejezqVFHXsFCrqot3J8iefZP%2Fq3KW8Y1m4nPwYfwOUY3tEGCUsjvv7PvxEa3orl8vQ6iZn76u47uxt1M%2Bb2Kjnf3P2ZWVxBdGcfXw7QXSpTl4Si1SnX6L2X2yaUjNt%2BDw0Xd40o6Z25NzmV4rxTJ9pvAljfYjl95r63Iuxboyetf0XbEBQGjL6zuy7cMOvu8aRRcWffLRjTHRO6DzXjNjutSq5e2KSf0PVDI8mmZuf107VNOfWz4851OeBFs%2B5ZLXnE%2FyxtZarrfrYDqw6wr2xGWIjpKsAWu%2BI2t%2BVyXex0jOkFJfNZpfsrQMOsKeYPHqqT%2BNdjB7q5euvRZPnb3oYUWsXUUomXo%2FW9JUVbx7J4HugOKR748Sz333%2Fyd8fMwk63mSElTs38OYRzF9LmyID2Efsvwpjn83sV86KdcDaFQ1NOXQi58u3ce%2FZMxo1nF6Nmgn7Y%2FTmxejV%2BpuEyuv9TaJArLfsb%2BIw6gkU6UvxFLggHe4Ot0uSrE5nKpjtqZKY4bc6eDxpBaOR51hGGj%2BVwg8UUAc4b5zk4det2ia1fWVJO2TlvZF9aafq7NnSl1EYN4y9zJ7BYRgeN5RaonxdR8%2BRfs09fmXXEH%2Becs89LqzDiTgeF3ljSZmwlZ1m55QTGn6hNi32qy1yujAU0iAXCmBQuG26zkI8nqx8t7tVlk4oDOW1Mbbh0RHvSCKixdiunWg32pIyxcyKCIieFj7YoVjVRAeseV9R9a0q5rdyvYktTFkxnyvWs%2FNzup6pu8B%2BROnrBae6djz2%2BInL0aAOq4Y%2Fe8%2BQDVf9G154buPm5xvWCb3mrjKRjN%2B7vp4xEwtQh3q8Y%2Ba0KbPYz19MYDO5tw1mkLIPz3985rOPP%2F10x9NP7wBEE68Q7pH8YFF6wGWwWXmN0KJs3CSfKkwsE%2FIgzx1QzhIE0DR3nLfB89CcmUMWLuFF2u%2BWPJGTu3C%2Bt3TBoiIAgpP5iG2lhdp%2BkEMyxSpMejflw753u9KSrHUfcfpp29njxj46a8zY3z3YPRTq3rmsqJu4b9TM2lGjps8c3qFLlw78AkQdn%2Bk78TN1N5wPn%2BSzg2gC%2FnKrZc73En4mKLYb3o4vKU6BwvQ0olRTQpJEXXkDB%2FTOLAxZRpmn39tucP%2FKjIL21tHmqcL5rLZZnbvMquO3Tl1n1aldEci5Ff%2FFEyCCePMvngykw%2BK%2FeMIh5f8VUtYgffQ49lB7%2BR0HUNTpQenhP6WBBkscHEs5y%2BQZ1WF29yx63DMUTVyicNM3RdTpRZly061Rq55Od5RisXIk%2FbGKDPGARzmLjqmfcouq%2Fe4LkcAKAEQZizSpY1khOWwS0KwXbHbQUZP2M1%2Bx3pUgbyrhA%2FvjeGG9tcNjs9M6maNnb2B4FnXTeR1Tw7TF6DZldL0ZRcHuMIs2WRn9LW10DWe%2Fei9JQJ4ELUkjOsxJ7m6%2BQYbnXvbTY2Ow6D6FHh%2F7lTTBZZSVLOtqB8g4iCCHzeZK%2BdC1Y38ymWJ3vb5SBnteXszG7cAfyXB6EYzgPBD%2FURrIP3Wr6u%2BOqQ9OmDF94qRp5JtZj%2F9u9sx5C%2Ficym8TiHvgB8gGOwAEwU4c%2FM4nELJA1RaoJelK5ZPTbBAIlYikk0WuCInpvPM3e2CJ%2B16ASv2UpGqjUBAIkMRRWhRNSeqtK6QAyGYBkJXxUyYgEkE7ZYLxAQJIVjbPWkkXx4%2BZIJRzr1gnnuT0TQ2Xp3rTPZ5kI5Hl5NZ2wZDslYJtjN4kb%2F%2BILklMTUvtHyFp1rT0tPw0qqdJaUlpzsxM6BvJlJ0W3iDhg5ZN3bwwdMsfKruRW2ZQbuRlt9evdcorVpPyolGwuJT%2FdUDsCHUKOz4AWfRHQvA065Z1snHLxtW7%2FoddaNewgZANO4LY%2Bn9OPN%2BrQSxmD80rC7ed1%2FRm9%2FpuaEacl3tH9TwUsfXIpYPVzprl6o4iBXdYT0AUtDAtYc3y%2BEuJtrjkUwGEVlI650ylKvE%2B5ABA%2FHNTwuf9lc%2BBgItUcf0%2FAgZwQedwuks0ypTyaYjSqY%2BiqLe60l3E5aIWOZ1mxPuV70toergeGwR4g0v8V2eKi0otVJZJ05xV7GHcsHQO%2B0ESk9LSjDup6913x%2FKzVKdeX9THFGzb1v5TDDfpQ45bECoJ9%2B43cBcf0nCXXr%2FF8%2F43notvxJ6rVEnqc1TWG05X9cp%2BAAQRKWiHl2Knck80KgqljCAC4Aq1QvJpPHP6XaxCImp1FiUv6pwAUXstt2Ud9NrbHGJCAsQx9ufEKktsFtJBzroOMYF9EK%2FV%2BGK1mv8PflNJUQAAAAABAAAAARmahXJJOF8PPPUACQgAAAAAAMk1MYsAAAAAyehMTPua%2FdUJoghiAAAACQACAAAAAAAAeAFjYGRg4Oj9u4KBgXPN71n%2FqjkXAUVQwU0Ap6sHhAB4AW2SA6wYQRRF786%2B2d3atm3b9ldQ27atsG6D2mFt2zaC2ra2d%2FYbSU7u6C3OG7mIowAgGQFlKIBldiXM1CVQQRZiurMEffRtDLVOYqbqhBBSS%2Fohgnt9rG%2BooxYiTOXDMvUBGbnWixwgPUgnUoLMJCOj5n1IP3Oe1ImajzZpD0YOtxzG6rSALoOzOiUm6ps4K8NJPs6vc%2F4cZ1UBv4u85FoRnHWr4azjkRqYKFej8hP3eqCfDER61uyT44DbBzlkBTwZD8h8%2FsMabOD3ZmFWkAiUs5f4f2SFNZfv6iTPscW%2BjOHynEzEcLULuaQbivCdW5SDNcrx50uFYLzFHYotZl1umvNM1tgNWX%2BV%2F3gdebi3ThTgVEMWKYci4kHZhxBie3TYx3rHbGr%2BPdo7x4dIHTKe5DFn%2BO%2Fj%2BW2VnE3ooW6isf0LIUENvZs1gf%2FLHojJwdpplCP5gn%2F5gi26FoYa19ZVFOJ6Sxuoz%2Fq2Ti20IKVJdnqvYJwnhfPH%2F2f6YHoQF30aZaK9J8T026RxH5fA%2FWPW%2F8IW4zkpnIfoFLifGB86v0ffm5nbyRs5iaHR3hNBD0HSfTzoPugRM%2BhdN0x052KoHLBS0tdgpidAiEesDsgWYO73RWQz2LWIwjqnMe%2FuYISQtlbyf2NlT9Q9PoBcBnrO6I5ELoMeyHkNnIXGdv809H%2FDXNOTeAEc0jWMJFcQxvFnto%2F5LjEvHrdbmh2Kji9aPL4839TcKPNAa6mlZUyOmZk6lzbPJ3bo56%2F%2FCz%2BVaqqrat5rY8x7xnzxl3nvo%2B27jFnz8c%2FmI9Nmh2XBdMsilrBitsnD9rI8aiN5DI%2FjSftC9mIf9pMfIB4kHiI%2BhWfQY5aPAYYYYYwpcyfpMMX0aZzBWZzDeVygchGXcBlX8ApexWt4HW%2FgLbzNbnfwLt7DJ%2Fp0TX4%2BUucji1hCnY%2FU%2BcijVB7D46jzkb3Yh%2F3kB4gHiYeIT%2BEZ9JjlY4AhRhhjytxJOkwxfRpncBbncB4XqFzEJVzGFbyCV%2FEaXscbeAtvs9sdvIv3cjmftWavuWs2mg6byt3ooIsFOyx77Kos2kiWsIK%2FUVPDOjawiQmO4CgdxnAcJzClz2PVbNKsy2ZzvoncjQ66qE2kNpHaRJawgr9RU8M6NrCJCY6gNpFjOI4TmNIn36TNfGSH5RrssKtyN%2B59b410iF0sUFO0l2UJtY%2F8jU9rWMcGNjHBEUypf0z8mm7vZLvZaC%2FLzdhmV2XBvpBF25IlLJOvEFfRI%2BNjgCFGGGNK5Rs6Z7Ij%2F45yNzro4m9Ywzo2sIkJjuBj2ZnvLDdjGxntLLWzLGGZfIW4ih4ZHwMMMcIYUyq1s8xkl97bH0y3JkZyM36j%2F%2B58rvTQxwBDjDDGNzyVyX35Ccjd6KCLv2EN69jAJiY4go%2Flfr05F%2BUa7CCzGx10sYA9tiWLxCWs2BfyN%2BIa1rGBTUxwBEfpMIbjOIEpfdjHvGaTd9LJb0duRp2S1O1I3Y4sYZl8hbiKHhkfAwwxwhhTKt%2FQOZPfmY3%2F%2FSs3Y5tNpTpL9ZQeGR8DDDHCGN%2FwbCbdfHO5GbW51OZSm8sSlslXiKvokfExwBAjjDGlUpvLTBY0K5KbiDcT672SbXZY6k7lbnTQxQI1h%2B1FeZTKY3gcT2KvTWUf9pMZIB4kHiI%2BxcQzxGfpfA7P4wW8yG4eT%2FkYYIgRxvgb9TWsYwObmOAITlI%2Fxf7TOIOzOIfzuEDlIi7hMq7gFbyK1%2FA63sBbeJtvdwfv4j28zyaP8QmVL%2FimL%2FENJ5PJHt3RqtyMbbYlPfQxwBAjjPEN9ZksqkMqN6PuV7bZy7LDtuRudNDFwzx1FI%2FhcTzJp73Yh%2F3kB4gHiYeIT%2BEZ9JjlY4AhRhjjb1TWsI4NbGKCIzjJlCmcxhmcxTmcxwVcxCVcxhW8glfxGl7HG3gLbzPxDt7Fe%2FgY%2F%2Begvq0YCAEoCNa1n%2BKVyTUl3Q0uIhoe%2B3DnRfV7nXGOc5zjHOc4xznOcY5znOMc5zjHOc5xjnOc4xznOMc5znGOc5zjHOc4xznOcY5znOMc5zjHOc5xjnOc4xznOMc5znGOc5zjHOc4xznOcY5znOM8XZouTZemS1OAKcAUYAowBZgCTAHm3x31O7p3vNf5c1iXeBkEAQDFcbsJX0IqFBwK7tyEgkPC3R0K7hrXzsIhePPK%2F7c77jPM1yxSPua0WmuDzNcuNmuLtmq7sbyfsUu7De%2Fxu9fvvvDNfN3ioN9j5pq0ximd1hmd1TmlX7iky7qiq7qmG3pgXYd6pMd6oqd6pud6oZd6pdd6p%2Ff6oI%2F6pC%2FKSxvf9F0%2F1LFl1naRcwwzrAu7AHNarbW6oEu6rCu6qmu6ob9Y7xu%2BkbfHH1ZopCk25RVrhXKn4LCO6KiOGfvpd%2BR3is15xXmVWKGRptgaysQKpUwc1hEdVcpEysTI7xTbKHMcKzTSFDtCmVihkab4z0FdI0QQBAEUbRz6XLh3Lc7VcI%2FWN54IuxXFS97oH58%2BMBoclE1usbHHW77wlW985wcHHHLEMSecsUuPXMNRqfzib3pcllj5xd%2B0lSVW5nNIL3nF6389h%2BY5NG3Thja0oQ1taEMb2tCGNrQn%2BQwjrcwxM93gJre4Y89mvsdb3vGeD3zkE5%2F5wle%2B8Z0fHHDIEceccMaOX67wNz3747gObCQAQhCKdjlRzBVD5be7rwAmfOMQsUvPLj279OzSYBks49Ibl97In%2FHCuNDGO%2BNOW6qlWqqlWqqlWqqlWqqYUkwpphTzifnEfII92IM92IM92IM92IM92IM92I%2FD4%2FA4PA6Pw%2BPwODwOj8M%2Ff7kaaDXQyt7K3mqglcCVwNVAq4FWA60GWglZCVkJWQlZCVkJWQlZDbQyqhpoNdAPh3NAwCAAwwDM%2B7b2sg8kCjIO4zAO4zAO4zAO4zAO4zAO4zAO4zAO4zAO4zAO4zAO47AO67AO67AO67AO67AO67AO67AO67AO67AO67AO67AO63AO53AO53AO53AO53AO53AO53AO53AO53AO53AO53AO5xCHOMQhDnGIQxziEIc4xCEOcYhDHOIQhzjEIQ5xiEMd6lCHOtShDnWoQx3qUIc61KEOdahDHepQhzrUoQ6%2Fh%2BP6RpIjiKEoyOPvCARUoK9LctP5ZqXTop7q%2F6H%2F0H%2B4P9yfPz82bdm2Y9ee%2FT355bS3%2FdivDW9reFtDb4beDL0ZejP0ZujN0JuhN0Nvht4MvRl6M%2FRm6M3w1of3PVnJSlaykpWsZCUrWclKVrKSlaxkJStZySpWsYpVrGIVq1jFKlaxilWsYhWrWMUqVrGa1axmNatZzWpWs5rVrGY1q1nNalazmtWsYQ1rWMMa1rCGNaxhDWtYwxrWsIY1rGENa1nLWtaylrWsZS1rWcta1rKWtaxlLWtZyzrWsY51rGMd61jHOtaxjnWsYx3rWMc61rEeTf1o6kdTP%2F84rpMqCKAYhmH8Cfy2JjuLCPiYPDH1Y%2BrH1I%2BpH1M%2Fpn5M%2FZh6FEZhFEZhFEZhFEZhFEZhFFZhFVZhFVZhFVZhFVZhFVbhFE7hFE7hFE7hFE7hFE7hFCKgCChPHQFlc7I52ZxsTgQUAUVAEVAEFAFFQBFQBBQBRUARUAQUAUVAEVAEFAFFQBFQti5bl63L1mXrsnXZuggoAoqAIqAIKAKKgCKgCCgCioAioAgoAoqAIqAIKAKKgCKgCCgCyt5GQBFQBPTlwD7OEIaBKAxSOrmJVZa2TsJcwJ6r0%2F%2B9sBOGnTDshOF%2BDndyXG7k7vfh9%2Bn35fft978Thp2wKuqqqKtarmq58cYbb7zzzjvvfPDBBx988sknn3zxxRdfPHnyVPip8FPhp8JPhZ8KP78czLdxBDAMAMFc%2FbdAk4AERoMS5CpQOW82uWyPHexkJzvZyU52spOd7GQnu9jFLnaxi13sYhe72MVudrOb3exmN7vZzW52s8EGG2ywwQYbbLDBBnvZy172spe97GUve9nLJptssskmm2yyySabbLHFFltsscUWW2yxxX6%2B7P%2BrH%2Fqtf6%2B2Z3u2Z3u2Z3u2Z3u2Z3s%2BO66jKoYBGASA%2FiUFeLO2tqfgvhIgVkOshvj%2F8f%2FjF8VqiL8dqyG%2Bd4klllhiiSWWWGKJJY444ogjjjjiiCOO%2BPua0gPv7paRAHgBLcEDFOsGAADAurFtJw%2Fbt23btm3btm3btm3btq27UCik%2F1sq1CH0I9wl%2FDTSONInsjxyKcpGc0VrRNtGx0dXRF%2FFpFiV2KbYl3j%2B%2BJz4vkTaxKjEgcSXpJzMm6yb3ALkAnoCV0ARLAcOBjdCAJQJqgWNhJZDT2EbbgTPhz8h%2BZFJyDbkFSqgVdGh6Br0BhbFFCwHVhNrj43DXuH58V74WcIkahHvyDRkLXIGeY18SxWl%2BlMHaIVuSc%2Bh3zHpmNbMJOYuy7DF2E7sFvYMJ3Clf%2B3DHecNvjm%2Fm38g1BYmioxYS5wqbhZ3S0Wl2tJkab50U04pl5CHy9vlmwqlZFJaK4uVnco55YlaUK2kNla7qEPV6epi9aMW01jN0zJohbRZ2mptj3ZWu6e91wE9vT5LX63v0c%2Fq9%2FUPRiZjprHS2GmcNG4ar8yIOcycZC4yN5mHzMvmE%2FOrhVq6NcCaYC2wNlgHrAvWQ%2Ft%2Fe6w9115r77XP2fecrE4xp65zwM3lNnZnuBfdZ17E071sXj6vrTfP2%2BHd8F74lJ%2FeL%2BHv86%2F6D%2F23Qfogf1A%2BqB10CAYGk4LFwdaf2C%2BJfQAAAAABAAAA3QCKABYAVgAFAAIAEAAvAFwAAAEOAPgAAwABeAFljgNuBEAUhr%2FajBr3AHVY27btds0L7MH3Wysz897PZIAO7mihqbWLJoahiJvpl%2BWxc4HRIm6tyrQxwkMRtzNIooj7uSDDMRE%2BCdk859Ud50z%2BTZKAPMaqyjsm%2BHDGzI37GlqiNTu%2Ftj7E00x5rrBBXDWMWdUJdMrtUveHhCfCHJOeNB4m9CK%2Bd91PWZgY37oBfov%2FiTvjKgfsss4mR5w7x5kxPZUFNtEoQ3gBbMEDjJYBAADQ9%2F3nu2zbtm3b5p9t17JdQ7Zt21zmvGXXvJrZe0LA37Cw%2F3lDEBISIVKUaDFixYmXIJHEkkgqmeRSSCmV1NJIK530Msgok8yyyCqb7HLIKZfc8sgrn%2FwKKKiwIooqprgSSiqltDLKKqe8CiqqpLIqqqqmuhpqqqW2Ouqqp74GGmqksSaaaqa5FlpqpbU22mqnvQ466qSzLrrqprs9NpthprNWeWeWReZba6ctQYR5QaTplvvhp4VWm%2BOyt75bZ5fffvljk71uum6fHnpaopfbervhlvfCHnngof36%2BGappx57oq%2BPPpurv34GGGSgwTYYYpihhhthlJFGG%2BODscYbZ4JJJjphoykmm2qaT7445ZkDDnrujRcOOeyY46444qirZtvtnPPOBFG%2BBtFBTBAbxAXxQYJC7rvjrnv%2FxpJXmpPDXpqXaWDg6MKZX5ZaVJycX5TK4lpalA8SdnMyMITSRjxp%2BaVFxaUFqUWZ%2BUVQQWMobcKUlgYAHQ14sAAAeAFNSzVaxFAQfhP9tprgntWkeR2PGvd1GRwqaiyhxd1bTpGXbm%2FBPdAbrFaMzy%2BT75H4YoxiYFN0UaWoDWhP2IGtZtNuNJMW0fS8E3XHLHJEiga66lFTq0cNtR5dXhLRpSbXJTpJB5U00XSrgOqEGqjqwvxA9GsekiJBw2KIekUPdQCSJZAQ86hE8QMVxDoqhgKMQDDaZ6csYH9Msxic9YIOVXgLK2XO01WzXkrLSGFTwp10yq05WdyQxp1ktLG5FgK8rF8%2FP7PpkbQcLa%2FJ2Mh6Wu42D2sk7GXT657H%2BY7nH%2FNW%2BNzz%2Bf9ov%2F07DXE7QQYAAA%3D%3D%29%20format%28%22woff%22%29%7D%40font%2Dface%7Bfont%2Dfamily%3A%27Open%20Sans%27%3Bfont%2Dstyle%3Anormal%3Bfont%2Dweight%3A700%3Bsrc%3Alocal%28%27Open%20Sans%20Bold%27%29%2Clocal%28OpenSans%2DBold%29%2Curl%28data%3Aapplication%2Fx%2Dfont%2Dwoff%3Bbase64%2Cd09GRgABAAAAAFIkABIAAAAAjFQAAQABAAAAAAAAAAAAAAAAAAAAAAAAAABHREVGAAABlAAAABYAAAAWABAA3UdQT1MAAAGsAAAADAAAAAwAFQAKR1NVQgAAAbgAAABZAAAAdN3O3ptPUy8yAAACFAAAAGAAAABgonWhGGNtYXAAAAJ0AAAAmAAAAMyvDbOdY3Z0IAAAAwwAAABdAAAAqhMtGpRmcGdtAAADbAAABKQAAAfgu3OkdWdhc3AAAAgQAAAADAAAAAwACAAbZ2x5ZgAACBwAADiOAABYHAyUF61oZWFkAABArAAAADYAAAA29%2BHHDmhoZWEAAEDkAAAAHwAAACQOKQeIaG10eAAAQQQAAAICAAADbOuUTaVrZXJuAABDCAAAChcAAB6Qo%2Buk42xvY2EAAE0gAAABugAAAbyyH8b%2FbWF4cAAATtwAAAAgAAAAIAJoAh9uYW1lAABO%2FAAAALcAAAFcGJAzWHBvc3QAAE%2B0AAABhgAAAiiYDmoRcHJlcAAAUTwAAADnAAAA%2BMgJ%2FGsAAQAAAAwAAAAAAAAAAgABAAAA3AABAAAAAQAAAAoACgAKAAB4AR3HNcJBAQDA8d%2BrLzDatEXOrqDd4S2ayUX1beTyDwEyyrqCbXrY%2BxPD8ylAsF0tUn%2F4nlj89Z9A7%2BtETl5RXdNNZGDm%2BvXYXWjgLDRzEhoLBAYv0%2F0NHAAAAAADBQ8CvAAFAAgFmgUzAAABHwWaBTMAAAPRAGYB%2FAgCAgsIBgMFBAICBOAAAu9AACBbAAAAKAAAAAAxQVNDACAAIP%2F9Bh%2F%2BFACECI0CWCAAAZ8AAAAABF4FtgAAACAAA3gBY2BgYGRgBmIGBh4GFoYDQFqHQYGBBcjzYPBkqGM4zXCe4T%2BjIWMw0zGmW0x3FEQUpBTkFJQU1BSsFFwUShTWKAn9%2Fw%2FUpQBU7cWwgOEMwwWg6iCoamEFCQUZsGpLhOr%2Fjxn6%2Fz%2F6f5CB9%2F%2Fe%2Fz3%2Fc%2F7%2B%2Bvv877MHGx6sfbDmwcoHyx5MedD9IOGByr39QHeRAABARzfieAFjE2EQZ2Bg3QYkS1m3sZ5lQAEscUDxagaG%2F29APAT5TwRIgnSJ%2Fpny%2F%2FW%2F%2Fv8P%2Fu0Bigj9C2MgC3BAqKcM3xgZGLUZLjNsYmQCsoGY4S3DfYZNDAyMIQAKyCHTAAAAeAGNVEd320YQ3oUaqwO66gUpi6wpN9K9V4QEYCquKnxvoTRA7VE5%2BZLemEvKyvkvA%2BtC%2BeRj6m9Iv0VH5%2BrMLEiml1XhzPdNn3n0rj6%2FEKn2%2FNzszO1bN29cv%2FbcdOtqGPjNxrPelcuXLl44f%2B7smdOnjh09crhe279vqrpXPuM%2BPbmzYj%2B2rVws5HMT42OjIxZnNQE8DmCkKiphIgOZtOo1EUx2%2FHotkGEMIhGAH6NTstUykExAxAKmEqSGMFl6aLn6J0svs%2FSGltwWF9lFSiEFfO1L0eMLMwrlT30ZCdgy8g2S0cMoZVRcFz1MVVStCCB8raOD2Md4abHQlM2VQr3G0kIRxSJKsF%2FeSfn%2By9wI1v7gfGqxXBmDUKdBsgy3Z1TgO64b1WvTsE36hmJNExLGmzBhQoo1Kp2ti7T2QN%2Ft2WwxPlRalsvJCwpGEvTVI4HWH0HlEByQPhx468dJ7HwFatIP4BBFvTY7zHPtt5Qcxqq2FPohw3bk1s9%2FRJI%2BMl61HzISwWoCn1UuPSfEWWsdShHqWCe9R91FKWyp01JJ3wlw3Oy2Ao74%2FXUHwrsR2HGHn4%2F6rYez12DHzPMKrGooOgki%2BHtFumcdtzK0uf1PNMOxwDhN2HVpDOs9jy2iAt0ZlemCLTr3mHfkUARWTMyDAbOrTUx3wAzdY%2BniaOaUhtHq9LIMcOLrCXQXQSSv0GKkDdt%2BcVypt1fEuSORsRUwgrZrAsamYJy8fu%2BAd0Mu2iYFhexjy9FIVLaLcxLDUJxABnH%2F97XOJAYQOOjWoewQ5hV4Pgpe0t9YkB49gh5JjAtb880y4Yi8AztlY7hdKitYm1PGpe8GO5vA4qW%2BFxwJfMosAk2X9n9X2cVVfnA36pzHNHJGbbITj75NTwpn4wQ7ySKfAu9u4kVOBVotr8LTsbMMIl4VynHBizBEJNVKBAfMNA9867j0InNX8%2BranLw2s6DOmqIHBIbDfQR%2FCiOVk4XBY4VcNSeU5YxEaGgjIEIUZOMi%2FoeJag4mEB3PUOweCaG4wwbWWAYcEMGKn9mR%2FsegY3R6zdYg2jipGKfZctzINQ%2FvxkJa9BOjR44W0OpTKAskcnjLTcKyuU%2FSVIWSKzKSHQHebYW9mfGYjfSHYfbT3%2Bv877XhsIwGzEUaleEwITyE2u%2F0q0Yfqq0%2F0dMDWuicvDanKbjsB2RY%2BTQwOnfvbMUhiNPFyDCRwhZhdjE69Ty6FjoOoeX0spZz6qKxxu%2Bed523KNd2do1fm2%2FUa6nFGqnkH8%2BkHv94bkFt2oyJj%2BfVPYtbzbgRpXuRU5uCMc%2BgFqEIGkWQQpFmUckZe2fTY6xr2FEDGH2px5nBcgOMs6WelWF2lmiKEiFjITOaMd7AehSxXIZ1DWZeymhkXmHMy3l5r2SVLSflBN1D5D5nLM%2FZRomXuZOi16yBe7yb5j0ns%2BiihRdlFbd%2FS91eUBslhm7mPyZq0MNzmezgspUUgVimQ3kn6ug48mntu3E1%2BMuBy8u4JnkZCxkvQUGuNKAoG4RfIfxKho8TPoEnyndzdO%2Fi7m8Dpwt4XrnSBvH45462t2hTEX4Bafun%2Bq8jIzK%2FAAEAAgAIAAr%2F%2FwAPeAF8egd8lFXW9zn3PmX6PNMnPZNJMRRDMkzmDYgZMRRDCEmMMUPJIgZEepHlRYyIiNhRUdYuS4ksy9reLDYsdOmLLC%2FLy7L2CgKrrCJkLt%2B9T2YyYPl%2BD8804J5zT%2Fn%2FzznPBQKbACSTvAEoqJAdtUhUJpQYjBJVAUrKSkIOJ1ZUOEKOUGkfV8ARiPB7E72m87WJZF58ibzhXPVE6QsAAnMufI4H9XXsUBh1UpOJSJLmQNWqNsasLkKhsrKnA%2FT1HCF9PQzSAPYtD5V5PW4lmFeIK86EcCRbObLp2lGjGxpH4%2Bf0wLkjjU3NDSNGxYSMxbSdDkzomhE1SypQalCISvniob1lDuTL7injC1O%2BMr%2FxmeJtxeRt%2FiJviJ8mmrjFOr0BJCZ3QAbkQFu0ypCZ45HcRqNJQkiT%2FLKsOO02s2Ryudze7CxVUnw%2Bv9%2BtmKTcgEEymzPRlgN2e5rHaeOXyeeiisnJFagMOSsqSkr45kL8Tr450SfM5%2Fy1V66pGvBwTV1BcYcDEX67QjQkbo8cigTplyVI2OHh%2F6zdXHO4%2BiR6SjoxMPzo8O21h2tPx7O2lmylNV%2FtY5Nwubj3fXUA%2F8BuFveBr74CoNB84V6pSnFCLhRCL7g7OijfR7Oy3FalR49AcXYRFBnsQUcgkAYO6H15j6wiAGu%2BI%2BAo6pleFDAWKJZMX%2BaImNunWOpiskIVH796ewAqEzvV9gqX9nQ4Qd8S%2F1V%2FScSM%2FrmsTP9FfNUNIvzuVlRPMFxY5PB6fY6iwsJw3%2FJIOOTx%2BlT%2BWzaR%2BxYWecrR7fWFFanqi%2F33nnn9%2Bv%2BMvXr7mk933%2Fv5Gy3PrN6yZjg7WFV1D5s2oGoh7nx%2Bk2vvTrkeDT0HKlieXvvakkfecj%2F5uKnhm6iNHRk27a6bevTL%2BclH3ulVkX3cBTJUXjip%2FCDvBiO4wQ95PB6qo%2Flen0%2BWTRpofo8nLa04mB3UgpeX5PbMLEzzKz4%2FtapOlXt5a1llpXhN7FF7r8zJ37o%2FiN15Q2XhvsE8RdajOqwFyrwFGETXr%2F0F9u9dNnZsWW9869X1azow9qe%2Fkpc7D52mPRf%2F%2FHcJFrR1npvf9sWX336EO7%2F9x7lqeUMn6frt8y%2B%2F%2FZD%2FJjzecOGEAnxvWdzjpTAzWtHbGjRhlhdMXqvLVZSWnl5kpSoChLJVtcwXSPea8vNLSrT0dEnTegyPaZIUqIlJLnSKhAV%2FpfBuhb9EbE53bYVIM%2F3S45hfiZ%2B7th8IFPHN5QuXcscms1vF8kiAZ2qBsEEEFQX7FnJDeNy%2B8nIF2JLZ7%2F77DPtk3rJhVV9vefPD%2B57CzCF98cr82%2Bs631s4%2FvbxrKPf1XjT0Iqrh%2F%2BuafTMxR%2B9e%2B%2BmxqZnxzzx5l8embstxo7PeX0Ju3DjoqYJA7C611hyd3hAtH%2FzpD5jAAVm4DM6Zjj5C5WIAIu9DuxCIB0kuvEBAKGBbSTz%2BL%2B3Qm7UZjaZqCSBqtrN%2BVQgmAMTua3joeaMhBTicTt9wULS8PSj5x58eNk9Z5c9RUrRiPte3MTKzvyHRd5Yh9vFygP4yq3JlfmyfHG%2Bso1LyP%2F5yqgRNVjuDPclRSGvk7Q%2B%2FejZJY89%2FOA5sTT7ifVb%2Bzru%2FOEM7tv0EisFhErSJGUpbrBBOOo3ms0ypVZUVc0umUyqilarYrDxpN1aJrKQuykJwvwz%2FyPMUOCTXSqlRa6CiEzJy8U4J8DWf%2FjpM%2FeeOMZeLMKpxYqbPTyx088Oz8MKtnMuFqefm4gzAKEZPpUqpG1g5qivGRSjkSKAxWo2giJRKOFCysqS4vjNhQXCAa4Bxz1HEI%2ByNlx0FBextqOk9SjezW49yhaIHbGzuBtOggKe1wgFWVapDCXbdSNt5ghfoNCgMxLA3X1v%2B%2BdV%2Beg%2FvIsdR9MJYWVcS5rISqDg%2BCuVQQLkSiTc7QoHPANIGq49dw6wi7GwgmvujZoUrrSRNsaMLqjsmfjnkYu4aU6SlJZ28xECNyqt0mMrM2pBricBidueiNS5iDcRA0ir4h%2By4yQgGJP%2FDwLVF05IQ%2BW9XLoPLou6LYoTFPCnGT0jYkaV2kfEaBok8y%2B1kkYCeeDQnIEyQI2nUrlDE3kkDT3PzsfZhXMoxZHGw2OmTRl7w%2BSpLeQoW8gexttwNi7C6ewO9hD7%2FusTaELr8eOAMA%2BA1nJtTNAj6jJKAAZEs8WgqihJRgX9wJHOkYoXkf8iwR2RiKKqRRiitWw3lYdnr30cDzNae%2F8Tw%2F1L3sS5gFALINXpKDQgmp1pQxW86M3O8aoqMTlNtTGnSjATM2tjXEgCYfS3hKyuCkFHkzBeScI6WKhFVxLuD%2BEQLt4TkOo6CU5f1drrhvrrVly%2FdspDayfe%2B8EtQx7fuJG0HcbZLyyc1r%2B5qXbojtE1xa0dt4x%2F5c31r9hA6MYtP5DrVgijoiV5Po6KKs3MBOCVStFlgez8bG57v8%2Fvq4tZ%2FGilfr8pX7VqJm1EzJQGeg3j5%2FxX8ruWMbrG4oduFyXxMEFyQlkpkMeJTvhKbCMY1j%2Fo2ykPlEmSr335KxvYPvbZydev29P65KNrX58%2Bc92zfxv6%2BKil76PnU1Sl6fe%2Bl694%2F%2FzIweMjUO1ZPnH2TU3fxqa09%2Bl%2F6OHXAQgEAaSZuhddMDiaZ1epkRAzpTKAxyVzrnGh7JLreGi7qF1VqO5WvoGQ0DwF584uo3cpz4sCBzc9T9SAQPKgoqI082X2QfxhshCzXmZ5Jmoo6MvOYAk7gCWH6cudN5%2B98oSroZZNBoRWbuEw1ygDmqI9OZ36aJrbbTPYqIFmZrldRpdFA27ONADF4%2FHXxjyKYhkRU9LgYsIJ6e%2BpgHAkGUjkgUhLSBg2N9w3IMwpylMaKScT%2Fn6efcC%2BPLN8xActmMGOhu%2B4bH6EpsV%2FyAgOoO0n9%2F%2BHnR2B5h7hr455LAPJ1%2Bwc%2B1i1AYGhXOs6eQf4IR%2BuigYUp8WSlweZTnAWFNpz6mJ2u4d60kbEPGnUwENEvUTbVJbqTCjIAQJlPo8IXEUNdQEJcCAhMvd%2Fgvy8Q3E6TmsbErv%2B%2BZ2tRuuN%2F7f1X%2BzsNyv%2FvYhoN066sbVlcRuZiq%2FiWvuP7rEb%2F7LuhyPfsFPLMffdxfMnz7%2B1fu5qEc0RPdM6QIHLo14FgCDKRFYNMiWU1MaoAsLfupYpQwobhpDby4OfkoJ4iZQWPyy9jNLm8wLSdEtUyzvBB3lwOVwbLXYqnl6U%2Bo3%2BQo%2FHnp1ttBtL%2BihOZyBQXGwBS0Z9zJIGwfoYXGwTYYlLnVeWdKFwoCSqAj0%2FLqoW8qk7kShFiku3kK9cfCPVHyDedt%2FqpeyLL06zk4uXtU1DyfXfE2fPmrng0Ccjbhg%2Bflxtq7zz3ZUzXhrU%2FO6sjqN73mrbXD2iY%2FKzm89vbBp7Y%2F3VcwaOI3vqq674XdnlYysH1Ym8GajvcgekQQFURnOzZJfFEgyCCwqLtNy6mKZRrzd9RMyrUkMdR%2BNfdbfu7DIBzCIaw0J5kS16edcXuNOdBXwbyU1J1ewxtvTOqxtHP%2F3%2BJIOl3xOz3v0nmr9Y%2Bf2d8VNjp4xrbbm7jQ5mdazJdtYzasufW2r%2B83%2FH0fEE%2B3DTXbdNum1%2BHfd4stOSZuvMURh1OXnyAPjtnsaYXeumMPAnaOwXTOb4NVYT72PqU%2BxG7xcf6mPNQAQX6%2FIUcHKmcllV1UUlBRXFZdIaYyZNUjgzJ6Rpm8u6mKrApzM0vUgYbrTrbF2SFHbS18Xa5GhSmF5P7JYqZODSiqKajIK%2FVYNEqQIEZRigFxShVFwJURhGD6JU0ZlDP443kvW7ccNSPH2abWFfCns140peoYDeNeZHHSqlRgkMcp00ViJSV30QKhkjagSue7JMQH4304%2FFkrTgKC9Tjh69VLueUScBrhFPNVAUJJTKEur6Ce0u1dCFuorNZH28UayJb2IaDjjNtKWsWmioXPicrpB365FYFc3LTU9PA%2BB2dlqdhUV2QCMFCAazGmNBl900ImaXkg7mVCR4KJVkyfpRJFR5F86oRckaXOFoe0m%2F7W6YevPVY5uWvzf1w3P7vm99YGyIHU4139VjH6ob1tLvqqpxR9u2r5m2onVI9RVXsHUX9eMTLkxQdnCc6AuVEIv2VCsq3G5XOGzt77rMZaWBtEDvNOgN0au8hkhEMg3QTPzqkVUq5feAklS7rOucMleiPU7ivc6kQtuiYCqrfNTdlVF8fxLxCKgtj3iUQC44%2BjrzOa06UfyDSESH3x2j106vnpWmTXnhlT1o%2BUfT%2Fqt9NdGau79%2FZhf73%2BexCP2T2Pz%2FZefZXez6I%2FgIyv%2FEkRs7Yf3IFpM1FG27n5x%2B%2BNQ9Q%2FotPPTGQSQBH%2FPd%2F9Yf%2Fvjjne1sx152gh0p6f3eKHwYW3%2FEZZ93sA627uCCpcfMzwj7AIC8WN4IKljh6miAWKkBQZHNZgqip6CSZLOSmpjVSs0yBZocIpTouZRiZWGortKL8gsDiITjI5Uik%2BLHJ7FXiYTziRJnywoMgWdwNFstbzxXRcbikdvy72CqiPvXAaQznI%2Ft4Idczsm9VLdbktKzzeY83vfZ7QGDlqalDY9ZNLRSTbODPb0mZneCvyYG9BLcSxY9KQVDSTe5ArmSp7voCQYwWfE4HPqnwOu4AyOYNn%2FC%2FfPZh2fjx7C84%2FaZ8xev2nXHraxT3vDKpkVrHaacdQ%2B%2B%2FxGdXTuy8Zr4NrZo3PgNgDCXI%2FUBnh9eKI36VZeLN%2BNWnxscUBNzSKpskmtiJleyNBOvSfVEKuQRD2%2B0Iw4l2BUdoTI%2BZiikBS%2B9h9OfOtrxL7aJvdiOkQOHDrc2tEs72U%2FHmW846xyGi3DSZ3j9azd1FvUDImwoz%2BE2NIBd1OtGAIdVkjTZUhOTqWTlLbMzaamUcEELnGVzAbVA0BHKleew8ew2Ng534wR8gL3Dxq5ZjO%2FxGuQP7A55A7ubrcHDnUMBdY8RLs0Mg6L5BgnAqphMiBbFWBOzKNxLAnII3zehaKqJofOXXkp5iCsitPAkbol0bqDV8RN4ijmIm4tl7zK2BLqkUsalGqFvNN1AqVkBQDQJoSl5QlZS0MVSLhaCX7P9dHD8OHKMEwKWxLu8KBdxL6ZDTbQo3e8nNquVEFemy2DIsGlmjQdbOr9BNkt%2Br%2BzlsmTu1FB3wd0z5VlnstgW8BBwKLpv9YJL5RlPdMKNOALkU1L14E93sr%2ByVfg43vTxgZtW%2FGXnd1vevKGVHafhuOnyAlyMU3AcPjDybB377rOT591Y2mUHeYJu%2FUg004jIzW%2BQJFm2GGhNrMaABoNsUijK3QmbMnfKFN2XPIHtjr%2FNdmE5uRrDZG78Xj5t2EIGAOCFiawBT%2BozgRw%2BbSAGXiPLwM0MRsr79e4NCw4Rxa5IJL6kRnJurq0bOKEZy79hDV4k7gVL5JHn1l4AdgYS%2BtfxVS0wMJpjIcRkNiOAzUBl2cq%2FUrNZoXwP3VtwpgBXF1eWAOXEQAdVfSMRDKBcx1awhYvEZm7FB7CZETKxJf4D39CN6%2FHf8XkJ6VIlly6LPUkqBVCQArccJKJUl6GXoPq6r3PD1MsbzldfSPxvRcyR3dAvmukGo9nI1bbxUPHKisdJjEQxq9QGilBcN36X0mUp6hA6Y9DpEYujXuXykscVRBpkK4wudhzbcaSC07GdfUgtRrZEms9Wzok3cw1WSi3nqklH6R3oPr8kYcedOm6WR9NMYETFagVwUFlRVM1MVW5RVLtHv11adI%2FEnAKwL1KEcM%2FJO9nv43fpSiwh81U7%2BqQGdrQtXseFv4FZvycdQPQ8%2BVKfDHgE0jgAfBZF8RpdNTGjRO01Mer6daQROSBexQQy16Hxpkj%2Bkj3BXubXE3gz1vNr%2FPlDb76Bs9nSNzaSY%2BxxdivejVP5tZCj0mP%2FOYvf4smfoAvtpHU62rkEFkhGowdsNrvdbQXBV3ZNM9TENGr%2FTSzoRn%2FZLXHoEyAo4ckJSx%2Bau%2BBBspEdYacX8yA6iCb0UGXmlKkTd504Fz8rb%2FgchAXYat0CdkjjEZynUFmSCDVIJg9AhmYypVOVEwBXRFK5UWSV22N7Ev4uHU92T9OQe%2BLX7PPaKziWzWZnfL9pJMZW1bO5OPS3LSUP1S3lg9poocvnk0ySppm8njQw8cTzu4wWMA6PAZgtFm40C%2FWaRcikzJbSWfPzuXKqQ0sxKLdfgl3BF0A82brsgaXLW7gB12EPzH7oTqxuZWvZKtp73M0Tm%2BPz4vvlDUeOLdxZwVwPk1KRVS2cQX0ce4s4n%2BRlpKcHICC7LeCGy4rdAbAELNlGX3ZNzCdRYyq%2BuhvwVHHWrRpn%2BIvGGoVFl%2FMhDadWMcJP9LZen9cr%2Bdin7JuOx%2FZeN2FqnzFL7767DtWvZu2f2TrnyermlsJrn977BC7f%2Flkz5g4srx3e8%2Borqypveeqmzf8qL%2F13n8KGgcUDKqrHbRP6FwNIYiqrimdLCgBFNBhVKlHOuxSdv3y2lARgcoLtYrOlOn53IGEMEF7k%2BdXC13JCQdThQHSbDQaX08hRhsdSYuuXVBAOtyLx4BHI6%2B6CYLnlEXbyLfYFex%2FD9zz7BAf0ztqVZ%2B7EwHn6YufCPz33%2FDraBqjXfyHBI2K%2BRonRKAOiVZYkC3BDJ%2Bq9VNpUJOaj%2BsXtVx6h57CC2dmLTMMKdPlKFXO0a4DY%2BdTwvZeN%2FqJLhrqRy8gSsx%2BT0e52yQh%2Bv2ynlszMrKwci9mcnemSzdRvt6NJiOSi%2BEtCbgo1UyM3WkiKOMKJUtMlGvCIi78nPihD2fPbzWFJ6WPdxqngfix9q9Sr9HQdwoJDth5mUy%2Fnm1hKoRixV%2FmpUJxwVT85trLi1EAa6twb%2BaS%2B9uuhNBsStmnSbVMVzTXLnPpUo6oYTYpJ0C2VLGYDkWXJqFCUkhDL9evG%2BooUZ3VpjZj8Izex59h6fnXg56wfNmF%2FDGMtC5Pi%2BGHyHdka%2F47Y4j27dJCYyF2B7wZVlZEQEERvNFFF4QqiSgVDdslOjEH5Z65AarLLowIDZAGWchEZbA%2FLwDo6mozsXBTfQUqoXleVJiZ0RugfzTJISFUVEExmlYuSRP1I0IAGUcZdOgxNpl1qFqqPbALSzPPvkbfjTVJ6vIrs30m%2FRXi%2F0ykkLWUbyWw9T7KjVgXRIIFRJlTBfN2EuvH0BNZX4iUpmc0y8bOPPmIblXMHz60Xa1gA6MDkVFt%2FZIKYnGpfnBa6sUmAHY9%2FmJhqI4S4fJ%2BQL55xoKIY%2BVYNoOZTiaaCvQtCfCFHMMy1CH34IX7GMmfKjQd%2FUoR8AzFIA%2BR3QIHeUTdBWVYkSTznFd6SVJko0DW%2BxLKLeyTRZYcwiGjADQ%2FjqVO8uP6KGOiGzmqyKN4maq1OtpHWXhja9SRIRonoRhEaJZ5K0NrOFyl%2F%2FvMAAGKNdIQ%2BqATAwK1gBjVKRVTIdwCUpB%2FrioP0XWLww7EvHPD6PGRL5ZkqbKpcLx3ptW2gZ%2Fz7GYIdmjju9pfm6E8Zq6OFTovBQvLy%2FP78LIMhaEkbFrNYZLfbPjjm5jWdnDM4JnvBk0Az%2Fy%2BZVYSeXlcUJWdMvMcN9%2B1u8h0omny9N6YT%2BhuGr1r0xzd%2BOr%2F5xbv%2FOn7T8Y9PswO%2FX3znY5MWPHHDsNfXvfono1K6rn7f%2BK3vx32E27h55MJbxwOBFVznDsUNTsjh7BvIojRg1Mw2n89szrWA2WPUFFDSh8QUL7iGxEC7mCz83SHi7H5mUeZ0aISzRVANCgTlw1AfH9d2D8WobftHX%2B7YNsMT%2BhpLLZbJM2ZOJJNvaZk%2BQ5rNdrPv2XH2t6XzFTdbPuiJ9jP3rwh0PPOXNWvWAMLoCyfoMWk2eDi6esRYymclxCubh8RkDexcM%2B%2BlZZJuOTk32SdwmnJoYkjgUBQyIf4DZqJx81Mjh9525cmTzcuHVf%2FBTQZgFvauOZFVwBH49ZIydr4kH4iQK81M2CcaDRi9Gi%2BobTZhqFy7xwIOIyi6fTTdPt5ft4%2BoT4Q%2BecShOXlPGioU%2FBLkji3iOnVPiAnZ9vHnOw9ON%2Fmw7Jv%2B1omT5kyVp7dNmDnLjWVoRx7zq9vG4YSfTjyy5vt7ViWNk9BynD61y%2BDMEKROSUpzOLKcJlOm3%2BOkzuoYFVUUVMesmuoZHFNTel5aloiry3bI3RbgrbNeR4XKwOMJ6AVAxMMtOP2GaQZcT2aVs%2B%2FY3zDt7LdoiJfID985vmNc3Qb61PyZM%2Bd3NmAPdGAahth3Jx%2B789Eel5%2B4rCjB7nSOkgMeuCKa7SZElSn1%2BqwAPhndyHVz283akJgZqJ4bgp8v7QVDiRwWFgxH9KfOeieocBWpiZ1l%2B9eu3bj%2Fufm1o2uv6ocGOq9zCZ23rKHh3ZdLPsoafsVgoKAwtzSV26sYyiEKd0SrzFlZAwZIfRwOUqzmSkGUpIHpPXr4fJFg8Kp0K1jRqlj7qv2GxYy5Eke5wr7FpDpWXFxYWDksVqi5e1fH3BkXz%2Bn4pxIOWz79gRHv0LneqJs2FQ76ewKfPao%2BpSsqEvmsj%2BykQFfCF6ZeRcGFyUQK8v26El%2F4WGzqS33OfxjpXbL2ndc3sTfYvm9%2BvP3WksHVg5tvOnmsZKGTFc2buvrNabOfa5w5%2Fdrrmura10otT%2FceNqZjJ5Xzew187smt%2F1i1bPw9We5Roeh1xYVrZ732vkM6L1UOHVlb2WcEHT5q0qRRuwBhBYC0lmeDB8LRdATw2Y0Wg8Fo9Nolp1MaEnNqJkCjR6D%2FJfU5336yUOPaKqJJEuCQeFQirWX7O%2B6YxfZjqapqE%2F61bQ958LsXt8S%2F40CwpeDekav%2Fvh0ILAPAD7lsA1jEZFcyGsFksprtJg9Rr4kR6DJ%2FZWoO7uobKtNnnyJUlrW3X3ttO14phMgLHn98yIjzPqkFgFxoY259XSt4oSTqd%2FL0JgaDT%2FNcE9PAaBctOk%2FsjOTEKYEwCRGJxwB6tajQpMDBcxoHXzN8CJbum6GLZe60066mRmnd%2BeJXN6mThXRIWPMH%2FUn%2BNdGgxLmTUKrIsmYzWa0Gg8lkN4P41WCzUcXkofbu2oTf3cjSZdpuokXRuGOyi1dx22KswGZWhYd5AffOIrF9jYxdh40sI74Et93MVivueDXr0gYPcG0ouF4DRIkAevQioLvExgPivyvuhO7qQJ5BQRgeLXS7XPrsKDMzI6PAajSaTPkuq9WRKzu46XwOzWzPRJNH7%2BG7krl7%2BOC8ePqbjJDCRIiEfKFykdziVfBd8q%2Bke9n%2B%2BuvnTGL7vy529F437Xwso%2FdL097ZwvbVXz9jOnlw3rz12%2BLfSS1Lh1%2B%2FurZpy%2BF4kfhtxYuQjGCut1tMFxHAq6vrscoOoatQFU0Xx29SyV%2FXLRG8TS0ierkyof%2BZtWWXEPbn7boC9dce3JHE5yf0pzhpostXLJYMcLnSvcYhMa9mp0Nidu8vu%2FxUrvPeVQMOCCQs6MzrxGVT5986ecr8W6dQmX3ELvzxh7swGyl%2FI6Xt6%2F70Qnv7mhfYKbbnQTS8jE7s8wA7B4LrOep1cC1ckMMn1Hl%2BRVFNlKpZmqrlcuQEq9U9hBOEwa5mQEaKzBKmSBWoSQVlTvPepDFCnPndRKFJtuemosq2GZrG9p%2FtaZv8wfaPbt58TGf7vePdSx%2Fwsv5K9SPtbB87%2FT%2Fs7H10mU722JDgM67pTN1euaIq8dIsyh%2BTpOUZ%2Bfg6PcNnz%2FZanE5V4I0FhsQsv8m6iSfIBUmS5S2dL8HBXl8ook%2BLIkFBaLdMkafPPzxZ2v7R5zsmPXeFIQMJ22e1lq48uri9oOMZ9uLa9lNYiho3Z9%2B6xqU%2FbcBDAybXN3ZFFJ3LddVEh0mcejw5BCxZZVnUS7wGFxqlMrTMRy%2BJIqpdWewrCD%2B6iu3%2Fsre97yvSbCP7xLR8SXyH1LKxZTYkqp%2F1XIZ4dpmjpLktAEU5bnchWNw5lhxTli9rcMynUdPgGPX%2BvJ2%2F2BgiqPTHK2HB5clePsGgXCkPt082oetPnbx1%2FbDrDtW395oycuG8yJd%2F3%2FXu6MZHa5Zcv2zRrf2wZn1HILfzsvKx%2Bb0rCstHz73%2B8VXN%2F8y%2F%2FJriK%2FqHR%2F%2B30LeE6xuRa8AjToRYDHa7y2UyEIfB4fWZnHbn4JjVYrfL3HVyQt3QpktOVnRhgnBcxKOXvoLpIyFPwCO6cjK3bsas9tdeeHRt8xasYDuu%2BTD4aeiNN0jGwgknTn4e%2F%2FyqK4UOT%2FGc4zM%2BcENZ1E8cDrfby3t%2Fj9NoJ7JNtumyPcmJ1sVDgItr7tQYgH%2BgrxdrpR2zt72PpSLjsXRp7XUHt5Mj8dki4Ynt%2FEpI9JkPcrlm6BV1m0GWiYgIK0G0GNEuC5llKWndDU1X%2Fx0SbTfiOtaElf%2FINyryZYexkjVJLfFF86aMXUzaumS4AZRtXEaWOMsoSyaOIVng81ETVTMyMjNzVEXJ9plMVLbbMxQ7yDqidR3RdPz2LIDSIO1WQ8wBsin%2FpGskRZpuUfew19lm7LMwJ1eRcrT7sG6R5NCsqBgvN92NPdk7uARPdt4vtTDH4m9q1lxH%2FPGvvE03jMkcer4XnuKKI5gApOW6bWqi%2BYoMaKSUSAQlGWWzQVWtfIZmMSoUAA1mj4T2S2cBqaROkYZeq3KlhdkClOu%2FmD2BI48cxZHsMWxja46fYO2kPwmyZ7A1fiy%2BDRewhcJLzK17ycs1KTC73ZrXK0koahm%2FJgob%2FpNT8no0p9XJMTHDAFyVskQJkKKvhBlTUzxHyokifvTqgNsSaw9mmBRz7n4cwoqu%2BvcfR9RErqqfl%2Bfkfr2%2FYcZNo8ic866XXnR8Z72xNZI450HXce2MIn%2BoKqkIYDYgmvQhAm8c7YR%2FMwyOoefSIULSSMJGySlCWEwR6LrOB4nC0uhAZiCmDrLp6%2B3xekDI4T38Id7D54ipCHUbcnIcfn%2BuNTMzIFGXy8qjKd9qSbTzYosp2hbbF7bnuBrm%2BREWRw08Coc18VTQ4xFQ6%2BEJhDmL2m6%2Fc%2FOZG4cpn31T3XpmM9quH32qucGAVz7Z9jEdXMUObcyzBF8xskNVg%2BknbU8BIO5gJWSlYgMK7tcIpZJMAaCyhONDYlbqCOKOo0cV29lA1ylOauB7yBN7yOHlOmgGQ75bkoI52TabW3Z7qCzl%2F3%2F2IIuHzuFynuSi2BZnlftyiBSnzxyCyzwcrImh4e0Xbhz2%2B9mfKtWtL7xTP39x26LeM2aFPyFVQ7CnuWmyw5K3EXsOrqIfh2dPY5tNjY2nGm7QTxGQIqmCtoEHIlG%2FAg4zmKnd7qNeu82mSJSaHQ5QoCRU1lYi9ElBdqqp5pwa1sv%2FRAMmELwQB0baym968pqFwxaOC99ePv7pgf89chFZcXX5l1NzcyPRii%2Bnphf8lzhBwpbiQanl0rP6Dg26zurbad4v56mukCugE0Wi7Vh7JsTasSV5lIO0dJbKBcljHAhLOdJqfN6cwad7QYchPV3OyCA%2Bn4mYMrPSXCNiBtuIGMiGNH4pGWmKygXqpwH4S8%2BePzvOII575nOCTh4R15lS69q26gmSEBt94OCr7YtF6z7vlm8b7mpdcN%2BrL%2FfHcyhjZk77c8arjmflv%2FBn9kZObzbAuFFEB4A0ST%2Bd2BztZXeaidFqTfd6iV%2FzO51ado7Fn%2BavjxnT0sDFqcleG3P6QR7xs%2BNNXUfUIJTSVqjbjT%2BpBpRfbpXXFSKawsFwiBuQbNyyZcyzs2sbcS679w9k3%2Fmvbhr%2B6qufy7sbvojGrt10dOm6WtZ5ttes1keObtl5BAjMBCYFpHXcnkW8R87TLC6j7EsnBrDZ8jIhM%2FOyYp9LSycWo2xQPZ4ctYBHz%2FYyHc11H2qb9S%2BiA4oURXyC3SM%2B0WGqPrVIoJJaFCmMXFRdbixfuGzBqEk3j1qwfGE43Pbogt%2BNn93Y9siC8v1T6%2BqnzxxRO50cnPC7BcsWhCMLly6MTZs8uu2RtlBo%2FiNtYyYOnz6ttm7aDBHpCoDEp%2BPghZnR%2F7I53U6Plce2UaYyMYkJqxeRED%2FHBp%2FidDkbYkCRuuwmm93WEFPtdgt6FMsl5xX9mtiW3kNfypcpEhAfkgPKkCfoEXdAGF7cGCBD0YAVbOGWH374gX38448%2FvsOW4BViZBv3vHrfq8eO8RdyHMhFiKNCMGoniiKGmUaJSlTVsUcEbCpFdAhyJGBIAFHnAbag8wAAgUm89lnw%2F0o5D7g2jvTvPzOzu9KCJNSFaAKEBMYHAokSuQpiY04OODjYsWxCcjbkNaluuPdyiXuaS0jHpPfeE0N68fVO%2FObSe%2B8uy39mVlqEzr76oeyi%2BbG7U3bK83yfkUZBGZwCMyKlaRaXRRTLC6E4JyfkAld4DKmpsbkrK0ttpSafxzc15nHqTVNjepQycUvmivi5NiuyMYtA0qyNo3NOVr9OFfZJmt75WUW7VMhOWtE4fsubj9zRP33SzuaW6LxFB3rWTJj4xSuvXdHyYsOAb%2Fbpj257c%2BOS5s4tvmrim7appHXPputbn8kPlVdURssit194%2FxklXdGr7p3261Hh7uKKUGH0uu2nzi8Pxya1V5qmAUYu4UfygiRwVi0%2FYrQaWIvIdGcQ4pBB7dzU9snCdpLZJF%2FSOXJNjdRPPa0uMhVd2TKurqk5Mq5FXFPXEB0%2F7ucNExvqGieOb6wDIIw7lSbR99oBPqhmvm9ikm0mm7%2Fc7yzPc%2BbV1IrpYEmnX1mlhbZglpActKMVbEo36zBrHWyifBGnSASrw44ZvIhr6bwgFCxiuH4R45HIul%2Bc91p4c3j55tf%2FfvilPddGFx5b8zJqf5X9DCi9v%2Fm10vvcrj6U09uHsg%2F0Ke%2F29invHSBfX7VJ%2BTAv99nwkcNvfNd82xjlI%2F4%2FSu%2BrLyi3%2FObXaPaLTJb0b6xlBfCX%2BDHKMLqgAOoieZk65HLlmXXU56PLK%2FRmGI2e9HQbys4GEGweShSEA0F1mAtak3BQbR1SPGxVVo3K6irbp3YM1ToJV3pGr452r7n58XnrWi6tr79h3tY9yqTy%2FKbYvMvxsYvGRLrPu%2FBCWegef0l%2BcNcmpeGP%2FqIz6oqkNPas06Fd6BEEkMAIbZHRaUaDTKd2RMKCgERqGDdkGNkrBpBGCE4XBIMoIpOMsR4lWko4kLBqJI%2BK5j8Faab66Q897w8yR4ALIR3yqYfpaPGg8hFyDSo70RG06A12%2FoayC49HL1E%2Fs9K3DL2QNXzKGb8fhTCZCCJkRZgzSkcQkogAAdYJoQTf6LXQWZQQHjx2hLz1I7pgEIaGErEHWAIzAAhaezTEW%2BS5kUqBYFHUgcViJEbamxB9uT%2FROLFE8QLBIegdsp5%2BnaSN8spKbara53ErgY4FlFnoIwadmhP5X7VaYcvuz5QHAu8h%2FcO3K%2Bs89eFTJuceP%2Bdft9utd0xUFqDpyj3kqh3K1%2BH6uhrlzX%2FZctHQEckuSNLhJG8MjPTGCNLRbwWDZH%2BFr%2F6Jm7D5hAmyIDMiQ0ZGTrbVkMkqRQ3FUq17vL06HSowmDyctbXd2N5201ln3XjW5a88G6uvnz2nLjJHWMg%2B7W0766bZL10emd02YWJ7G%2BNFAYSwiCGdcx%2BZGTqdRB35BoSomd9sMRrSZYQkAYOKeoYC8S5MM5WnxriwyfZwnAs9I2%2Fh3kG0RVlFY12UNylYiiCAo%2FgZTriVRKwOA5LAgiyuTNnkwQ4Hyucer4lJXb96j39EPHUF%2BJnjK%2F5%2BbriipGXeqiuf3np9%2B4YudA6O3jbYEQv6S2bt37Cle8be7rMBwVgcxo%2BIr4APJkRy7enY7QbIl%2FLTzVK65C8mdrvDIed4PSa5IIE5pbQ8dlABTRX6S6xu1DgHrezj3QjuuaN9%2Fn1P7N541ards5oXtJ3REgwFWsOdE%2Fb9v3W9wlu7a432i6at2N7wzOzzq6tvrAr76ePuDExYn%2BqLI0JEDyCnCdwXdyjui3uFjR%2FVNMjMIUk6ao6YiGZWHZ0i%2FDX75U5H1aEgAOK2LmrkhkxmMUmXJFnOsjrBQR%2FdrXNlOGl7yiCq4Y2Z%2BzTTkbYwT8qwtv73xo0CxS6XhZtDZ7WvpVaAD0ZnlC6fNWF%2Bvigy%2Byj67YoVdz%2FPrAF7Z8wo%2F9mM65SDUhQQLFSOCbslO2RAIOJINwsiAoTMFr0emUykKWYSWc8XiHtk4gMlbe5qgAb7UsMIa0IFwu6bbumd0PqX1%2F72IW5Tjkmn%2F3QfCVmPHEWCwiKd8Cj0e7KGEUURmUU6Ebk1RiCQCHSypSLhfEr%2F%2B2Eqe2hQsaNeALBCVcRlNjI7Fh1Y7Gaz0W60ySYW9pXNXt9QQI0EXB1%2F3PjAIiZPQYprQ3RWgnr3Xd88KXuOu%2FGW5v7s6Kwj6xc5btOZJpzh7hmf2cktXDiKGxPRSYI8MjopD%2BWfMDoJeePRSb4QbvyciNkVzReismdxFD2z4Oyi0vHr6MwOwnTUfEt8ic9KPBFjIvYqgzhkDw%2FxTGK3kxc9YlKPgt969IarH3%2FwwP4nFG9dY%2BPEiY2NdULbnf0v3Hr7wAu3dHR2dnTMm5cy6s2OlKZTy49OL2AW1Ib01FNiGh70BD7YIdHEB79%2FOej1B9UBL%2B6NL0aoFonqQehRdg4ip%2FLxIFqsSMPn2KuMXYbaUNsyJZw1fMrGrnIA6Qpa2n5Y%2BTuAYvg1fgUA6eAP5Nrjj4L8IMFW%2BuJUVye0D51Au5h8T7W6B7CZSZlyNlXeJ75ClUs8XEnM8as%2BEb9qmXpVwDBeWUH%2BLLTzNU5DpKiQug4YJk0jh0pMoyDbnI1lQp0JPk9rzJdhoRy8xZvKwaN4g9Cm5HHsnddbrUub3bCVWHLF4ldiF1wYPjM27aFzzp37w3lvHP3F7rOrUcnw6jY6d1dT86yJ4eiY0sOnTO6%2F%2FYLru%2Bj0cyyamXhHhoZU2lu3GPuhiOexHiQ0HfQPYqfoh9HVJ1B0w2%2F%2FheIgzFQV2SMV52iKgYTCOlIxU1N0cUXaQwR7uWRYkxbXSNDfPYvXhpfEa4MpdD7OPtrg4sg4yUbMNmIRLCjNZEJsvgbgEETRbiYUvqb4syENGQkj%2FJFkkzkxTAQrMmlscsKiQLvUAAeUNb8G7yQ062PCs0QKkEYsI9rR6nzH9imOvcoLeLew9%2FghbKIUT%2BhoLlq5jiPvcYqZDnXNrC6WKXZGjNP8%2BVlGYAXOBfY556p5%2BZaodTT0KC89ZE%2BUXqqiG9pSFPdShT1JcXDoO1XhHnmNmZqia%2BgnXgMYFag1wGbucZ7cAJnQGCmivUCW3ep0GlBamtthAIqVWwGovcRJi9eKLYy8TgmP0%2BBgddahWmkscQqUlpiPo4MhBwPPA1tV5FzFz7cKwm9%2Bd%2BCzzzahATIdd1Du%2FG5GoOPWnR9%2BofQoyl1qHsRXeDuriLez36eUA%2BdUeTlUxtt7N1fgvJMpulHDv1AchOdUhXek4hxNMZBQZI1UzNQUXVzB2vvoeGkj2IAMglnogXTIjaRLBGTZYORGZXcgqMUn8260FqnLBlSM7lL%2BuB%2BVocqr6Rhetkf5tfL7vfj3qKxH%2BSMavZf%2B%2BVuaSiUAhD7DLeIHkgA2yIZCCEdyXJ4cuz0tB9LAW%2BTMK3Ab3QxXJQWpdOWImbyK8arGGFaJqpEG2V2IO%2FyqihEFV1Wm94Xts3tnv8iA1RevaL1x1sDRP56CjrR2UWL1%2FZBiOG0%2BWqzyvXWXXHDpANrEwNWGNfM3DSi%2FfHYJ%2Frbsp%2B8e6j5uKR4aUmlIXgO18Vocrdaz1uOkKrqR6V8oDkKPqsgfqZipKbq4gr0RJcl9kqDwq4yNv3kb1KtYuCSJSmbrqZpIDiOjjbIoSpJTMDbFZEdTTJAFWdIRyZowKGrdjOZBjePIDroW0tZGwh2UUz1yNcPaH1CQ4fikjst3rbt0NcHv%2FagMUij5c2Vc18rz5%2FNZJM3JfMkD1dAaGU3tegXFxQDlWSZTbXkgUGPKKtBBcbEui2SWhkqnxEIQcFgyozFLwnGq7ZUx0g03TH%2FaTYLqcnOkuuX8iaFL8zhXsVAn4a3SSDRSWl1%2FRVfoo3fmXTau%2BubIbfnTo2vnNjQ0TVjXsWQjbb4%2BhL9FfuGvkV%2BcNqai1JldVTJn7srmu%2B7JLfy6KLhqVGhcaeOylsh5lbWnl49r6TrnKPVMv%2FLO%2FazH5ASbVEBr5VQ%2BUtQfAPb2jbbEazY1vfvCE6Xna%2BkHfxhi6RUj001a%2BkAasPTikemClt4lAX%2B3T%2BGCYcUDmqJ%2FlKrwqwogTCEpQjeUQBBOgS2RydU1JDM%2FP2g3GoNBuabG7%2FGMKZPlsC%2FfW50fjVVXsyDp7OxQNJZtNo6aSoF3p%2BS0NFDHPHgbYiBJgQZGv%2FERLZmZ0t5q6wkJKnqMhzBz8MufZG0ZXsZRzHYYrWJk1TDShwoZfiVWbn2rce4L19%2F03NdfPRtr2nHzvKc%2Femdx%2Fd3LDyM4XkaJq%2Bcfm%2FbY8bqFq1fv6FyOvX%2B1oHvwefbOru7Y0zcz5q91cn3Tq52bInXKZx9RCGvWp8UlOEsQzpxD6T%2F05acLVrNap952xtZhP0xWx0%2B0iY%2BfnCrjtT1FbQ2389oqStRWanr34n%2BeflDP00eNTBe09C6rWpeVidoeugYAvcGv8LTaXynTgF0DGRLXuBwA%2Fy5J0T00eaRi6JdU8UmS4qDyuqqwJBTvUMXlkqApuriC9Vdu9UkSBIfk5fPVpZGx4MYuV46oJ%2BkEY0tOTnr6qEKLpcQNmZh%2BSJ2ImdjppB56CnnSKS02%2BRpiJifBU2MEnYC8izsQ2clwI9I%2B1YYLf3Gtkw8SVgdtm4XAwyNdtX46hDAvXCL2GCmnN3ZetuitjjuuvUr5%2F0PfKX9DwuFDDfpT17zfga0rz19x8fIFq84TXdXF99Wdtr1n%2Fm5lz4fKh8pLyPrJR8gyV%2Bhdtuva4%2FMv2Lj1ih27%2Blg74MwMf2tPV9%2FaEPAZUHI97ucl3KK2k5t4PReeOJ319ZfAyRW8pRiS%2BgUt3aSlD6jpeSPTBS29y6C2pIDWK8yCw0JYeIl7wbKhNGJ1pqWZBQEIyYUcNwVKAXHz0vPBYdBQiw8WTxJRTWOGj2%2BK1tf%2FPFpXNzVaf2ojO%2BKOwcEvTpva%2FPOG6c1EmNrUMqWhpRkIfcaHKAN0OZ81eEfOGnzxWQOjb0jBFAZx%2FC%2BzhmCNsJ9hQWsvOLVn0n5GBm1eUrt%2FzK5jR21o%2FOiJKy9AhwzKa%2F6alefjSoYJlXV2dVyL7IwUqpp%2BQes1ytH2RjTouvnWlnFKMOP2oSGVpeD1c2ZST4ByefGmpvMavgVOruA1XMnTC0emC1p6V0B9A0u1np977PkV5qi9zXh%2BBQ8XJOgmziYWsLhqD%2B1vHQZzli2Dxi8VWsCcbXDIRM6dEpOdxEnL%2BCQocxLLTDtnDWdWTT4Wyh0nAU7ot8Herhf%2F%2FuZLf5xv0ulUfvGjOONEDrXMYEgzK%2BCtE9qVsXpQVixvbB7mnLQ8CVqeut5Qc%2F0zNdcJKk9oH6byMk5M5VGJGk2mO108BE7wQmekxuJwGFF%2Bvs6WAeDL0umKLHa6drMgI7HQX0YznaWSNBddcwhCLotpRQ5tBcd%2BThplmiAy%2BBMMx2M6XcOLuERnVGvx%2B3WnH9vn31Wm9Cv3oTPQhPGbvaRDW9Q9dstdd%2FXVrfR7t8jpaBvqQuejTSZZXeCR145%2B8%2B1PDivZbnPyN%2BhT3SphMXhgNARhQWRMoMKEHQ6%2FX19RkWu3V%2BXr9aEchzvgiMYCATCbfxaNmc3YJNDOmfLEZnDT4VwQvFNiQupwHj45Cp00iOdT56kG4bniI7dDo6KTeT2fSk%2BLtyhf7dl5pPfHLSgb4QUvT7nsi2%2BR%2BbhTt2fL%2BU90tDx99FwN5Pu4fbWMBnC3%2FZprdiD9%2FciByqY1XcvYaf26naXlbOCeHGf7BhavuJhFHD0h%2FFXwSAVgZP0Zi5ozAMh6jE0ZWF4vsh39sg5pyx2NKqQzEZ2XGU%2BdFNAgrdc1Ne977elTUafn6kbhr2ed0XJ29tMLqh5sYBENqFX4M4lKD8Q9ehmS1eqmkUWyR8ay7CDxvRTYHVKNZ7qk8YhEdy1YcOklCy%2B67Pqa0tKaiorSGvGlCzavv%2BiCDZu7ykKhsrKqKkDwa%2BHPgkEygQuqIm4KNEUEQjLdBhvobPTrYvM6MzavFyCQ9fpZmoNENQebXw6qkISXvbF5mNVHiE23yjF6xRM27knfvXTUtKZoET%2B%2FfAk7F%2Buray7vKyjOr%2BKHAr4bGHqI3IN7%2BG5S%2BAS7SU0nbeih999Xlbp%2FqtQllG7Sj%2Fp4jIw7kiaIOqTTySBou5KZB5gLq7jGWhvCumKTs7N6sN5L%2Bp1zkG2h8t3HkHQFCVwRmQhIknSCRC8wvD8WUrffQHtNwbWDkz3iI84XlPdRySFI3luLeVIwEfnuWhIEtNuffHstwOzeZBl%2F%2BgzwRczUIGsiggSSZNFlkHRtI0Z%2BoT8E%2BbOoWSnwxY%2FoUzVPdILhSZyRP8ezp2Vz%2BE4SGJn%2FndpNDXwrMFMaMYjsRi%2BqN9Luoz60qB5QH885cqO31JNM8Ua1DBJFgVlJkOt5SRihMGIaeQcIpN7Ap91gROGgt0eWkkvbi2wunXrfKIyCdLA9wszuRplAgHssUq3uc6%2FavnXvvku37cGf9hzou3r%2FLbcAELbTizQXhfm75mXsYF6m6kEvys4gbKuXAofMQuS5LUhtbJnmP9AJy8gdX3yp56m7v%2BAps89kZzPacGPqPmctKUf%2BVkA7vpHbtCsijrgDV9RLQAg9pa0JI9VZmsxW0W%2FVN5vqlE12xKZeO24nRzp2bfoHPRPEf7z2SBs4vvHEBm8ApCxj83oe25YVSSeAEcaCFtqW8B8j5EX48mN%2F%2FIKMjge2AeK7BW0S%2B6EYdkQaJaL3%2BXI8RW5ntmywWIrSafaLika5cnP12dklBpdLzpRy83Knx0heRt66PJxOMvMy82yFPiiEabFCndlkMzXHbNp2YiNNoxZenyxzKUghO%2FCtQOhvro%2FH5DgKdA420DrVfS4oWELdb%2F7qWvq7BuL7XXhXXu9CVyrtGKN5yj0hZNq9ecn93ynPj9q6VMBLtvjQpG%2Be6ps7ebnwys5f3ucNFDzwTXgIxqK0Tx5wFVff9zVyT%2F%2FQ4%2BXsWgfzjp%2B0n6MTYDbdHRriMbs%2FSh7wQyNfQ04lboD45x8nfd7MPgcMBhzF34tPQRpYGbthFXUmWnBEBixim90k62TJikTRaiW6PJLPDTwBLSYu4RpNwn%2B8DhpfWI1CfA%2BzWrZnHP5%2BzefKBrTh0zXKHkmuzliH39q3rwfXHT%2FUN3Nu1gWuZ9Wn05u0pyuGRuJWn14KAMTT4QTpzcPp0q6k3PF0dS8BvtMDAcsjIIiIQGKXQLYPAt8FgTU2uvZ8EQDruB3sL%2FEV7krVDmZIWNNupYoPkxTdQ3NGKoYYgS4mKQ4q76sKS0JxHADfqZupKbq4gq9wuaT6%2FwCVeR0IAAAAAQAAAAEZmiehT9dfDzz1AAkIAAAAAADJQhegAAAAAMnoSqH7DP2oCo0IjQABAAkAAgAAAAAAAHgBY2BkYODo%2FbuCgYGr9zfPv0quXqAIKrgJAJZXBsIAeAFtkQOsGEEQhv%2Fbnd272rZtG0Ft27ZtW1G9dYMiamrbZlgrqN17M89K8uVfTna%2FoRs4AwCUGVBCU0zQl7DAlEIZWoPOfhXUs0BbVQAL1CG0ZepQd9STPdUW9dQ61FGN%2BU5LpOW1pswUpmU0hZj%2BTGOmWnQ2lPNyV2rEoO%2FA%2BmUw0CwATG8cNjkwyXzEYZrG9Of5NUyy%2BXBY7Q4Hm9a8tgCH%2FWU4bOcwPfmsjc7GvDcYPWk7StjU2G8qAf5xwHQE6D%2BzHRXUbqzi96bmrEQNEeim4V965jWnB%2Bho0sNRHnTn7E5H0V3nQAlaAGsawqkxWKfGhDPoO2Ts%2FGdwsk5fIecd011vh9O%2FOaegHO9toBWAfYLM5JBSxvoNquliyEeDvUucbeXvMd55vIqRtTGMJTnzAkP5bdnsXvTX6VGOPkbfYe%2ByRgh%2F6xHoLms6QDmmlvyFPThTB2PEtbczfMbr3XUu1JD7fmqUjaYre68jzpPD3wJIH6QH0RyQ5L6Ui%2FGeGFqDOZLiPj7iXnpkDsKJ5%2BTwO3LmEe8JYecb2fcazoXMC%2FEd4z0J7EFS3MdH3EuPJJX07gom%2Bff4%2FDMcpS1ee85bBLQNGO84cgiqPerpVcghUBEeK%2FS1jzBBfUZbwUv5X%2F7bkOlslqCEwJ5TBw4lBFsBJdRuHA4vYk%2Fown8RLYvLrQAAeAEc0jWMJFcQxvFnto%2F5LjEvHrdbmh2Kji9aPL4839TcKPNAa6mlZUyOmZk6lzbPJ3bo56%2F%2FCz%2BVaqqrat5rY8x7xnzxl3nvo%2B27jFnz8c%2FmI9Nmh2XBdMsilrBitsnD9rI8aiN5DI%2FjSftC9mIf9pMfIB4kHiI%2BhWfQY5aPAYYYYYwpcyfpMMX0aZzBWZzDeVygchGXcBlX8ApexWt4HW%2FgLbzNbnfwLt7DJ%2Fp0TX4%2BUucji1hCnY%2FU%2BcijVB7D46jzkb3Yh%2F3kB4gHiYeIT%2BEZ9JjlY4AhRhhjytxJOkwxfRpncBbncB4XqFzEJVzGFbyCV%2FEaXscbeAtvs9sdvIv3cjmftWavuWs2mg6byt3ooIsFOyx77Kos2kiWsIK%2FUVPDOjawiQmO4CgdxnAcJzClz2PVbNKsy2ZzvoncjQ66qE2kNpHaRJawgr9RU8M6NrCJCY6gNpFjOI4TmNIn36TNfGSH5RrssKtyN%2B59b410iF0sUFO0l2UJtY%2F8jU9rWMcGNjHBEUypf0z8mm7vZLvZaC%2FLzdhmV2XBvpBF25IlLJOvEFfRI%2BNjgCFGGGNK5Rs6Z7Ij%2F45yNzro4m9Ywzo2sIkJjuBj2ZnvLDdjGxntLLWzLGGZfIW4ih4ZHwMMMcIYUyq1s8xkl97bH0y3JkZyM36j%2F%2B58rvTQxwBDjDDGNzyVyX35Ccjd6KCLv2EN69jAJiY4go%2Flfr05F%2BUa7CCzGx10sYA9tiWLxCWs2BfyN%2BIa1rGBTUxwBEfpMIbjOIEpfdjHvGaTd9LJb0duRp2S1O1I3Y4sYZl8hbiKHhkfAwwxwhhTKt%2FQOZPfmY3%2F%2FSs3Y5tNpTpL9ZQeGR8DDDHCGN%2FwbCbdfHO5GbW51OZSm8sSlslXiKvokfExwBAjjDGlUpvLTBY0K5KbiDcT672SbXZY6k7lbnTQxQI1h%2B1FeZTKY3gcT2KvTWUf9pMZIB4kHiI%2BxcQzxGfpfA7P4wW8yG4eT%2FkYYIgRxvgb9TWsYwObmOAITlI%2Fxf7TOIOzOIfzuEDlIi7hMq7gFbyK1%2FA63sBbeJtvdwfv4j28zyaP8QmVL%2FimL%2FENJ5PJHt3RqtyMbbYlPfQxwBAjjPEN9ZksqkMqN6PuV7bZy7LDtuRudNDFwzx1FI%2FhcTzJp73Yh%2F3kB4gHiYeIT%2BEZ9JjlY4AhRhjjb1TWsI4NbGKCIzjJlCmcxhmcxTmcxwVcxCVcxhW8glfxGl7HG3gLbzPxDt7Fe%2FgY%2F%2Begvq0YCAEoCNa1n%2BKVyTUl3Q0uIhoe%2B3DnRfV7nXGOc5zjHOc4xznOcY5znOMc5zjHOc5xjnOc4xznOMc5znGOc5zjHOc4xznOcY5znOMc5zjHOc5xjnOc4xznOMc5znGOc5zjHOc4xznOcY5znOM8XZouTZemS1OAKcAUYAowBZgCTAHm3x31O7p3vNf5c1iXeBkEAQDFcbsJX0IqFBwK7tyEgkPC3R0K7hrXzsIhePPK%2F7c77jPM1yxSPua0WmuDzNcuNmuLtmq7sbyfsUu7De%2Fxu9fvvvDNfN3ioN9j5pq0ximd1hmd1TmlX7iky7qiq7qmG3pgXYd6pMd6oqd6pud6oZd6pdd6p%2Ff6oI%2F6pC%2FKSxvf9F0%2F1LFl1naRcwwzrAu7AHNarbW6oEu6rCu6qmu6ob9Y7xu%2BkbfHH1ZopCk25RVrhXKn4LCO6KiOGfvpd%2BR3is15xXmVWKGRptgaysQKpUwc1hEdVcpEysTI7xTbKHMcKzTSFDtCmVihkab4z0FdI0QQBAEUbRz6XLh3Lc7VcI%2FWN54IuxXFS97oH58%2BMBoclE1usbHHW77wlW985wcHHHLEMSecsUuPXMNRqfzib3pcllj5xd%2B0lSVW5nNIL3nF6389h%2BY5NG3Thja0oQ1taEMb2tCGNrQn%2BQwjrcwxM93gJre4Y89mvsdb3vGeD3zkE5%2F5wle%2B8Z0fHHDIEceccMaOX67wNz3747gObCQAQhCKdjlRzBVD5be7rwAmfOMQsUvPLj279OzSYBks49Ibl97In%2FHCuNDGO%2BNOW6qlWqqlWqqlWqqlWqqYUkwpphTzifnEfII92IM92IM92IM92IM92IM92I%2FD4%2FA4PA6Pw%2BPwODwOj8M%2Ff7kaaDXQyt7K3mqglcCVwNVAq4FWA60GWglZCVkJWQlZCVkJWQlZDbQyqhpoNdAPh3NAwCAAwwDM%2B7b2sg8kCjIO4zAO4zAO4zAO4zAO4zAO4zAO4zAO4zAO4zAO4zAO47AO67AO67AO67AO67AO67AO67AO67AO67AO67AO67AO63AO53AO53AO53AO53AO53AO53AO53AO53AO53AO53AO5xCHOMQhDnGIQxziEIc4xCEOcYhDHOIQhzjEIQ5xiEMd6lCHOtShDnWoQx3qUIc61KEOdahDHepQhzrUoQ6%2Fh%2BP6RpIjiKEoyOPvCARUoK9LctP5ZqXTop7q%2F6H%2F0H%2B4P9yfPz82bdm2Y9ee%2FT355bS3%2FdivDW9reFtDb4beDL0ZejP0ZujN0JuhN0Nvht4MvRl6M%2FRm6M3w1of3PVnJSlaykpWsZCUrWclKVrKSlaxkJStZySpWsYpVrGIVq1jFKlaxilWsYhWrWMUqVrGa1axmNatZzWpWs5rVrGY1q1nNalazmtWsYQ1rWMMa1rCGNaxhDWtYwxrWsIY1rGENa1nLWtaylrWsZS1rWcta1rKWtaxlLWtZyzrWsY51rGMd61jHOtaxjnWsYx3rWMc61rEeTf1o6kdTP%2F84rpMqCKAYhmH8Cfy2JjuLCPiYPDH1Y%2BrH1I%2BpH1M%2Fpn5M%2FZh6FEZhFEZhFEZhFEZhFEZhFFZhFVZhFVZhFVZhFVZhFVbhFE7hFE7hFE7hFE7hFE7hFCKgCChPHQFlc7I52ZxsTgQUAUVAEVAEFAFFQBFQBBQBRUARUAQUAUVAEVAEFAFFQBFQti5bl63L1mXrsnXZuggoAoqAIqAIKAKKgCKgCCgCioAioAgoAoqAIqAIKAKKgCKgCCgCyt5GQBFQBPTlwD7OEIaBKAxSOrmJVZa2TsJcwJ6r0%2F%2B9sBOGnTDshOF%2BDndyXG7k7vfh9%2Bn35fft978Thp2wKuqqqKtarmq58cYbb7zzzjvvfPDBBx988sknn3zxxRdfPHnyVPip8FPhp8JPhZ8KP78czLdxBDAMAMFc%2FbdAk4AERoMS5CpQOW82uWyPHexkJzvZyU52spOd7GQnu9jFLnaxi13sYhe72MVudrOb3exmN7vZzW52s8EGG2ywwQYbbLDBBnvZy172spe97GUve9nLJptssskmm2yyySabbLHFFltsscUWW2yxxX6%2B7P%2BrH%2Fqtf6%2B2Z3u2Z3u2Z3u2Z3u2Z3s%2BO66jKoYBGASA%2FiUFeLO2tqfgvhIgVkOshvj%2F8f%2FjF8VqiL8dqyG%2Bd4klllhiiSWWWGKJJY444ogjjjjiiCOO%2BPua0gPv7paRAHgBLcEDlNxQAADArI3Ydv7Vtm3btm3btm3btm3bD7VvBoIgLXVVqCf0ztXT9dzd3j3cvcX90CN5Snmae%2Fp45np2e356gbeH94HP8Q3x3feH%2FX38NwJwoHigQ2Ba4GBQCK4NfgxVDE0OnQr7w1nCI8P7wi8jdqR4ZGzkRDQSLRmdH%2F0UqxTrEVsbux%2FPHe8b3xh%2FlgglzESJRJfE6MS6ZChZJzkj%2BRouCA9GJKQuMhI5hsZRHR2A7kZ%2FYZWxldhtPDPeFd%2BIPybyE0OIy2SIrEy2IneSX8mvFKB6UpfodPQYeiOTjmnK3GOzsCPYpexaLjdXiRvBHeJ%2B8BX5Lvxe%2FqOACmWEnsJ60SsyYjqxiLhE3CoeE6%2BLL8RvUlRqJXWThkszpJXSbjkq83JaOZ9cXm4gd5IXKZACK4qSSSmiVFWmq0lVUtOr%2BdXyagO1oxbRSM3UsmnFtOpaC62nNkqbo7M60HPppfXaemu9j77X4IwUI49RxqhrtDWOGzeM92Y985lFWWWtcdZia4d10%2FpiU3YZu6%2B91j7rME5xp5szGVAgDcgBioDhYDpYDjaDE%2BAmeAW%2Bp8R%2FA5ajfCcAAAABAAAA3QCKABYAWAAFAAIAEAAvAFwAAAEAAQsAAwABeAF9jgNuRAEYhL%2FaDGoc4DluVNtug5pr8xh7jj3jTpK18pszwBDP9NHTP0IPs1DOexlmtpz3sc9iOe9nmddyPsA8%2BXI%2BqI1COZ%2FkliIXhPkiyDo3vCnG2CaEn0%2B2lH%2BgmfIvotowZa3769ULZST4K%2BcujqTb%2Fj36S4w%2FQmgDF0tWvalemNWLX%2BKSMBvYkhQSLG2FZR%2BafmERIsqPpn7%2ByvxjfMlsTjlihz3OuZE38bTtlAAa%2FTAFAHgBbMEDjJYBAADQ9%2F3nu2zbtm3b5p9t17JdQ7Zt21zmvGXXvJrZe0LA37Cw%2F3lDEBISIVKUaDFixYmXIJHEkkgqmeRSSCmV1NJIK530Msgok8yyyCqb7HLIKZfc8sgrn%2FwKKKiwIooqprgSSiqltDLKKqe8CiqqpLIqqqqmuhpqqqW2Ouqqp74GGmqksSaaaqa5FlpqpbU22mqnvQ466qSzLrrqprs9NpthprNWeWeWReZba6ctQYR5QaTplvvhp4VWm%2BOyt75bZ5fffvljk71uum6fHnpaopfbervhlvfCHnngof36%2BGappx57oq%2BPPpurv34GGGSgwTYYYpihhhthlJFGG%2BODscYbZ4JJJjphoykmm2qaT7445ZkDDnrujRcOOeyY46444qirZtvtnPPOBFG%2BBtFBTBAbxAXxQYJC7rvjrnv%2FxpJXmpPDXpqXaWDg6MKZX5ZaVJycX5TK4lpalA8SdnMyMITSRjxp%2BaVFxaUFqUWZ%2BUVQQWMobcKUlgYAHQ14sAAAeAFFSzVCLEEQ7fpjH113V1ybGPd1KRyiibEhxt1vsj3ZngE9AIfgBmMR5fVk8qElsRjHOHAYW%2BQwyumxct4bKxXkWDEvx7JjdszQNAZcekzi9Zho8oV8NCbnIT%2FfEXNRJwqmlaemnQMbN8E1OE7Mzb%2FP%2F8xzKZrEMA2hl3rQATa0Uxs2bN%2B2f8M2AEpwj5yQBvklvJ3AqRcEaMKrWq%2F19eWakl7NsZbyJoNblqlZc7KywcRbRnBjc00FeF6%2Fenoi05EcG62tsXhkPcdk87BHVC%2BZXleUPrOsUHaUI2tb4y%2F8OwbsTEAJAA%3D%3D%29%20format%28%22woff%22%29%7D%2A%7Bbox%2Dsizing%3Aborder%2Dbox%7Dbody%7Bpadding%3A0%3Bmargin%3A0%3Bfont%2Dfamily%3A%22Open%20Sans%22%2C%22Helvetica%20Neue%22%2CHelvetica%2CArial%2Csans%2Dserif%3Bfont%2Dsize%3A16px%3Bline%2Dheight%3A1%2E5%3Bcolor%3A%23606c71%7Da%7Bcolor%3A%231e6bb8%3Btext%2Ddecoration%3Anone%7Da%3Ahover%7Btext%2Ddecoration%3Aunderline%7D%2Epage%2Dheader%7Bcolor%3A%23fff%3Btext%2Dalign%3Acenter%3Bbackground%2Dcolor%3A%23159957%3Bbackground%2Dimage%3Alinear%2Dgradient%28120deg%2C%23155799%2C%23159957%29%3Bpadding%3A1%2E5rem%202rem%7D%2Eproject%2Dname%7Bmargin%2Dtop%3A0%3Bmargin%2Dbottom%3A%2E1rem%3Bfont%2Dsize%3A2rem%7D%2Eproject%2Dtagline%7Bmargin%2Dbottom%3A2rem%3Bfont%2Dweight%3A400%3Bopacity%3A%2E7%3Bfont%2Dsize%3A1%2E5rem%7D%2Eproject%2Dauthor%2C%2Eproject%2Ddate%7Bfont%2Dweight%3A400%3Bopacity%3A%2E7%3Bfont%2Dsize%3A1%2E2rem%7D%40media%20screen%20and%20%28max%2Dwidth%3A%2042em%29%7B%2Epage%2Dheader%7Bpadding%3A1rem%7D%2Eproject%2Dname%7Bfont%2Dsize%3A1%2E75rem%7D%2Eproject%2Dtagline%7Bfont%2Dsize%3A1%2E2rem%7D%2Eproject%2Dauthor%2C%2Eproject%2Ddate%7Bfont%2Dsize%3A1rem%7D%7D%2Emain%2Dcontent%3Afirst%2Dchild%7Bmargin%2Dtop%3A0%7D%2Emain%2Dcontent%20img%7Bmax%2Dwidth%3A100%25%7D%2Emain%2Dcontent%20h1%2C%2Emain%2Dcontent%20h2%2C%2Emain%2Dcontent%20h3%2C%2Emain%2Dcontent%20h4%2C%2Emain%2Dcontent%20h5%2C%2Emain%2Dcontent%20h6%7Bmargin%2Dtop%3A2rem%3Bmargin%2Dbottom%3A1rem%3Bfont%2Dweight%3A400%3Bcolor%3A%23159957%7D%2Emain%2Dcontent%20p%7Bmargin%2Dbottom%3A1em%7D%2Emain%2Dcontent%20code%7Bpadding%3A2px%204px%3Bfont%2Dfamily%3AConsolas%2C%22Liberation%20Mono%22%2CMenlo%2CCourier%2Cmonospace%3Bcolor%3A%23383e41%3Bbackground%2Dcolor%3A%23f3f6fa%3Bborder%2Dradius%3A%2E3rem%7D%2Emain%2Dcontent%20pre%7Bpadding%3A%2E8rem%3Bmargin%2Dtop%3A0%3Bmargin%2Dbottom%3A1rem%3Bfont%3A1rem%20Consolas%2C%22Liberation%20Mono%22%2CMenlo%2CCourier%2Cmonospace%3Bcolor%3A%23567482%3Bword%2Dwrap%3Anormal%3Bbackground%2Dcolor%3A%23f3f6fa%3Bborder%3Asolid%201px%20%23dce6f0%3Bborder%2Dradius%3A%2E3rem%3Bline%2Dheight%3A1%2E45%3Boverflow%3Aauto%7D%2Emain%2Dcontent%20pre%3E%20code%7Bpadding%3A0%3Bmargin%3A0%3Bfont%2Dsize%3A1rem%3Bcolor%3A%23567482%3Bword%2Dbreak%3Anormal%3Bwhite%2Dspace%3Apre%3Bbackground%3Atransparent%3Bborder%3A0%7D%2Emain%2Dcontent%20pre%20code%2C%2Emain%2Dcontent%20pre%20tt%7Bdisplay%3Ainline%3Bpadding%3A0%3Bline%2Dheight%3Ainherit%3Bword%2Dwrap%3Anormal%3Bbackground%2Dcolor%3Atransparent%3Bborder%3A0%7D%2Emain%2Dcontent%20pre%20code%3Abefore%2C%2Emain%2Dcontent%20pre%20code%3Aafter%2C%2Emain%2Dcontent%20pre%20tt%3Abefore%2C%2Emain%2Dcontent%20pre%20tt%3Aafter%7Bcontent%3Anormal%7D%2Emain%2Dcontent%20ul%2C%2Emain%2Dcontent%20ol%7Bmargin%2Dtop%3A0%7D%2Emain%2Dcontent%20blockquote%7Bpadding%3A0%201rem%3Bmargin%2Dleft%3A0%3Bfont%2Dsize%3A1%2E2rem%3Bcolor%3A%23819198%3Bborder%2Dleft%3A%2E3rem%20solid%20%23dce6f0%7D%2Emain%2Dcontent%20blockquote%3E%3Afirst%2Dchild%7Bmargin%2Dtop%3A0%7D%2Emain%2Dcontent%20blockquote%3E%3Alast%2Dchild%7Bmargin%2Dbottom%3A0%7D%2Emain%2Dcontent%20table%7Bwidth%3A100%25%3Boverflow%3Aauto%3Bword%2Dbreak%3Anormal%3Bword%2Dbreak%3Akeep%2Dall%3Bborder%2Dcollapse%3Acollapse%3Bborder%2Dspacing%3A0%3Bmargin%3A1rem%200%7D%2Emain%2Dcontent%20table%20th%7Bfont%2Dweight%3A700%3Bbackground%2Dcolor%3A%234CAF50%3Bcolor%3A%23fff%7D%2Emain%2Dcontent%20table%20th%2C%2Emain%2Dcontent%20table%20td%7Bpadding%3A%2E5rem%201rem%3Bborder%2Dbottom%3A1px%20solid%20%23e9ebec%3Btext%2Dalign%3Aleft%7D%2Emain%2Dcontent%20table%20tr%3Anth%2Dchild%28odd%29%7Bbackground%2Dcolor%3A%23f2f2f2%7D%2Emain%2Dcontent%20dl%7Bpadding%3A0%7D%2Emain%2Dcontent%20dl%20dt%7Bpadding%3A0%3Bmargin%2Dtop%3A1rem%3Bfont%2Dsize%3A1rem%3Bfont%2Dweight%3A700%7D%2Emain%2Dcontent%20dl%20dd%7Bpadding%3A0%3Bmargin%2Dbottom%3A1rem%7D%2Emain%2Dcontent%20hr%7Bmargin%3A1rem%200%3Bborder%3A0%3Bheight%3A1px%3Bbackground%3A%23aaa%3Bbackground%2Dimage%3Alinear%2Dgradient%28to%20right%2C%23eee%2C%23aaa%2C%23eee%29%7D%2Emain%2Dcontent%2C%2Etoc%7Bmax%2Dwidth%3A64rem%3Bpadding%3A2rem%204rem%3Bmargin%3A0%20auto%3Bfont%2Dsize%3A1%2E1rem%7D%2Etoc%7Bpadding%2Dbottom%3A0%7D%2Etoc%20ul%7Bmargin%2Dbottom%3A0%7D%40media%20screen%20and%20%28min%2Dwidth%3A%2042em%29%20and%20%28max%2Dwidth%3A%2064em%29%7B%2Etoc%7Bpadding%3A2rem%202rem%200%7D%2Emain%2Dcontent%7Bpadding%3A2rem%7D%7D%40media%20screen%20and%20%28max%2Dwidth%3A%2042em%29%7B%2Etoc%7Bpadding%3A2rem%201rem%200%3Bfont%2Dsize%3A1rem%7D%2Emain%2Dcontent%7Bpadding%3A2rem%201rem%3Bfont%2Dsize%3A1rem%7D%2Emain%2Dcontent%20pre%2C%2Emain%2Dcontent%20pre%3E%20code%7Bfont%2Dsize%3A%2E9rem%7D%2Emain%2Dcontent%20blockquote%7Bfont%2Dsize%3A1%2E1rem%7D%7D%2Esite%2Dfooter%7Bpadding%2Dtop%3A2rem%3Bmargin%2Dtop%3A2rem%3Bborder%2Dtop%3Asolid%201px%20%23eff0f1%3Bfont%2Dsize%3A1rem%7D%2Esite%2Dfooter%2Downer%7Bdisplay%3Ablock%3Bfont%2Dweight%3A700%7D%2Esite%2Dfooter%2Dcredits%7Bcolor%3A%23819198%7D%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23a71d5d%3B%20font%2Dweight%3A%20normal%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23795da3%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%230086b3%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%230086b3%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%230086b3%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%234070a0%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23183691%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23969896%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<section class="page-header">
<h1 class="title toc-ignore project-name">Coursera - Predicting Possible Next Words</h1>
<h4 class="author project-author">Thomas Roscher</h4>
<h4 class="date project-date">2017-05-24</h4>
</section>


<div id="TOC" class="toc">
<ul>
<li><a href="#understanding-the-problem">Understanding the Problem</a></li>
<li><a href="#getting-and-sampling-the-text-corpus">Getting and Sampling the Text Corpus</a></li>
<li><a href="#normalizing-the-text-corpus">Normalizing the Text Corpus</a></li>
<li><a href="#splitting-the-data">Splitting the Data</a></li>
<li><a href="#tokanization">Tokanization</a></li>
<li><a href="#exploring-the-data">Exploring the Data</a></li>
<li><a href="#building-the-algorithm-stupid-backoff---a-first-approach-using-dplyr">Building the Algorithm: Stupid Backoff - A First Approach using “dplyr”</a></li>
<li><a href="#testing-the-model-on-some-of-the-quiz-data-provided-by-coursera">Testing the Model on some of the Quiz Data Provided by Coursera</a></li>
<li><a href="#testing-algorithm-1.0-on-the-test-data-set">Testing Algorithm 1.0 on the Test Data Set</a></li>
<li><a href="#building-the-algorithm-backoff-2.0---indexing-data.table-and-keys">Building the Algorithm: Backoff 2.0 - Indexing, “data.table” and Keys</a></li>
<li><a href="#testing-algorithm-2.0-on-the-test-data-set">Testing Algorithm 2.0 on the Test Data Set</a></li>
</ul>
</div>

<section class="main-content">
<p>knitr::opts_chunk$set(cache=TRUE)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(plyr)       <span class="co"># function mapvalues()</span>
<span class="kw">library</span>(tidyverse)  <span class="co"># data frame manipulation</span>
<span class="kw">library</span>(stringr)    <span class="co"># string manipulation</span>
<span class="kw">library</span>(stringi)    <span class="co"># string manipulation</span>
<span class="kw">library</span>(tau)        <span class="co"># generate N-grams</span>
<span class="kw">library</span>(knitr)      <span class="co"># function kable()</span>
<span class="kw">library</span>(cowplot)    <span class="co"># plotting several gg</span>
<span class="kw">library</span>(data.table) <span class="co"># for fast binary serach with keys</span>
<span class="kw">library</span>(dtplyr)     <span class="co"># for combining the power of dplyr and data.table</span>
<span class="kw">library</span>(tictoc)</code></pre></div>
<div id="understanding-the-problem" class="section level2">
<h2>Understanding the Problem</h2>
<p align="justify">
Mobile devices are no longer a necessity, they’ve become a primal need. But lacking a full-size keyboard, text entry on touch screen devices in particular can be rather annoying. Natural Language Processing (NLP) which is a field that covers computer understanding and manipulation of human language offers possibilities to build models that tackle the problem described above.
</p>
<p align="justify">
But how can we build models which predict the word that people may have in mind when writing? The basic idea is to learn from something called a corpus, which essentially is a collection of words or groups of words, within the language. Based on the information provided by corpus one can then build models that assign a probability to each possible next word. One of those language models (LM) is the so called N-gram model which is build around the idea that the probability of some future word depends only on a limited history of preceding words (Markov assumption).
</p>
<p align="justify">
While this may sound complicated at first sight, the actual process is quiet straight forward. Once a “nice and clean” corpus is provided, one uses N-gram models to calculate the frequencies of words and group of words within the corpus. The resulting N-grams along with the calculated probabilities are then stored and form the basis for the word prediction algorithm. In essence, the actual prediction mechanism eventually just goes through the N-gram tables and based on the given input identifies adequate N-grams and suggests the ones with the highest probability.
</p>
<p align="justify">
Note, that this paper is not a summary but rather an in depth documentation of all steps and consideration which were required to train the final algorithm and apply it on a web application. Besides, whenever repetitive steps were required example code is shown only for the first element. Regarding model paramaters my aim is to build an algorithm thats runs in less then 0.5 seconds and requires a maximum of 250 Mbyte of backround data.
</p>
<p align="justify">
Disclaimer, I am by far no expert for LMs and basically this was my first that I occupied myself with the topic.
</p>
</div>
<div id="getting-and-sampling-the-text-corpus" class="section level2">
<h2>Getting and Sampling the Text Corpus</h2>
<p align="justify">
Coursera provided a fairly large dataset which consists of several hundred thousand news articles, blog entries and Twitter messages. So first things first, lets read in the data. I use the command readLines() because it is rather fast (reading the Twitter messages for example takes 8 seconds) and it matches the structure of the txt files. I set encoding to UTF-8 because otherwise some special characters are not displayed properly.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># read data</span>
twitter   &lt;-<span class="st"> </span><span class="kw">readLines</span>(<span class="st">&quot;en_US.twitter.txt&quot;</span>, <span class="dt">encoding =</span> <span class="st">&quot;UTF-8&quot;</span>)
news      &lt;-<span class="st"> </span><span class="kw">readLines</span>(<span class="st">&quot;en_US.news.txt&quot;</span>, <span class="dt">encoding =</span> <span class="st">&quot;UTF-8&quot;</span>)
blog      &lt;-<span class="st"> </span><span class="kw">readLines</span>(<span class="st">&quot;en_US.blogs.txt&quot;</span>, <span class="dt">encoding =</span> <span class="st">&quot;UTF-8&quot;</span>)
profanity &lt;-<span class="st"> </span><span class="kw">readLines</span>(<span class="st">&quot;swearWords.txt&quot;</span>, <span class="dt">encoding =</span> <span class="st">&quot;UTF-8&quot;</span>)

<span class="co"># example to get a grasp of the data</span>
twitter[<span class="dv">1</span>]</code></pre></div>
<pre><code>## [1] &quot;How are you? Btw thanks for the RT. You gonna be in DC anytime soon? Love to see you. Been way, way too long.&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># mean characters across data sources</span>
<span class="kw">print</span>(<span class="kw">c</span>(<span class="kw">mean</span>(<span class="kw">nchar</span>(twitter)), <span class="kw">mean</span>(<span class="kw">nchar</span>(news)), <span class="kw">mean</span>(<span class="kw">nchar</span>(blog))))</code></pre></div>
<pre><code>## [1]  68.68045 202.42830 229.98695</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># number of blog, twitter, and news text blocks</span>
<span class="kw">print</span>(<span class="kw">c</span>(<span class="kw">length</span>(twitter), <span class="kw">length</span>(news), <span class="kw">length</span>(blog)))</code></pre></div>
<pre><code>## [1] 2360148   77259  899288</code></pre>
<p align="justify">
Having data from those 3 different sources is quiet nice because used words and word patterns may be rather different across them. However, because the data is fairly large as seen above and also because I need to consider the number of N-grams later on, sampling seems to be a valid approach. After sampling I merge the the data sources and further break everything down into sentences. Note, that I use more twitter entries because they contain on average much less characters, and thus sentences, compared to the other text sources.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># sample data (final sample size used in the application later on)</span>
<span class="co"># set.seed(2017)</span>
<span class="co"># twitter.sample &lt;- sample(twitter, 250000, replace = FALSE)</span>
<span class="co"># news.sample    &lt;- sample(news, 50000, replace = FALSE)</span>
<span class="co"># blog.sample    &lt;- sample(blog, 200000, replace = FALSE)</span>
<span class="co"># corpus         &lt;- c(twitter.sample, news.sample, blog.sample)</span>

<span class="co"># sample data (used in this paper due to RAM)</span>
<span class="kw">set.seed</span>(<span class="dv">2017</span>)
twitter.sample &lt;-<span class="st"> </span><span class="kw">sample</span>(twitter, <span class="dv">75000</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)
news.sample    &lt;-<span class="st"> </span><span class="kw">sample</span>(news, <span class="dv">37500</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)
blog.sample    &lt;-<span class="st"> </span><span class="kw">sample</span>(blog, <span class="dv">37500</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)
corpus         &lt;-<span class="st"> </span><span class="kw">c</span>(twitter.sample, news.sample, blog.sample)

<span class="co"># to deal with smiley and stuff like that</span>
corpus &lt;-<span class="st"> </span><span class="kw">iconv</span>(corpus, <span class="st">&quot;UTF-8&quot;</span>, <span class="st">&quot;ASCII&quot;</span>, <span class="st">&quot;?&quot;</span>)

<span class="co"># split into single sentences (as good as possible)</span>
corpus &lt;-<span class="st"> </span><span class="kw">unlist</span>(<span class="kw">strsplit</span>(corpus , <span class="st">&quot;[</span><span class="ch">\\</span><span class="st">.</span><span class="ch">\\</span><span class="st">!</span><span class="ch">\\</span><span class="st">?</span><span class="ch">\\</span><span class="st">:]+&quot;</span>))

<span class="co"># number of sentences</span>
<span class="kw">length</span>(corpus)</code></pre></div>
<pre><code>## [1] 392001</code></pre>
<p align="justify">
Running the code above leaves me with a manageable amount of sentences for comparing some different approaches. I will increase the size of the corpus later on once the final algorithm is trained.
</p>
</div>
<div id="normalizing-the-text-corpus" class="section level2">
<h2>Normalizing the Text Corpus</h2>
<p align="justify">
Let’s remind ourself that ideally, for N-Gram tokenization later on, one needs a nice and clean corpus which consists of nothing else but “valid” words. Hence, the first and arguably one of the most important steps before building any language model is normalizing the text corpus. I wrote the function norm.text() for that purpose which preforms a vast number of actions:
</p>
<ul>
<li>converts everything to lowercase</li>
<li>removes emails</li>
<li>removes urls</li>
<li>removes punctuation and symbols</li>
<li>removes numbers</li>
<li>removes useless white space</li>
<li>removes twitter language</li>
<li>removes profanity</li>
<li>deals with apostrophes as special punctuation</li>
<li>removs some odd patterns which I encountered</li>
</ul>
<p align="justify">
Note that even after running the code below, the corpus is far from perfect. For example, there probably are a lot of typos as well as what one may call “chat words” which strictly speaking are not real words but are nevertheless widely used on Internet (e.g. lol). Also there still are stop words as well as words with similar word stem. While what one may call base normalization is mandatory and done by norm.text(), removing stop words and merging words with the same word stem (as often done in text analysis) is arguably not adequat for word prediction.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># normalize the text corpus</span>
norm.text &lt;-<span class="st"> </span>function(string, swearwords){
                <span class="co"># lower case</span>
                string &lt;-<span class="st"> </span><span class="kw">tolower</span>(string)
                <span class="co"># e-mail</span>
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;</span><span class="ch">\\</span><span class="st">S+@</span><span class="ch">\\</span><span class="st">S+&quot;</span>, <span class="st">&quot;&quot;</span>) 
                <span class="co"># URLs</span>
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;http[[:alnum:]]*&quot;</span>, <span class="st">&quot;&quot;</span>)
                <span class="co"># hashtags</span>
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;#[[:alnum:]]*&quot;</span>, <span class="st">&quot;&quot;</span>)
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;# [[:alnum:]]*&quot;</span>, <span class="st">&quot;&quot;</span>)
                <span class="co"># @</span>
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;@[[:alnum:]]*&quot;</span>, <span class="st">&quot;&quot;</span>)
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;@ [[:alnum:]]*&quot;</span>, <span class="st">&quot;&quot;</span>)
                <span class="co"># twitter language</span>
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;RT&quot;</span>, <span class="st">&quot;&quot;</span>)
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;PM&quot;</span>, <span class="st">&quot;&quot;</span>)
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;rt&quot;</span>, <span class="st">&quot;&quot;</span>)
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;pm&quot;</span>, <span class="st">&quot;&quot;</span>)
                <span class="co"># apostrophes </span>
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;'ll&quot;</span>, <span class="st">&quot; will&quot;</span>)
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;'d&quot;</span>, <span class="st">&quot; would&quot;</span>)
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;can't&quot;</span>, <span class="st">&quot;cannot&quot;</span>)
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;n't&quot;</span>, <span class="st">&quot; not&quot;</span>)
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;'re&quot;</span>, <span class="st">&quot; are&quot;</span>)
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;'m&quot;</span>, <span class="st">&quot; am&quot;</span>)
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;n'&quot;</span>, <span class="st">&quot; and&quot;</span>)
                <span class="co">#'s-genitive</span>
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;'s&quot;</span>, <span class="st">&quot; &quot;</span>)
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;s'&quot;</span>, <span class="st">&quot; &quot;</span>)
                <span class="co"># everything that is not number,letter, whitespace or '</span>
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;[^[:alnum:]]&quot;</span>, <span class="st">&quot; &quot;</span>)
                <span class="co"># digits</span>
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;[:digit:]&quot;</span>, <span class="st">&quot;&quot;</span>)
                <span class="co"># more then one whitespace</span>
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;</span><span class="ch">\\</span><span class="st">s+&quot;</span>, <span class="st">&quot; &quot;</span>)
                <span class="co"># trim whitespace</span>
                string &lt;-<span class="st"> </span><span class="kw">str_trim</span>(string, <span class="dt">side =</span> <span class="kw">c</span>(<span class="st">&quot;both&quot;</span>))
                <span class="co"># deal with &quot;don t und dont&quot;</span>
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;don t&quot;</span>, <span class="st">&quot;do not&quot;</span>)
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;dont&quot;</span>, <span class="st">&quot;do not&quot;</span>)
                <span class="co"># deal with &quot;u s for usa&quot;</span>
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, <span class="st">&quot;u s&quot;</span>, <span class="st">&quot;usa&quot;</span>)
                <span class="co"># profanity (for loop takes a while)</span>
                for (i in swearwords){ 
                string &lt;-<span class="st"> </span><span class="kw">str_replace_all</span>(string, i, <span class="st">&quot;&quot;</span>)
                }
<span class="kw">return</span>(string)
}
<span class="co"># normalize text</span>
corpus.clean &lt;-<span class="st"> </span><span class="kw">norm.text</span>(corpus, profanity)</code></pre></div>
</div>
<div id="splitting-the-data" class="section level2">
<h2>Splitting the Data</h2>
<p align="justify">
Next, I split the data into a training and a test set, so that I can check the accuracy of my algorithm later on.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2007</span>)
idx &lt;-<span class="st"> </span><span class="kw">sample.int</span>(<span class="kw">length</span>(corpus.clean),<span class="dt">size=</span><span class="kw">length</span>(corpus.clean)*<span class="fl">0.1</span>, <span class="dt">replace=</span><span class="ot">FALSE</span>) 
testing  &lt;-<span class="st"> </span>corpus.clean[idx]
training  &lt;-<span class="st"> </span>corpus.clean[-idx]</code></pre></div>
</div>
<div id="tokanization" class="section level2">
<h2>Tokanization</h2>
<p align="justify">
In lexical analysis, tokenization is the process of breaking a stream of text up into words, phrases, symbols, or other meaningful elements called tokens. The list of tokens becomes input for further processing. Eventually, I want to break the text down into words, to emit N-grams (N-grams are a contiguous sequence of n items from a given sequence of text or speech). R provides several packages that can be used for creating N-grams, including “tau”, “ngram”, “RWeka” and “textcat”. I chose Tau because it is rather fast.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create N-grams</span>
unigram_tau  &lt;-<span class="st"> </span><span class="kw">textcnt</span>(training, <span class="dt">n =</span> 1L, <span class="dt">method =</span> <span class="st">&quot;string&quot;</span>, <span class="dt">split =</span> <span class="st">&quot; &quot;</span>)
bigram_tau   &lt;-<span class="st"> </span><span class="kw">textcnt</span>(training, <span class="dt">n =</span> 2L, <span class="dt">method =</span> <span class="st">&quot;string&quot;</span>, <span class="dt">split =</span> <span class="st">&quot; &quot;</span>)
trigram_tau  &lt;-<span class="st"> </span><span class="kw">textcnt</span>(training, <span class="dt">n =</span> 3L, <span class="dt">method =</span> <span class="st">&quot;string&quot;</span>, <span class="dt">split =</span> <span class="st">&quot; &quot;</span>)
fourgram_tau &lt;-<span class="st"> </span><span class="kw">textcnt</span>(training, <span class="dt">n =</span> 4L, <span class="dt">method =</span> <span class="st">&quot;string&quot;</span>, <span class="dt">split =</span> <span class="st">&quot; &quot;</span>)
fivegram_tau &lt;-<span class="st"> </span><span class="kw">textcnt</span>(training, <span class="dt">n =</span> 5L, <span class="dt">method =</span> <span class="st">&quot;string&quot;</span>, <span class="dt">split =</span> <span class="st">&quot; &quot;</span>)

<span class="co"># transform trie encodings to dataframe (illustrated only for unigram_tau)</span>
unigram.df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">counts =</span> <span class="kw">unclass</span>(unigram_tau), <span class="dt">size =</span> <span class="kw">nchar</span>(<span class="kw">names</span>(unigram_tau)))
unigram.df$n.gram &lt;-<span class="st"> </span><span class="kw">rownames</span>(unigram.df)
<span class="kw">rownames</span>(unigram.df) &lt;-<span class="st"> </span><span class="ot">NULL</span></code></pre></div>
<p align="justify">
Calculating the N-gram frequencies took quiet a while even when just using the rather small sample. However, since they must be created only once speeding up the process is less important. What is important though, is storing them efficiently. Why is that? Well, first of all storing them in R requires RAM which is a limited resource. Besides, one needs to consider that the amount of time the algorithm takes to make a prediction may be affected by the manner in which N-grams are stored. Thus, let’s first take a look how large the generated N-grams are when stored in a data frame.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># used storage of the N-grams</span>
<span class="kw">print</span>(<span class="kw">object.size</span>(unigram.df) +<span class="st"> </span><span class="kw">object.size</span>(bigram.df) +<span class="st"> </span><span class="kw">object.size</span>(trigram.df) +<span class="st"> </span><span class="kw">object.size</span>(fourgram.df) +<span class="st"> </span><span class="kw">object.size</span>(fivegram.df))</code></pre></div>
<pre><code>## 881129672 bytes</code></pre>
<p align="justify">
Unfortunately, it seems that the classical data frame is not really suitable since the N-grams of my sample already requires a lot of RAM. Thus, I may have to switch to some other storage type later on. Using SQLite or data.table might be an option. Yet, let’s turn to some data exploration first to see if we can get some additional valuable insights. Maybe I can handle the size issue without using an external database.
</p>
</div>
<div id="exploring-the-data" class="section level2">
<h2>Exploring the Data</h2>
<p align="justify">
Next, I gonna build some figures to understand variation in the frequencies (I used log because data is highly skewed) of words and word pairs in the data. Note, that I restricted the plot samples containing 70000 of the respective N-grams. Code below is illustrative for the two plot types:
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2017</span>)
p1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">sample_n</span>(unigram.df, <span class="dv">70000</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>), 
             <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">log</span>(counts))) +<span class="st"> </span>
<span class="st">                </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;steelblue&quot;</span>, 
                               <span class="dt">fill =</span> <span class="st">&quot;white&quot;</span>, 
                               <span class="dt">alpha=</span>.<span class="dv">7</span>, 
                               <span class="dt">binwidth =</span> <span class="fl">0.5</span>) +
<span class="st">                </span><span class="kw">theme_gray</span>() +<span class="st"> </span>
<span class="st">                </span><span class="kw">xlab</span>(<span class="st">&quot;&quot;</span>) +
<span class="st">                </span><span class="kw">ylab</span>(<span class="st">&quot;&quot;</span>) +
<span class="st">                </span><span class="kw">ggtitle</span>(<span class="st">&quot;Distribution of 1-grams&quot;</span>)
   
<span class="kw">set.seed</span>(<span class="dv">2017</span>)
p4 &lt;-<span class="st"> </span><span class="kw">top_n</span>(<span class="kw">sample_n</span>(unigram.df, <span class="dv">70000</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>), <span class="dt">n =</span> <span class="dv">10</span>, counts) %&gt;%
<span class="st">                </span><span class="kw">ggplot</span>(., <span class="kw">aes</span>(<span class="dt">x =</span> n.gram, <span class="dt">y =</span> counts)) +
<span class="st">                </span><span class="kw">geom_bar</span>(<span class="dt">stat=</span><span class="st">'identity'</span>, 
                         <span class="dt">color =</span> <span class="st">&quot;steelblue&quot;</span>, 
                         <span class="dt">fill =</span> <span class="st">&quot;white&quot;</span>) +
<span class="st">                </span><span class="kw">theme_gray</span>() +
<span class="st">                </span><span class="kw">coord_flip</span>() +
<span class="st">                </span><span class="kw">xlab</span>(<span class="st">&quot;&quot;</span>) +
<span class="st">                </span><span class="kw">ylab</span>(<span class="st">&quot;&quot;</span>) +
<span class="st">                </span><span class="kw">ggtitle</span>(<span class="st">&quot;Most common 1-grams&quot;</span>)</code></pre></div>
<p><img src="data:image/png;base64,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" style="display: block; margin: auto;" /><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAqAAAADACAMAAADsiSGEAAABCFBMVEUAAAAAADoAAGYAOjoAOmYAOpAAZmYAZrYzMzM6AAA6AGY6ZmY6kLY6kNtGgrRNTU1NTW5NTY5Nbo5NbqtNjshmAABmOgBmZgBmkJBmtrZmtv9uTU1uTW5uTY5ubk1ubo5ubqtujshuq6tuq+SOTU2OTW6OTY6Obk2ObquOjk2Ojo6Oq6uOyP+QOgCQtpCQ29uQ2/+rbk2rbm6rbo6rjk2rq46ryKur5Mir5OSr5P+2ZgC2tma2/7a2/9u2///Ijk3Ijm7I5KvI/8jI/+TI///bkDrbtmbb/9vb///kq27k5Kvk/+Tk///r6+v5+fn/tmb/yI7/25D/5Kv//7b//8j//9v//+T///8i4GWNAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAQBUlEQVR4nO2dDXvbthWFnXSd63SO4jXeVrtZ0ipLss3eYm/Zaq2Lm87aqs2ubMUW//8/GT7JCxIgAZCUQPmcJ7EkXgIgr14BIC4BbmUQlLC21n0AEFQnAAolLQAKJS0ACiUtAAolLQAKJS0ACiUtAAolre4AnW4JPXzP3t8df/pjYbl59F6949s/7m9XE/NdzEQ1mmxtqT1vdliJB+2OeyCabD14K97cHW9ZHJhRN3emBPzbOaDihEzWpg8bAeW7+AI6Z2Vs5++Ydtse+hA00efJoLEDWri5K6Xg3w4Blf6Z6196xaLkBNRXc/2bvjvmRc23Ov9iUtTk4a/l73f6c5sDsx4ATcK/nQPKTmhXVoasLeLVqXjZvTvenm49+LOsQeeyJyCrTGbRu/CPH/dz47+NX682THQ/gtUlwjopHMh/8r843s5kaW9lFbAr9pzzN3PZOVBHNihNHv5D/PLvjr8UgGp3mG5WO7PzlNWE3st0QMkdLp8n4d/uAeWcyf+ywdf0fbKz9el/BKCf8J4NOz0boLJVEca8wyCUGwpAlSZ5z0D1MrgDeWk/TnUWNzufszIf/GlHWY2ch6HJw+/2OS83j77jgJb9dEABnSpbsZfpAPOT2+eq5LX6t3tA+S+OsyZ+f6I9lx1M7j3ZB+XvpuJEFKBFH5TtdsCN4t223E2oMBRNvNTH/d38nXTydl6arDz4N8LSiN/4zQ49sgGJeXXCj3i6zY+8cIfpZiHRNMuGrNjLdAD95PS51Jr92yeg+kQlfbpR/7gvfpFqrxKg/Gy58cFbmSA/zcJQAlQkl5qLGoTvKRNz8dZrW6YWBZtHNiAxf82Fkw64Twp3mG4WUk1zZuxlOqDyyeZzoXX7tz9ARVssuiTFJboEVLhvyv1hAVTANzeMXIXBBPTumOcm2prdqeqk6bpZjpJIB+a/6Qk9sgGJefXj/gEfS5KA5u4w3CykjNRppgPKnxw+51q7f/vrg6rjZ1t7BFRttjuQ/7oPMvl9Gg7Mj2xA4pcqrI2fbmclQA03C3UI6Pr92+NVvNCEnUIZUH4eopGY5C2KrYkvAWpr4ufGkBZtgqSbDjLdRzIdqI9sQOK+mj/857EmIneHtCo3C1mb+DpAHT5Pwr89jIMq1uTp8F/dlFyx04skcQ6qY652oR12w1nWiyTTf0YnXjpQ9Iy2yt9IcWQDEgf0Zuc3j95n5kWS6WYhcZHEe4S2S6kqoE6fJ+Hf/iJJarCBnck0H+SUgH6uGwAxvvGzX4krx+owU8lZ2lAAypuYLdqWkGGQfDhOHELlGxleJ3Qih0K21XmUh4aUm+W+c/09kGEmN6BOnyfh3x5j8eI41ZiyGAHN+6BzfdIsDbNs011498UYxdf5a0MBqIrEkc4O3/Llft6J5x5+8JZ9taVvJD+yAUl0h6b81OV55O4w3KyYmOthSL1XLaAunyfh3827m6kYt4P60Ir9u0mAyt7+wC5+BqS1+HeTAB1k33JAWot/NwnQQfYth6R1+HejAIU2TwAUSloAFEpaABRKWgAUSloAFEpaABRKWp0BelWRZdNGmJ3WrlzZ4N7Io2u29pZxTLH6xAFosBmArqJYfeIANNi8bkAf29Xu2FsmBaAJmdcOqHUHAOrvQa9jHq65O0AXzy7IC3lD3lXdC0CjRDO3NT2Bp5SwuXNAnZ/t7gWgUaKZP/6JKxN/AWhZy5OjbPHVWXb9xX+f/X40OhJc3r4cPTlbyM+ZRPV6NNrLgSXFANAo0cwBaK1m42zGOJyNF4djhuklo5FDy4CVnzMB6O2ri2z2lO//GRNF0ZqpfevwBUCDza0BXby4/P7d0+XpGa8n2X/5L5P1Zv7u9ndndveiBo0SzRyA1ur21Q+vPjz74dUFAfSFqjczguoha/Ut7gWgUaKZA9B6nf/x6+Xpu6dZbQ3Kd5Ttfcm9ADRKNHMAWq/rkeyFFoCKC6dnHyigHE47oBiob6vHjveQlLiG37sggOqreFqDnjuu4ldMypqK1SeOGjTY3N04aJx7HTXoRqjqTAAabO4aUGN4Pu+Put27wW0SAO3CDEB7EwDtwtwxoKz3uXch/qgPH1Q8SW8ruxeARol+UwA0ROKCiISQVHyJbwuIJG2ELKcGQIPNPQDKw5oycqSaeBVJ4tsr7t1kQKvOBKDB5h4A5UwuT0uAvhyNilASKQaARol+UwA0RK4a9BW9ViLFANAo0W8KgIao0gdVw/X5tpJ7AWiU6DcFQEO0PCmu4vkHHfAUwSWLe9c9mN6nqs4EoMHmBCNJ7Y+9ZVKEOhMyrx3QihGAhnkQgLrkihPVzUaquBeARolmDkAdAqDeRn1uADTYHA9oNZB5fpSJm+n1dLnFIXvhW5anZ/6hznsOKL+ZlvuTD3lYXwCoMjSqEsi8HvN/HEyxlY+FLp796/SMY+sf6tzggScfQPm93xxS5i3rixT9pgCoQ5VA5u2by+/V+Lxu5tlWPu1zHBDqvN816OL56yPhKRXdqLwAUG0IAVQGMpenf39jTJcTt9EvXvxPtPC+oc57Dejy9NsT2VFiP2nrSyYaIcNhjvf3XtVA5uwPY2WQ2IqJSsvTv724DAh13mtAZ2O5qIBg0fpS8SBq0GZAdSCTT08qABUvbMtsxLD1D3XeZ0BZLblsrkEBqDA0qhrIXP4lXz+M/5+NRr98LVfGCQl1tj/2lknXByjzGNMYfVAPazOgVS2+9tuPFFMfy75vgGZymGl5MpbX7ZaXigcBqLdmT86adyoD6t7r/gKKcVAPqx9qmT2g5AwyVdwLQKNEMweg9XIA6uleABolmjkArZVt6qbcdrE8fcd6/NcjfhUfMasTgLpFMweg9bJN3dRrND3NFodP9UBU6KzODRx0BqDB5s6aeGPqpgL09EzMnmPbY2Z1ogZ1i2YOQOtlm7pZBTRiVicAdYtmDkDrZZu6WQU0YlYnAHWLZg5A62WbulkBNGZWJwB1i2YOQOtlm7opt1FAY2Z1AlAA2gGg7dwbMo23HKwHoEIAtHORYiLGkgAoAL3yALQhnOnpXgDa1oMA1CEA6m/Uh46HKKxO9tVp1RMPxXzOrGWo0yUAihr0yrMGLYc41RMP5XzOtqFOlwZcSwDQYHPrJt4IcZInHrINLUOdLqEGBaBXYYAWcUz9xEMxn7NlqNMlAApAr8IANeKYfMkGPZ+zVajTJQAKQK+CAC3imOqJh2o+Z8tQp0sAFIBeeQBqXZ1WPfFQzudsG+pEJAmArj+SVEth56T0bgWgHZvXDqhjFwDq60EA2qhKTKkpwkSKAaBRopkD0CYB0CajPisAGmzuAFAa9BQxThXWlOvZyg9kRcYMgLYXzRyANqkIeqoYp0RRrmcrx5cKQD1DnQOOZ9YIgAabO2ziizVr5Tuxnq167BxqUCEAGmzuGlC5Zq1AUaxnu5AP7gSgQgA02NwtoCrGqVDk69miBhVblRoBlfcpYvEwD2sUoCrGqVAUC4Oe553T2R4AbfCk6MN/dYaHKHhYAwAlQU8V4zwRLIr1bNUlPTN8Y73dDpEkomsO4PkRFrD1sAYA6pJzPVtSTE2oPf7YWyZdbx/UtfY3HqLQtdzr2ZKvDmvUl8QXUsZDFDysMUhWJJukSmCJFANATd2+HGd4iIKPtRWYWgBUbVXyuIpn1/B4kJePNRbJF38tJnrKCyTyFoD68ImHKPhYYwEtJnqqCGdm3nSPZ3XWSD6G5gjjoB7WyK+ATFNS4/MZ+Vx1L2rQKNHMAWiIyIi9inBm5HPVvQA0SjRzABoi1KDWrUoANNjcE6DuPmjJvQA0SjRzABoiDai8apcxT/7XeRWPSFKMaOYAtHORYlpMLAagUgDUQ8Wi9NWtte61DioB0CbRzAGoh/QtygDUvlUJgAabu65BlydfXJpPRCwvIZoB0PaimQNQD+WAsqt184mI5SVEfSbNbWwwCYAGmzsG9LdjeVs4fSKiuYRoyb2oQaNEMwegHlKAnnzz5jIrPxGxtIRoBkDbi2YOQD2UN/GzcVZ+ImJ1CVFSDACNEs0cgHqouEg6PSs/ETEwkpQB0DBhyoeHinFQ2Z7TJyKWlhDNMFDfXjRz1KCdixRTG+kEoB4eBKDdixRTaZMAaKAHAainAh47R4oBoFGimQPQzkWKAaBtPWgCGndfWMLmTmtQPWPOujbo4vnrveqcRAAaJZq5AehPRADUEIlrWtcGVTMWm0KdGz1QAkCDzd0Cmq9hZ1kblPRRSTGoQaNEMwegfjIAtawNCkABaIS5J0Ata4MCUAAaYe4L0OraoAAUgEaY+wK0ujaoA1BEkmJEMwegMXKuDVpyrz0Wr0kFoM0erAHU9bsPPeMNBNS9NmjJve5RJQDq58EaQP1hvVeAVmKeYcsvagHQGtHM/QB1weqz1vqmA1rnXgDqLa/V7bwANXbyOOONA7Q0kZMTez0KmNUpBEBN+T3lIxxQn47qhgFansippnz4z+pssAxXbQD1W2E5HFCaOlyDBLQ8kVN9KES968wGNWjJrc6nfNwjtfAf8WR5IqfYcOiY8uHMBoCacj7lw+eYh2vusQalkzu1hyvuBaDebnU95cPnmIdr7g9QY3InfwNA++mD+hzzcM09AppP5BS0uq7i3Yo/9han3dba51W84ykfPsc8XHMPgDar/dE1WzcOUGMctKrPnBYfDTd132pzdC3SrqnYXhZukBouYgA0nWIBaOep+xYAhaBkBEChpAVAoaQFQKGkBUChpNUDoMXoaP04qV2LQ7UUjHjQ8p736lpZKU1E2frJzpFlr0Thp6Uc6n5OdZ34HZVxSZcnIigWVyxR94AWd4ka94t6isf2xfxbsVhRsPI0MWVzqeh3TNmrUPhpKYeqhOZLs2aM7bikzIPMl5HFEnUPaBGhN2L1nrrmxy/wKD/iykdFmpiys0zf+xJT9koUflrKoSqh+dKYePH89VEWlVTdmBVXLFX3gBb3OBl3OwVIphE3RwZWZEWayLLV7zum7JUo7rT4WiUyofnSlG55+u3JURaVlK/ax5r4qLSGuge0uEvUuF/UX/welEwutBFakxVp4srWKWLKXomiTos7VCU0X5oSzsa8UY5KyhfmYzxGpTWUXg16+3JcfIjuh8aVfU278Cn2Q2NOSzg0pipjey3ja1BLojRq0HZ90EytiakUDWhcH/R8TD8kCGjEaUmHxnQG5ajGOK4P+kawmGIftLhL1Lhf1FMFn7w2E8sVBahIE1N20arHlL0ShZ+WcqhKaL74lHcUmVQuGB1ZLFFv46DqBvHIsUieekaeBBiQ/MlZbNm6ZxJZ9koUfFp6cHfV46Bqin+C46AQ1KEAKJS0ACiUtAAolLQAKJS0ACiUtAAolLQAKJS0ACiUtAAolLQAKJS0ACiUtAAolLQAKJS0ACiUtAAolLQAKJS0ACiUtAAolLQAKJS0ACiUtAAolLQAKJS0ACiUtAAolLQAKJS0ACiUtAAolLQAKJS0ACiUtAAolLT+D3u2fYPB6Il2AAAAAElFTkSuQmCC" style="display: block; margin: auto;" /><img src="data:image/png;base64,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" style="display: block; margin: auto;" /></p>
<p align="justify">
Well, obviously there is a tremendous amount of N-grams that show only up a few times (often even just once). Many of them are useless things like “aaarrrgggghhh”. This finding may be rather interesting since it suggests that deleting those cases to lower the number of the N-grams might be a valid approach to save some memory and run time. The variable size which counts the characters of each N gram, also supports that approach because there seem to be fare too many one and two letter words as well as words with and oddly large number of characters. Regarding the most used words and word pairs, the plots show that there frequency drops off quickly and that unsurprisingly stop words are most prevalent.
</p>
<p align="justify">
Next, let’s investigate how many unique n-grams one needs in a frequency sorted dictionary to cover a certain amount of all n-gram instances in the corpus.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># illustrative variable creation for unigrams</span>
unigram.df.p &lt;-<span class="st"> </span><span class="kw">sample_n</span>(unigram.df, <span class="dv">70000</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>) %&gt;%
<span class="st">                </span><span class="kw">arrange</span>(<span class="kw">desc</span>(counts)) %&gt;%
<span class="st">                </span><span class="kw">mutate</span>(<span class="dt">counts.cs.p =</span> <span class="kw">cumsum</span>(counts)/<span class="kw">sum</span>(counts)) %&gt;%
<span class="st">                </span><span class="kw">mutate</span>(<span class="dt">id =</span> <span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">70000</span>))

x &lt;-<span class="st"> </span>unigram.df.p %&gt;%
<span class="kw">filter</span>(counts.cs.p &gt;<span class="st"> </span><span class="fl">0.7499</span>)  %&gt;%
<span class="kw">head</span>(<span class="dt">n =</span> 3L)
<span class="kw">kable</span>(x)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">counts</th>
<th align="right">size</th>
<th align="left">n.gram</th>
<th align="right">counts.cs.p</th>
<th align="right">id</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">276</td>
<td align="right">6</td>
<td align="left">effect</td>
<td align="right">0.7499254</td>
<td align="right">1049</td>
</tr>
<tr class="even">
<td align="right">276</td>
<td align="right">4</td>
<td align="left">aist</td>
<td align="right">0.7500257</td>
<td align="right">1050</td>
</tr>
<tr class="odd">
<td align="right">275</td>
<td align="right">8</td>
<td align="left">approach</td>
<td align="right">0.7501256</td>
<td align="right">1051</td>
</tr>
</tbody>
</table>
<p align="justify">
Above you see that in order to cover 75 percent of the 1-gram instances in the sample corpus not to many of the most occurring words are needed. Let’s plot this stuff for all N-grams to get even more valuable information. Code below is illustrative for one of the three plots.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p7 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(unigram.df.p, <span class="kw">aes</span>(<span class="dt">x=</span>id, <span class="dt">y=</span>counts.cs.p)) +
<span class="st">                </span><span class="kw">geom_line</span>(<span class="dt">color =</span> <span class="st">&quot;steelblue&quot;</span>) +
<span class="st">                </span><span class="kw">theme_gray</span>() +<span class="st"> </span>
<span class="st">                </span><span class="kw">xlab</span>(<span class="st">&quot;&quot;</span>) +
<span class="st">                </span><span class="kw">ylab</span>(<span class="st">&quot;&quot;</span>) +
<span class="st">                </span><span class="kw">ggtitle</span>(<span class="st">&quot;&quot;</span>)</code></pre></div>
<p><img src="data:image/png;base64,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" style="display: block; margin: auto;" /></p>
<p align="justify">
Clearly, at least for the 2-grams there is a strongly exponential pattern which becomes less extreme as the number of N increases. Well, what does this imply for the algorithm? Clearly there is a point where adding rare N-grams does not seem to be efficient because gaining a bit more coverage requires a vast amount data.
</p>
</div>
<div id="building-the-algorithm-stupid-backoff---a-first-approach-using-dplyr" class="section level2">
<h2>Building the Algorithm: Stupid Backoff - A First Approach using “dplyr”</h2>
<p align="justify">
Now that I have some workable data and got an idea about it’s descriptive characteristics the next step is to create an algorithm which assigns probabilities to the various N-grams and returns the top predictions based on an input string. The basic idea is to start with a simple baseline model which then can be used to tweak parameters. What follows is an implementation of a “stupid back off model” which starts with 5-grams. Here, back off basically means that one goes back to a N-1 gram model to calculate probabilities whenever one encounters a word with the probabilities of zero. For each time I back off one level, the probabilities are multiplied with the back off factor alpha (0.4). The aim here is not to code the final product. Rather I want to get a functioning base model which is then used to test any further specifications regarding things as efficient coding, data storage, sampling size, or corpus setting.
</p>
<p align="justify">
In order to illustrate the algorithm let’s walk through an example where we want to complete the sentence “I must know what are you going to”.
</p>
<ol style="list-style-type: decimal">
<li>Take the last four words of the input sentence (“are you going to”).</li>
<li>Look for any 5-grams that with those last four words.</li>
<li>If applicable store the last word of encountered 5-grams and and calculate their probability.</li>
<li>Probability is calculated as follows: Number of times that 5-grams ended with that word divided by how often it’s first four words show up in the 4-gram table.</li>
<li>For example “are you going to be” may show up x times in the 5-gram table and “are you going to” may be listed y times in the 4-gram table. Therefore, the probability is x/y.</li>
<li>Store the 3 most probable words.</li>
<li>Step wise back off to the 2-gram level. For each level repeat the procedure with an adjusted probability (x*0.4) and store 3 most probable words</li>
<li>Drop any words that are suggested again during the backing off process.</li>
<li>Print the three most probable words along with their probability.</li>
<li>Lastly, if there are no matches just print the three most common words in the corpus.</li>
</ol>
<p align="justify">
Before writing the function, I preform two actions to reduce the size of the N-gram tables. First, I delete now useless variables that were created during the analysis so far. Secondly, I drop any N-grams which show up only once which reduces the size of the N-gram tables by about 50 percent.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># based on the findings in the descriptive part, I drop any N-gram that shows up only once</span>
unigram.df.short  &lt;-<span class="st"> </span><span class="kw">filter</span>(unigram.df, counts &gt;<span class="st"> </span><span class="dv">1</span>) %&gt;%
<span class="st">                     </span><span class="kw">select</span>(n.gram, counts)
bigram.df.short   &lt;-<span class="st"> </span><span class="kw">filter</span>(bigram.df, counts &gt;<span class="st"> </span><span class="dv">1</span>) %&gt;%
<span class="st">                     </span><span class="kw">select</span>(n.gram, counts)
trigram.df.short  &lt;-<span class="st"> </span><span class="kw">filter</span>(trigram.df, counts &gt;<span class="st"> </span><span class="dv">1</span>) %&gt;%
<span class="st">                     </span><span class="kw">select</span>(n.gram, counts)
fourgram.df.short &lt;-<span class="st"> </span><span class="kw">filter</span>(fourgram.df, counts &gt;<span class="st"> </span><span class="dv">1</span>) %&gt;%
<span class="st">                     </span><span class="kw">select</span>(n.gram, counts)
fivegram.df.short &lt;-<span class="st"> </span><span class="kw">filter</span>(fivegram.df, counts &gt;<span class="st"> </span><span class="dv">1</span>)%&gt;%
<span class="st">                     </span><span class="kw">select</span>(n.gram, counts)

<span class="co"># used storage of the N-grams</span>
<span class="kw">print</span>(<span class="kw">object.size</span>(unigram.df.short) +<span class="st"> </span><span class="kw">object.size</span>(bigram.df.short) +<span class="st"> </span><span class="kw">object.size</span>(trigram.df.short) +<span class="st"> </span><span class="kw">object.size</span>(fourgram.df.short) +<span class="st"> </span><span class="kw">object.size</span>(fivegram.df.short))</code></pre></div>
<pre><code>## 49499328 bytes</code></pre>
<p align="justify">
Next, now that everything is prepared let’s create the algorithm. Basically, I create 4 of them where one is for input sentences of at least 4 words length. The other three are for input sentences of length 3,2, and 1, respectively. Code is shown only for the first one because it remains basically the same except that the “starting point” is are different N-grams.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># useful function to get n last word, borrowed from a fellow student</span>
getLastWords &lt;-<span class="st"> </span>function(string, words) {
    pattern &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;[a-z']+( [a-z']+){&quot;</span>, words -<span class="st"> </span><span class="dv">1</span>, <span class="st">&quot;}$&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>)
    <span class="kw">return</span>(<span class="kw">substring</span>(string, <span class="kw">str_locate</span>(string, pattern)[,<span class="dv">1</span>]))
}
############################
######## ALGORITHM #########
############################

<span class="co"># pred.word4 is for cases where the input sentence is at least 4 words</span>
pred.word4 &lt;-<span class="st"> </span>function(input.sentence){
        
<span class="co"># take the last four words from input sentence as input for 5-gram table</span>
isr5 &lt;-<span class="st"> </span><span class="kw">getLastWords</span>(input.sentence, <span class="dv">4</span>)
<span class="co"># take the last three word from input sentence as input for 4-gram table</span>
isr4 &lt;-<span class="st"> </span><span class="kw">getLastWords</span>(isr5, <span class="dv">3</span>)
<span class="co"># take the last two words from input sentence as input for 3-gram table</span>
isr3 &lt;-<span class="st"> </span><span class="kw">getLastWords</span>(isr4, <span class="dv">2</span>)
<span class="co"># take the last word from input sentence as input for 2-gram table</span>
isr2 &lt;-<span class="st"> </span><span class="kw">getLastWords</span>(isr3, <span class="dv">1</span>)

<span class="co"># start at the 5-gram table</span>
pred.five &lt;-<span class="st"> </span>fivegram.df.short %&gt;%
<span class="st">    </span><span class="co"># In the 5-gram table filter any 5-grams that start with the last four</span>
<span class="st">    </span><span class="co"># words from input sentence and end with a whitespace</span>
<span class="st">    </span><span class="kw">filter</span>(<span class="kw">grepl</span>(<span class="kw">paste0</span>(<span class="st">&quot;^&quot;</span>, isr5,<span class="st">&quot; &quot;</span>), n.gram)) %&gt;%
<span class="st">    </span><span class="co"># create variable that shows last word of the filtered 5-grams</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">predicted.word =</span> <span class="kw">getLastWords</span>(n.gram, <span class="dv">1</span>))  %&gt;%
<span class="st">    </span><span class="co"># calculate propability for the last word</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">propability =</span> counts/fourgram.df.short$counts[fourgram.df.short$n.gram ==<span class="st"> </span>isr5]) %&gt;%
<span class="st">    </span><span class="co"># arrange descending</span>
<span class="st">    </span><span class="kw">arrange</span>(<span class="kw">desc</span>(propability)) %&gt;%
<span class="st">    </span><span class="co"># only keep the predicted word and it's propability</span>
<span class="st">    </span><span class="kw">select</span>(predicted.word, propability) %&gt;%
<span class="st">    </span><span class="co"># only keep top 3 </span>
<span class="st">    </span><span class="kw">top_n</span>(<span class="dv">3</span>) 
        
<span class="co"># do exactly the same stuff for the 4-gram table plus backoff factor</span>
pred.four &lt;-<span class="st"> </span>fourgram.df.short %&gt;%<span class="st">  </span>
<span class="st">    </span><span class="kw">filter</span>(<span class="kw">grepl</span>(<span class="kw">paste0</span>(<span class="st">&quot;^&quot;</span>, isr4,<span class="st">&quot; &quot;</span>), n.gram)) %&gt;%
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">predicted.word =</span> <span class="kw">getLastWords</span>(n.gram, <span class="dv">1</span>))  %&gt;%<span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">propability =</span> (counts*<span class="fl">0.4</span>)/trigram.df.short$counts[trigram.df.short$n.gram ==<span class="st"> </span>isr4]) %&gt;%
<span class="st">    </span><span class="kw">arrange</span>(<span class="kw">desc</span>(propability)) %&gt;%
<span class="st">    </span><span class="kw">select</span>(predicted.word, propability) %&gt;%
<span class="st">    </span><span class="kw">top_n</span>(<span class="dv">3</span>) 
        
<span class="co"># do exactly the same stuff for the 3-gram table plus backoff factor</span>
pred.tri &lt;-<span class="st"> </span>trigram.df.short %&gt;%<span class="st">  </span>
<span class="st">    </span><span class="kw">filter</span>(<span class="kw">grepl</span>(<span class="kw">paste0</span>(<span class="st">&quot;^&quot;</span>, isr3,<span class="st">&quot; &quot;</span>), n.gram)) %&gt;%
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">predicted.word =</span> <span class="kw">getLastWords</span>(n.gram, <span class="dv">1</span>))  %&gt;%<span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">propability =</span> (counts*<span class="fl">0.4</span>*<span class="fl">0.4</span>)/bigram.df.short$counts[bigram.df.short$n.gram ==<span class="st"> </span>isr3]) %&gt;%
<span class="st">    </span><span class="kw">arrange</span>(<span class="kw">desc</span>(propability)) %&gt;%
<span class="st">    </span><span class="kw">select</span>(predicted.word, propability) %&gt;%
<span class="st">    </span><span class="kw">top_n</span>(<span class="dv">3</span>) 
           
<span class="co"># do exactly the same stuff for the 2-gram table plus backoff factor</span>
pred.two &lt;-<span class="st"> </span>bigram.df.short %&gt;%<span class="st">  </span>
<span class="st">    </span><span class="kw">filter</span>(<span class="kw">grepl</span>(<span class="kw">paste0</span>(<span class="st">&quot;^&quot;</span>, isr2,<span class="st">&quot; &quot;</span>), n.gram)) %&gt;%
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">predicted.word =</span> <span class="kw">getLastWords</span>(n.gram, <span class="dv">1</span>))  %&gt;%<span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">propability =</span> (counts*<span class="fl">0.4</span>*<span class="fl">0.4</span>*<span class="fl">0.4</span>)/unigram.df.short$counts[unigram.df.short$n.gram ==<span class="st"> </span>isr2]) %&gt;%
<span class="st">    </span><span class="kw">arrange</span>(<span class="kw">desc</span>(propability)) %&gt;%
<span class="st">    </span><span class="kw">select</span>(predicted.word, propability) %&gt;%
<span class="st">    </span><span class="kw">top_n</span>(<span class="dv">3</span>) 
        
<span class="co"># do exactly the same stuff for the 1-gram table plus backoff factor</span>
pred.one &lt;-<span class="st"> </span>unigram.df.short %&gt;%<span class="st">  </span>
<span class="st">    </span><span class="kw">arrange</span>(<span class="kw">desc</span>(counts)) %&gt;%<span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">predicted.word =</span> n.gram)  %&gt;%<span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">propability =</span> (counts*<span class="fl">0.4</span>*<span class="fl">0.4</span>*<span class="fl">0.4</span>*<span class="fl">0.4</span>)/<span class="kw">sum</span>(unigram.df.short$counts)) %&gt;%
<span class="st">    </span><span class="kw">arrange</span>(<span class="kw">desc</span>(propability)) %&gt;%
<span class="st">    </span><span class="kw">select</span>(predicted.word, propability) %&gt;%
<span class="st">    </span><span class="kw">top_n</span>(<span class="dv">3</span>) 

<span class="co"># combine results into a datframe and sort</span>
prop.table &lt;-<span class="st"> </span><span class="kw">rbind</span>(pred.five,pred.four,pred.tri,pred.two, pred.one) %&gt;%
<span class="st">    </span><span class="kw">arrange</span>(<span class="kw">desc</span>(propability))  

<span class="co"># drop words wich are found again in a lower N-gram</span>
prop.table &lt;-<span class="st"> </span>prop.table[!<span class="kw">duplicated</span>(prop.table$predicted.word),]

<span class="co"># show results</span>
prop.table &lt;-<span class="st"> </span>prop.table %&gt;%
<span class="st">    </span><span class="kw">top_n</span>(<span class="dv">3</span>)

<span class="kw">return</span>(prop.table)
}

<span class="co"># test </span>
<span class="kw">pred.word4</span>(<span class="st">&quot;this thing works pretty&quot;</span>)</code></pre></div>
<pre><code>##   predicted.word propability
## 1           much 0.007368266
## 2           good 0.007273801
## 3           sure 0.005337269</code></pre>
<p align="justify">
The final prediction function shown below just chooses the appropriate function based on the length of the input string. The reason for this approach is that I eventually want to predict a word whenever the user hits the space-bar.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># final function that chooses the appropiate pred.word() depending on input length</span>
<span class="co"># and normalized the input sentences with norm.text()</span>
word.pred &lt;-<span class="st"> </span>function(input){
        input.clean &lt;-<span class="st"> </span><span class="kw">norm.text</span>(input, profanity)
        inlength &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unlist</span>(<span class="kw">strsplit</span>(input.clean,<span class="st">&quot; &quot;</span>)))
        if (inlength &gt;=<span class="st"> </span><span class="dv">4</span>) {
                p &lt;-<span class="st"> </span><span class="kw">pred.word4</span>(input.clean)
        }  else if (inlength ==<span class="st"> </span><span class="dv">3</span>) {
                p &lt;-<span class="st"> </span><span class="kw">pred.word3</span>(input.clean)
        }  else if (inlength ==<span class="st"> </span><span class="dv">2</span>) {
                p &lt;-<span class="st"> </span><span class="kw">pred.word2</span>(input.clean)
        }  else
                p &lt;-<span class="st"> </span><span class="kw">pred.word1</span>(input.clean)
<span class="kw">return</span>(p)
}</code></pre></div>
<p align="justify">
Now, that I have a working model There are quiet a few things which I need to consider for potentilally alternative specifications (some of them were already outlined):
</p>
<ul>
<li><p>What is a good alternative to the data frame format to store the N-gram tables? (data.table)</p></li>
<li><p>What sample size offers good predictive performance without over-straining the hardware? (I’ll try to find the right balance between speed and accuracy. Getting about 1 million sentences would be nice)</p></li>
<li><p>Does removing the stop words makes sense? (Removing seems not natural to me)</p></li>
<li><p>Does aggregating words with similar word stem makes sense? (Again, removing seems not natural to me)</p></li>
<li><p>Do I want to consider any other approaches such as Kneser-Ney? (Stupid Backoff seems to be a good compromise between too simple models such as Laplace Smoothing and unnecessary advanced models)</p></li>
<li><p>To which approach do I switch if the algorithm is rubbish? (Neural Nets)</p></li>
<li><p>How do I choose between word predictions that have the same probability? (no idea, except rolling a dice)</p></li>
<li><p>How do I deal with completely unknown words? (Maybe teach the algorithm to add new words/sentences to the text corpus. Though, I think that might be a bit over the top for this project. Probably just show three most frequent 1-grams)</p></li>
</ul>
</div>
<div id="testing-the-model-on-some-of-the-quiz-data-provided-by-coursera" class="section level2">
<h2>Testing the Model on some of the Quiz Data Provided by Coursera</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">word.pred</span>(<span class="st">&quot;The guy in front of me just bought a pound of bacon, a bouquet, and a case of&quot;</span>)</code></pre></div>
<pre><code>##   predicted.word propability
## 1            the 0.168421053
## 2              a 0.013980583
## 3           this 0.003106796</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">word.pred</span>(<span class="st">&quot;You're the reason why I smile everyday. Can you follow me please? It would mean the&quot;</span>)</code></pre></div>
<pre><code>##   predicted.word propability
## 1          world 0.857142857
## 2           most 0.006530612
## 3            one 0.006530612
## 4           same 0.006530612</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">word.pred</span>(<span class="st">&quot;Hey sunshine, can you follow me and make me the&quot;</span>)</code></pre></div>
<pre><code>##   predicted.word propability
## 1       happiest 0.400000000
## 2           most 0.008030888
## 3      oppounity 0.004942085</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">word.pred</span>(<span class="st">&quot;Ohhhhh #PointBreak is on tomorrow. Love that film and haven't seen it in quite some&quot;</span>)</code></pre></div>
<pre><code>##   predicted.word propability
## 1           time 0.148571429
## 2             of 0.009078215
## 3         people 0.001574311</code></pre>
</div>
<div id="testing-algorithm-1.0-on-the-test-data-set" class="section level2">
<h2>Testing Algorithm 1.0 on the Test Data Set</h2>
<p align="justify">
Before I can answer any of the above statements, obviously I need to measure the accuracy on some test data. So that I’m eventually able to judge the algorithm not only by it’s required stored data and it’s speed but also by it’s accuracy. Below you find some code were the algorithm predicts the last words of each sentence in some of the test data. Note that, word prediction is not comparable to other machine learning fields were accuracy measures are much higher. In my case getting something around 15% would be descent (Someone told me that Swiftkey gets about 30 percent. However, they switched to neuronal nets recently which improved their accuracy a lot).
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testing.short &lt;-<span class="st"> </span>testing[<span class="kw">nchar</span>(testing) &gt;<span class="st"> </span><span class="dv">25</span>]
<span class="kw">set.seed</span>(<span class="dv">2017</span>)
testing.short &lt;-<span class="st"> </span><span class="kw">sample</span>(testing.short, <span class="dv">2500</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)

<span class="co"># delete last word to get input sentence and normalize it</span>
input &lt;-<span class="st"> </span><span class="kw">lapply</span>(testing.short, function(x) <span class="kw">gsub</span>(<span class="st">&quot;</span><span class="ch">\\</span><span class="st">s*</span><span class="ch">\\</span><span class="st">w*$&quot;</span>, <span class="st">&quot;&quot;</span>, x))

<span class="co"># save last true word  </span>
last.word.real &lt;-<span class="st"> </span><span class="kw">lapply</span>(testing.short, function(x) <span class="kw">getLastWords</span>(x, <span class="dv">1</span>))

<span class="co"># apply predict function to input only keep words </span>
last.word.pred &lt;-<span class="st"> </span><span class="kw">lapply</span>(input , function(x) <span class="kw">word.pred</span>(x)[,<span class="dv">1</span>])

<span class="co"># create data frame that includes pass and fail </span>
accuracy.df &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">cbind</span>(last.word.real, last.word.pred)) %&gt;%
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">last.word.real =</span> <span class="kw">as.character</span>(last.word.real)) %&gt;%
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">last.word.pred =</span> <span class="kw">as.character</span>(last.word.pred)) %&gt;%
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">pass =</span> <span class="kw">ifelse</span>(<span class="kw">str_detect</span>(last.word.pred,last.word.real), <span class="dv">1</span>, <span class="dv">0</span>))</code></pre></div>
<p align="justify">
The summary table below shows the accuracy (in percent) for 2500 test sentences, the execution time for a single input string (in seconds), and the size of the required N-gram tables (in byte), as well as the provided number of N-grams.
</p>
<table>
<thead>
<tr class="header">
<th align="right">accuracy</th>
<th align="right">size</th>
<th align="right">speed</th>
<th align="right">n_grams</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.18</td>
<td align="right">49499328</td>
<td align="right">0.37</td>
<td align="right">698231</td>
</tr>
</tbody>
</table>
<p align="justify">
Using about 700.000 N-grams I get a good accuracy. The execution time is becoming a problem though there is no way to increase the N-gram library further using the current approach without becoming too slow. The size of the N-gram tables is alright but still improvable. In order to improve the results I plan to implement the following two changes: Using indexes and shifting to data.table in combination with keys which should result in significant model improvements regarding speed and storage.
</p>
</div>
<div id="building-the-algorithm-backoff-2.0---indexing-data.table-and-keys" class="section level2">
<h2>Building the Algorithm: Backoff 2.0 - Indexing, “data.table” and Keys</h2>
<p align="justify">
Indexing means that one uses the 1-gram table as an index dictionary, in a sense that each word gets an unique index number. Any other N-gram table is then transferred into a sequence of numbers. The reason why this may help is that searching for numbers instead of strings is considerably faster. Besides, I can probably save some storage because the data type integer is much smaller then character. So let’s give that approach a shot and transform the N-grams accordingly.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># give each word an unique index number</span>
unigram.df.short &lt;-<span class="st"> </span>unigram.df.short  %&gt;%
<span class="kw">mutate</span>(<span class="dt">word.index =</span> <span class="kw">c</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(unigram.df.short)))

<span class="co"># split higher N-grams into single words</span>
bigram.df.short.sep &lt;-<span class="st"> </span>bigram.df.short  %&gt;%
<span class="st">    </span><span class="kw">separate</span>(n.gram, <span class="kw">c</span>(<span class="st">&quot;word1&quot;</span>, <span class="st">&quot;word2&quot;</span>), <span class="st">&quot; &quot;</span>)
trigram.df.short.sep &lt;-<span class="st"> </span>trigram.df.short  %&gt;%
<span class="st">    </span><span class="kw">separate</span>(n.gram, <span class="kw">c</span>(<span class="st">&quot;word1&quot;</span>, <span class="st">&quot;word2&quot;</span>, <span class="st">&quot;word3&quot;</span>), <span class="st">&quot; &quot;</span>)
fourgram.df.short.sep &lt;-<span class="st"> </span>fourgram.df.short  %&gt;%
<span class="st">    </span><span class="kw">separate</span>(n.gram, <span class="kw">c</span>(<span class="st">&quot;word1&quot;</span>, <span class="st">&quot;word2&quot;</span>, <span class="st">&quot;word3&quot;</span>, <span class="st">&quot;word4&quot;</span>), <span class="st">&quot; &quot;</span>)
fivegram.df.short.sep &lt;-<span class="st"> </span>fivegram.df.short  %&gt;%
<span class="st">    </span><span class="kw">separate</span>(n.gram, <span class="kw">c</span>(<span class="st">&quot;word1&quot;</span>, <span class="st">&quot;word2&quot;</span>,<span class="st">&quot;word3&quot;</span>, <span class="st">&quot;word4&quot;</span>, <span class="st">&quot;word5&quot;</span>), <span class="st">&quot; &quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># change N-gram values to corresponding index number</span>
bigram.df.short.sep   &lt;-<span class="st"> </span><span class="kw">as.data.table</span>(<span class="kw">sapply</span>(bigram.df.short.sep,   mapvalues, <span class="dt">from =</span> unigram.df.short$n.gram, <span class="dt">to =</span> unigram.df.short$word.index))
trigram.df.short.sep  &lt;-<span class="st"> </span><span class="kw">as.data.table</span>(<span class="kw">sapply</span>(trigram.df.short.sep,  mapvalues, <span class="dt">from =</span> unigram.df.short$n.gram, <span class="dt">to =</span> unigram.df.short$word.index))
fourgram.df.short.sep &lt;-<span class="st"> </span><span class="kw">as.data.table</span>(<span class="kw">sapply</span>(fourgram.df.short.sep, mapvalues, <span class="dt">from =</span> unigram.df.short$n.gram, <span class="dt">to =</span> unigram.df.short$word.index))
fivegram.df.short.sep &lt;-<span class="st"> </span><span class="kw">as.data.table</span>(<span class="kw">sapply</span>(fivegram.df.short.sep, mapvalues, <span class="dt">from =</span> unigram.df.short$n.gram, <span class="dt">to =</span> unigram.df.short$word.index))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># adjust variable type</span>
fivegram.df.short.sep[]   &lt;-<span class="st"> </span><span class="kw">lapply</span>(fivegram.df.short.sep, as.integer)
bigram.df.short.sep[]     &lt;-<span class="st"> </span><span class="kw">lapply</span>(bigram.df.short.sep, as.integer)
trigram.df.short.sep[]    &lt;-<span class="st"> </span><span class="kw">lapply</span>(trigram.df.short.sep, as.integer)
fourgram.df.short.sep[]   &lt;-<span class="st"> </span><span class="kw">lapply</span>(fourgram.df.short.sep, as.integer)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">object.size</span>(unigram.df.short) +<span class="st"> </span><span class="kw">object.size</span>(bigram.df.short.sep) +<span class="st"> </span><span class="kw">object.size</span>(trigram.df.short.sep) +<span class="st"> </span><span class="kw">object.size</span>(fourgram.df.short.sep) +<span class="st"> </span><span class="kw">object.size</span>(fivegram.df.short.sep))</code></pre></div>
<pre><code>## 13076304 bytes</code></pre>
<p align="justify">
Nice, the amount of required storage is much lower then before (only about a fourth). Now, the next step is adjust my code and test whether or not the execution time is lower as well. Note that the code of the algorithm remains pretty much the same. The key for improvement here is basically replacing the filter() function of dplyr with the equivalent function of data.table. Besides, I set keys to each N-gram table which is nothing else but keeping a sorted version of certain columns. So why do I expect this changes to improve execution time? In short, instead of vector scans the new algorithm uses binary search now to find adequate N-grams. You may have noticed another change in the code. I do not use discounted probabilities any longer. Instead I use just the frequencies. Higher order N-grams are still more likely to be suggested then lower order N-grams. Honestly speaking, the reason for this was some coding issues related to the key function of “data.table” and results seem to remain the same. I’m far from an expert in “Language Models” and for this specific task, I do not see why using probabilities is required because the order of the suggestion will be the same anyways.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># set keys for the N-gram-dictionaries </span>
<span class="kw">setkey</span>(fivegram.df.short.sep, word1, word2, word3,word4)
<span class="kw">setkey</span>(fourgram.df.short.sep, word1, word2, word3)
<span class="kw">setkey</span>(trigram.df.short.sep, word1, word2)
<span class="kw">setkey</span>(bigram.df.short.sep, word1)

###########################
###### ALGORITHM 2.0 ######
###########################

<span class="co"># this function is used if the input sentence is at least for words</span>
pred4i &lt;-<span class="st"> </span>function(input.sentence){
    
<span class="co"># take the last four words from input sentence as input for 5-gram table</span>
last.words4 &lt;-<span class="st"> </span><span class="kw">getLastWords</span>(input.sentence, <span class="dv">4</span>)

<span class="co"># transform input sentence into a data.table and replace charatcers with indices</span>
last.words4   &lt;-<span class="st"> </span><span class="kw">strsplit</span>(last.words4 , <span class="st">&quot; &quot;</span>)
input.table4  &lt;-<span class="st"> </span><span class="kw">as.data.table</span>(<span class="kw">sapply</span>(last.words4,
  mapvalues, <span class="dt">from =</span> unigram.df.short$n.gram, <span class="dt">to =</span> unigram.df.short$word.index))
w1 &lt;-<span class="st"> </span>input.table4[<span class="dv">1</span>]
w2 &lt;-<span class="st"> </span>input.table4[<span class="dv">2</span>]
w3 &lt;-<span class="st"> </span>input.table4[<span class="dv">3</span>]
w4 &lt;-<span class="st"> </span>input.table4[<span class="dv">4</span>]
input.table4 &lt;-<span class="st"> </span><span class="ot">NULL</span>
input.table4 &lt;-<span class="st"> </span><span class="kw">cbind</span>(w1,w2,w3,w4)
<span class="kw">colnames</span>(input.table4) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;w1&quot;</span>,<span class="st">&quot;w2&quot;</span>,<span class="st">&quot;w3&quot;</span>,<span class="st">&quot;w4&quot;</span>)
input.table4[]   &lt;-<span class="st"> </span><span class="kw">lapply</span>(input.table4, as.integer)

pred.five.i &lt;-<span class="st"> </span>fivegram.df.short.sep[.(input.table4$w1,
                                       input.table4$w2,
                                       input.table4$w3,
                                       input.table4$w4
                                       ), nomatch =<span class="st"> </span>0L] %&gt;%<span class="st"> </span>
<span class="kw">mutate</span>(<span class="dt">predicted.word =</span> word5) %&gt;%
<span class="kw">arrange</span>(<span class="kw">desc</span>(counts)) %&gt;%
<span class="kw">select</span>(predicted.word)
pred.five.i &lt;-<span class="st"> </span>pred.five.i[<span class="dv">1</span>:<span class="dv">3</span>]
    

pred.four.i &lt;-<span class="st"> </span>fourgram.df.short.sep[.(input.table4$w2,
                                       input.table4$w3,
                                       input.table4$w4
                                       ), nomatch =<span class="st"> </span>0L] %&gt;%<span class="st"> </span>
<span class="kw">mutate</span>(<span class="dt">predicted.word =</span> word4) %&gt;%
<span class="kw">arrange</span>(<span class="kw">desc</span>(counts)) %&gt;%
<span class="kw">select</span>(predicted.word)
pred.four.i &lt;-<span class="st"> </span>pred.four.i[<span class="dv">1</span>:<span class="dv">3</span>]
    
pred.tri.i &lt;-<span class="st"> </span>trigram.df.short.sep[.(input.table4$w3,
                                     input.table4$w4
                                     ), nomatch =<span class="st"> </span>0L] %&gt;%<span class="st"> </span>
<span class="kw">mutate</span>(<span class="dt">predicted.word =</span> word3) %&gt;%
<span class="kw">arrange</span>(<span class="kw">desc</span>(counts)) %&gt;%
<span class="kw">select</span>(predicted.word)
pred.tri.i &lt;-<span class="st"> </span>pred.tri.i[<span class="dv">1</span>:<span class="dv">3</span>]

pred.bi.i &lt;-<span class="st"> </span>bigram.df.short.sep[.( input.table4$w4
                                    ), nomatch =<span class="st"> </span>0L] %&gt;%<span class="st"> </span>
<span class="kw">mutate</span>(<span class="dt">predicted.word =</span> word2) %&gt;%
<span class="kw">arrange</span>(<span class="kw">desc</span>(counts)) %&gt;%
<span class="kw">select</span>(predicted.word)
pred.bi.i &lt;-<span class="st"> </span>pred.bi.i[<span class="dv">1</span>:<span class="dv">3</span>]
   
pred.one.i &lt;-<span class="st"> </span><span class="kw">as.data.table</span>(<span class="kw">data.frame</span>(<span class="dt">predicted.word =</span> <span class="kw">c</span>(<span class="st">&quot;the&quot;</span>, <span class="st">&quot;to&quot;</span>, <span class="st">&quot;and&quot;</span>)))

<span class="co"># combine results into a datframe and sort</span>
prop.table &lt;-<span class="st"> </span><span class="kw">rbind</span>(pred.five.i,pred.four.i,pred.tri.i,pred.bi.i, pred.one.i) 

<span class="co"># drop words wich are found again in a lower N-gram</span>
prop.table &lt;-<span class="st"> </span>prop.table[!<span class="kw">duplicated</span>(prop.table$predicted.word),]

<span class="co"># reduce to top three</span>
prop.table &lt;-<span class="st"> </span><span class="kw">na.omit</span>(prop.table)
prop.table &lt;-<span class="st"> </span>prop.table[<span class="dv">1</span>:<span class="dv">3</span>]

<span class="co"># transform back to words</span>
w &lt;-<span class="st"> </span><span class="kw">mapvalues</span>(prop.table$predicted.word, <span class="dt">from =</span> unigram.df.short$word.index, <span class="dt">to =</span> unigram.df.short$n.gram)
        
prop.table$predicted.word &lt;-<span class="st"> </span>w

<span class="kw">return</span>(prop.table)

}</code></pre></div>
</div>
<div id="testing-algorithm-2.0-on-the-test-data-set" class="section level2">
<h2>Testing Algorithm 2.0 on the Test Data Set</h2>
<p align="justify">
The summary table below compares the new algorithm with the old one. I did increase to sample size significantly which must be considered when evaluating the table. So how does the the new algorithm overall?
</p>
<table>
<thead>
<tr class="header">
<th align="right">accuracy</th>
<th align="right">accuracy3</th>
<th align="right">size</th>
<th align="right">size3</th>
<th align="right">speed</th>
<th align="right">speed3</th>
<th align="right">n_grams</th>
<th align="right">n_grams3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.18</td>
<td align="right">0.24</td>
<td align="right">49499328</td>
<td align="right">44129872</td>
<td align="right">0.37</td>
<td align="right">0.19</td>
<td align="right">698231</td>
<td align="right">2472218</td>
</tr>
</tbody>
</table>
<p align="justify">
As I was hoping, accuracy improved because now I use about 2.5 Million N-grams in the dictionary which is almost 4 times as much as before. Moreover, those improvement comes with no costs at all. Using integers, even witch the increased corpus, I still require less storage then originally. Regarding speed the finding is similar (I measured the time required for predicting the next word of the sentence “I hope this thing works pretty” with about 4 of 8 GByte available). Switching to data.table helped a lot. Even with the much longer tables through which the algorithm must search I was able to reduce the execution time by almost half.
</p>
<p align="justify">
Altogether, I’m quiet happy with the new model so that the last step that remains now is building the Shiny page. Once the page is running I may try to improve the model further. While I know that there are plenty of ways to improve coding as well as the algorithm (I would still consider this as the Alpha Version), I still hope that anyone who may read this paper may gained some new insights.
</p>
</div>
</section>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
